To avoid confusion with my main fmri file, here I will describe what I am currently doing for the last few subjects as a note to update the fmri file. Also, remember to split the fmri page into sub-pages, where we explain how to install tools, we give general info, and then a single files for the workflow.

some interesting links: https://www.youtube.com/watch?v=J0npRWV2zTY  [Andrea Jahn on fmriprep](https://www.youtube.com/@AndrewJahn)

Here are my steps:

# Data collection and preparation
at the hospital:
  - take fmri scans from the hospital computer. in the gui, specify what buttons to select.
  - anonymize the fnames with the script i use. this is important to protect subjects privacy (no names should be in the files that leave the hospital)
  - take bh and et data from the output folders in the exp PC
  - copy all the files into a sourcedata/ folder in bh, nifti, et folders

Now I have my source data folder. We need to.
  - anonymize/deface the images
  - run the script01 to move and rename the raw files into the main BIDS folder. This will create a sub-xx folder for each raw sub data
  - run the script02 to convert the behavioural mat data into events.tsv files following the BIDS specification. This will parse the trial data from the mat file, and create new tsv files into each sub-xx folder corresponding to each run.

# BIDS to preprocessing
Now we have our base (raw) data organized in a BIDS folder. this is our starting point for any other analysis. What now?
The main steps we need to follow are: fmriprep, GLM. rois. mvpa

For fmriprep: (fmriprep, docker, fmripre-docker)
  - install docker (and WSL if on windows). Assign resources (RAM, disk, cpus) reasonably (< 80% of your system capacity).
  - install fmriprep-docker. this is as easy as `pip install fmriprep-docker`.
  - share with docker the folders you are going to use. these are you BIDS folder, and a `temp_fmriprep` folder.
  - run fmripre-docker. Below you can see my terminal call to pre-process sub-41. The arguments I use (and a lot more that I don't use) are explained [here](https://fmriprep.org/en/stable/usage.html). Make sure you are familiar with these.
    
    ```sh
    fmriprep-docker /data/projects/chess/data/BIDS /data/projects/chess/data/BIDS/derivatives/fmriprep participant --work-dir //data/projects/chess/data/temp_fmriprep --mem-mb 10000 --n-cpus 16 --output-spaces MNI152NLin2009cAsym:res-2 anat fsnative --fs-license-file /data/projects/chess/misc/.license --bold2t1w-dof 9 --task exp --dummy-scans 0 --fs-subjects-dir /data/projects/chess/data/BIDS/derivatives/fastsurfer --notrack --participant-label 41
    ```
    
!!! note
    if you want to run analysis on surface data, you may want to consider getting CIFTI output images from fmriprep. I did not test this, but it should produce cortical BOLD series projected from the Glasser2016 template (the same parcellation I use for MVPA). In theory, SPM should be able to analyze .gii surface data, and bt getting the CIFTI outputs you should already have the parcellation projected to subject space for subsequent analyses. Or at least it should give a Glasser parcellation on subject/MNI space that is directly usable for MVPA, therefore skipping the quite time-sonsuming and complicate step to produce the HPC ROIs (see below)
    
!!! warning
    this call is very resource and time intensive. It will take several hours (4-8, depending on your PC specs) at full capacity to preprocess a single subject. If you need to process many subjects, you may want to play with the ncpus and mem-mb parameters to be sure that you are using all the available resources. A good test of this is to open the task manager on windows, and check the CPU and RAM usage during a run. Ideally, we want the CPU to be always at max speed, and the RAM to be 10 GB below the maximum. If the RAM needed by the process is higher than the RAM available, you will get Out of Memory errors, or No more space on disk errors if you did not specify a work-dir folder. If this happens, lower the mem-mb and n-cpus until tyou find the right spot.
    
  - If the run finishes successfully (check the last line of your terminal output), you should have a new `BIDS/derivatives/fmriprep/sub-xx` folder (see [here](https://fmriprep.org/en/stable/outputs.html) for a complete list of outputs generated by fmriprep). make sure that inside you `anat` and `func` folders you have all the scans (anatomical, functional all runs) in the spaces you specified. Since we specified fsnative as space and we did not use the no-recon-all flag, fmriprep will also produce surface data in `BIDS/derivatives/fastsurfer/sub-xx`.
  - QA: Check the sub-xx.hmtl report to make sure everything run smoothly. Specifically, check the registrations, and look for particularly high FD values in the functional runs -- they may be indicative of poor data. See [this page](https://fmriprep.org/en/stable/outputs.html#confounds) for a description of the confounds and [this video](https://www.youtube.com/watch?v=fQHEKSzFKDc&list=PLIQIswOrUH6_szyxn9Fy-2cxd3vjlklde&index=3) for more information on what to look for.

# First-level analysis -- GLM 
Once we are done with preprocessing, it's time for GLM. Running the GLM and setting the contrasts is as easy as running script03. Remember to double-check the parameters at the top of the file. Specifically, you will need to adjust:
  - read/write folder, including the fmriprep folder in `fmriprepRoot`, your BIDS folder in `BIDSRoot`, the folder you want to save your GLM results to (it should ideally be in the derivatives folder, in a `fmriprep-spm` folder) in `outRoot`, and a directory to store your temporary files (e.g., uncompressed, since SPM can't read compressed gz files, and/or smoothed files) in `tempDir`.
  - the list of subjects you want to analyze in `selectedSubjectsList`. It must be list of integers like `selectedSubjectsList = [41,42,43,44];` or `selectedSubjectsList = '*';` to perform the analysis on all subjects.
  - the list of runs you want to analyze in `selectedRuns`.
  - The contrasts you want to set to get the corresponding t-maps. Here is an example for my task:
  ```
  selectedTasks(1).name = 'exp'; % The name of the task to analyze. Must correspond to the task in your BIDS filenames
  selectedTasks(1).contrasts = {'Check > No-Check'}; % The name of the contrast
  selectedTasks(1).weights(1) = struct('C_WILDCARD___WILDCARD_', 1, 'NC_WILDCARD___WILDCARD_', -1); % The weights assigned to each regressor. See function adjust_contrasts.m for more information on how to set this correctly.
  selectedTasks(1).smoothBool = false; % Whether to smooth the images before GLM. Useful for localizers.
  ```

If everything was set correctly, this script should run smoothly and produce new `sub-xx` folders in your output folder. You can check whether the subject folder contains a sub-folder for each analyses task, along with `beta_000x.nii` files for each regressor (i.e., each confound and condition * number of runs).

At this stage, it is strongly advisable to check whether the design matrix was correctly specified. To do so, you can open the SPM GUI by typing `spm fmri` in your Matlab Command Window, then click on 'Results' and select the SPM.mat file inside your bets images directory in `BIDS/fmriprep-spm/{space}/sub-xx/{task_name}/`. This will open the SPM Contrast Manager, that will show the design matrix and assigned contrasts. Make sure the matrix looks reasonable (no overlapping or extremely long conditions, correct number of runs, confound regressors at the end of each run, etc.), and that the contrast weights were assigned correctly. 

Now, select your contrast and click 'Done'. In the next window, select apply masking -> None, p value adjustment -> None -> 0.001, threshold -> 0. And voila'! You will see the results of the contrast -- that is, your thresholded t map for this subject -- on the top right, along with a list of significantly active cluster on the bottom right panel.

If you want, you can visualize these activations on a volume of your subject (or on the surface if you have performed recon-all). To do so you can click on 'Display' -> 'overlays...' and select 'sections' if you want to plot on the volume, or `render` if you want to plot on surface. This will open a new windows, where you need to select the subject anatomical image. This image will be in the `BIDS/derivatives/fmriprep/sub-xx/anat` folder. If you plot on sections, you need to select the nii file corresponding to the same space your GLM was performed on (usually MNI). If you plot on surface, select the pial or inflated brain.

!!! warning
    As I mentioned above, SPM cannot import nii.gz files directly, so you will need to decompress the anatomical image into a .nii. This can be done very easily with any decompressing tool by right-clicking the file in your file explorer. Once the file is decompressed, select it with the SPM GUI.

Once we double-checked the results of the GLM, and we are sure we are happy with it, we'll need generate our ROI masks and perform the multi-variate analysis (MVPA and RSA). This will be done in [cosmomvpa](https://cosmomvpa.org/documentation.html). 

# Generate and organize your ROI masks
To run the MVPA you will need some Regions of Interest (ROIs) to select your voxels. One way to do this, is to perform a functional localizer task in the scanner, and run a GLM on the pre-processed and smoothed data for that task to select only voxels active in a given condition (e.g., Faces > Objects to get FFA). Another way could be using pre-defined anatomical masks, mapped in the same space as your subjects (usually, MNI). If you use an anatomical mask, make sure it is in the same space as your subjects, and it has the same resolution. If the resolution of your data (usually, 2*2*2) is different from the resolution of your parcel (1*1*1), you will need to resample/reslice the anatomical mask to match the resolution of your data. Thic can be done in ANTs, SPM, or many python libraries (e.g., nilearn/nibabel).

In my pipeline, I use the [Glasser2016 parcellation projected on fsaverage](https://figshare.com/articles/dataset/HCP-MMP1_0_projected_on_fsaverage/3498446), comprising 180 ROIs per hemisphere. This part is a bit tricky to understand for new-comers because is full of jargon and uses tools that are not very user-friendly. In a nutshell, the Glasser parcellation (aka HCP-MMP1 parcellation) annotation files that you can find on that website are converted to labels, and mapped from the fsaverage to the subject's T1 and MNI volume spaces. This can be done automatically using the `HPC-to-subject.sh` script (see top of the file for more information and usage notes).

# Multi-variate analysis
Once we produced and organized our ROIs, it's time for MVPA. Again, running the MVPA analysis is as easy as running a script. In my pipeline, script04 runs independent cross-validated SVM classification analysis on each subject and ROI, and returns the decoding accuracy for each roi of the HPC parcellation.

The script produces a `BIDS/derivatives/mvpa` folder organized in a BIDS structure, with folders for each subject including a tsv file with the decoding accuracy results. 

The Glasser parcellation has percels at three levels, where each higher level groups several ROIs into a single ROI. In my pipeline, I run the analysis at the lowest level (180 parcels per hemisphere), and average the results of the ROIs within a bigger ROI to get the average accuracy of the bigger ROI. This can be done with the script06. This script prepares the average accuracies at each level by averaging the accuracies at the lowest level, compute the significance against chance for each decoding accuracy, and plots the significant accuracies on an inflated brain for each grouping level. For instance:

![Decoding Example](https://raw.githubusercontent.com/HOPLAB-LBP/hoplab-wiki/main/assets/fmri/combined_brain_grid.png)


    
