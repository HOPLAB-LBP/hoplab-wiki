var __index = {"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welcome to the Hoplab Wiki","text":"<p>Welcome to the Hoplab Wiki repository. This Wiki is a work in progress and an ongoing effort to migrate all the Hoplab wisdom into a more user-friendly format. This process is currently managed by @costantinoai and @kschevenels. For any questions, feel free to ping me.</p> <ul> <li> <p> Research Tools &amp; Methods</p> <p>Access guides and procedures for conducting research at Hoplab</p> <p> Explore methods</p> </li> <li> <p> Get Started</p> <p>Essential information for new members to hit the ground running</p> <p> Start here</p> </li> <li> <p> Contribute</p> <p>Learn how you can help improve and expand our knowledge base</p> <p> How to contribute</p> </li> </ul>"},{"location":"index.html#research-tools-methods","title":"Research Tools &amp; Methods","text":"<ul> <li> <p> Behaviour</p> <p>Methodologies for behavioral experiments</p> <p> Learn more</p> </li> <li> <p> Coding</p> <p>Best practices and resources for research coding</p> <p> Learn more</p> </li> <li> <p> Deep Neural Networks</p> <p>Guides for implementing and using DNNs in research</p> <p> Learn more</p> </li> <li> <p> EEG</p> <p>Procedures for EEG data collection and analysis</p> <p> Learn more</p> </li> <li> <p> Eye Tracking</p> <p>Protocols for eye-tracking experiments</p> <p> Learn more</p> </li> <li> <p> fMRI</p> <p>Guidelines for fMRI studies and data analysis</p> <p> Learn more</p> </li> </ul>"},{"location":"index.html#essential-resources","title":"Essential Resources","text":"<ul> <li> <p> Student Starter Pack</p> <p>Essential information for new students</p> <p> Get started</p> </li> <li> <p> Computer Setup</p> <p>Set up your work environment</p> <p> Set up</p> </li> <li> <p> Practical Setup</p> <p>Day-to-day operational guidelines</p> <p> Learn more</p> </li> <li> <p> Mailing Lists</p> <p>Stay informed with our mailing lists</p> <p> Subscribe</p> </li> <li> <p> Research Ethics</p> <p>Ethical guidelines for research</p> <p> Learn more</p> </li> <li> <p> Outreach</p> <p>Engage with the wider community</p> <p> Explore</p> </li> </ul>"},{"location":"index.html#quick-links","title":"Quick Links","text":"<ul> <li> Lab Calendar (Requires permission)</li> <li> Hoplab Teams Directory (Requires permission)</li> <li> Hoplab Website</li> <li> Hoplab Publication</li> </ul>"},{"location":"index.html#need-help","title":"Need Help?","text":"<p>Can't find what you're looking for? Have questions or suggestions? Don't hesitate to reach out:</p> <ul> <li>Wiki Managers: @costantinoai and @kschevenels</li> <li>Contact: Andrea Costantino</li> </ul>"},{"location":"contribute.html","title":"Contribute to the Hoplab Wiki","text":"<p>Welcome to the Hoplab Wiki repository. This Wiki is a work in progress and an ongoing effort to migrate all the Hoplab knowledge and procedures into a more user-friendly format. This process is currently managed by @costantinoai and @kschevenels. For any questions, feel free to ping me. </p> <p>This guide will help you set up, update, and maintain the Wiki both locally and online. Follow the instructions if you want to make changes to the wiki.</p>"},{"location":"contribute.html#table-of-contents","title":"Table of Contents","text":"<ol> <li>Getting Started</li> <li>Editing the Wiki<ul> <li>Adding a New Page</li> <li>Creating Child Pages</li> <li>Adding Tags</li> <li>Common Formatting Syntax</li> <li>Linking and Referencing</li> </ul> </li> <li>How to Contribute<ul> <li>Easy Workflow (Quick Changes)</li> <li>Advanced Workflow (Extensive Changes)</li> </ul> </li> <li>Reviewing and Accepting Pull Requests (for Admins)</li> <li>Troubleshooting</li> </ol>"},{"location":"contribute.html#getting-started","title":"Getting Started","text":"<p>Before you begin, ensure you have the following:</p> <ul> <li>A GitHub account (click here to sign up).</li> <li>Be part of the <code>HOPLAB-LBP</code> organization (contact Andrea if you need to be added).</li> <li>If you plan on following the Advanced Workflow (encouraged for more complex changes), also make sure that you have Conda or Miniconda, and git or GitHub Desktop (strongly encouraged) installed.</li> </ul>"},{"location":"contribute.html#editing-the-wiki","title":"Editing the Wiki","text":"<p>We welcome contributions from all members. All the content of the wiki is written in Markdown files located in the <code>docs</code> directory. You can edit these files in your browser (if you follow the Easy Workflow) or locally using any text editor or IDE (e.g., VSCode, Sublime Text) if you follow the Advanced Workflow.</p>"},{"location":"contribute.html#adding-a-new-page","title":"Adding a New Page","text":"<ol> <li>Create a new Markdown file in the <code>docs</code> directory (e.g., <code>docs/new-page.md</code>).</li> <li>Add the new page to the <code>nav</code> section of <code>mkdocs.yml</code>:  <pre><code>nav:\n  - Home: index.md\n  - Guide: guide.md\n  - New Page: new-page.md\n</code></pre></li> </ol>"},{"location":"contribute.html#creating-child-pages","title":"Creating Child Pages","text":"<p>To create a child page, place the Markdown file in a subdirectory and update the <code>nav</code> section in <code>mkdocs.yml</code> accordingly:</p> <ol> <li>Create a new subdirectory in the <code>docs</code> directory (e.g., <code>docs/subdir</code>).</li> <li>Create a new Markdown file in the subdirectory (e.g., <code>docs/subdir/child-page.md</code>).</li> <li>Update the <code>nav</code> section in <code>mkdocs.yml</code>:  <pre><code>nav:\n  - Home: index.md\n  - Guide: guide.md\n  - Subdir:\n      - Child Page: subdir/child-page.md\n</code></pre></li> </ol>"},{"location":"contribute.html#adding-note-todo-and-placeholder-tags","title":"Adding <code>NOTE</code>, <code>TODO</code>, and <code>PLACEHOLDER</code> tags","text":"<p>For ease of collaboration, we keep track of all the tasks in our documentation in the Issues page. Tasks are organized by file, and each file with tags will automatically be listed as Issue.</p> <p>To add a new task to this list, you just need to write <code>NOTE</code>, <code>TODO</code>, or <code>PLACEHOLDER</code> in any document in the <code>docs/</code> folder. This will automatically be added to the Issue for that page during the Wiki building process. It is a good practice to write the name of the author in square brackets. Example:</p> <p><code>TODO: [Andrea] fix hyperlinks</code></p> <p>Please, remember to delete the source tag from the original file once the task is resolved. This will ensure that the Issue page includes only un-resolved tasks.</p>"},{"location":"contribute.html#common-formatting-syntax","title":"Common Formatting Syntax","text":"<p>Here are some common Markdown elements:</p> <ul> <li>Headers: <code># Header 1</code>, <code>## Header 2</code>, <code>### Header 3</code>, etc.</li> <li>Bold text: <code>**bold text**</code></li> <li>Italic text: <code>*italic text*</code></li> <li>Links: <code>[link text](URL)</code></li> <li>Lists: <ul> <li>Unordered list: <code>- Item 1</code></li> <li>Ordered list: <code>1. Item 1</code></li> </ul> </li> <li>Images: <code>![Alt text](path/to/image.png)</code> (see this section for instructions on how to link images.)</li> </ul> <p>For more advanced formatting options, refer to the MkDocs Material Reference Guide.</p>"},{"location":"contribute.html#linking-and-referencing","title":"Linking and Referencing","text":"<p>When creating or editing content, you may want to reference or link to other sections within the wiki, external resources, or images. Here's how to do it:</p>"},{"location":"contribute.html#internal-links-within-the-wiki","title":"Internal Links (Within the Wiki)","text":"<p>Use relative paths for internal links. The general format is:</p> <pre><code>[Link Text](path/to/file.md)\n</code></pre> <p>Examples:</p> <ol> <li> <p>Linking to a page in the same directory:    <pre><code>[Getting Started](getting-started.md)\n</code></pre></p> </li> <li> <p>Linking to a page in a subdirectory:    <pre><code>[fMRI Analysis](research/fmri/fmri-analysis.md)\n</code></pre></p> </li> <li> <p>Linking to a specific section on another page:    <pre><code>[Ethics Guidelines](research/ethics/index.md#ethical-guidelines)\n</code></pre></p> </li> <li> <p>Linking to a parent directory:    <pre><code>[Back to Research](../index.md)\n</code></pre></p> </li> </ol>"},{"location":"contribute.html#external-links-outside-the-wiki","title":"External Links (Outside the Wiki)","text":"<p>For external links, use the full URL:</p> <pre><code>[Hoplab Website](https://www.hoplab.be/)\n</code></pre>"},{"location":"contribute.html#adding-and-linking-images","title":"Adding and Linking Images","text":"<p>When adding images to the Wiki:</p> <ol> <li>Store all images in the <code>docs/assets</code> folder.</li> <li>Use descriptive, lowercase names for images, separating words with hyphens (e.g., <code>fmri-analysis-workflow.png</code>).</li> <li> <p>Use relative links to reference images. The path depends on the location of your Markdown file:</p> <ul> <li> <p>If your Markdown file is in the main <code>docs</code> folder:  <pre><code>![fMRI Analysis Workflow](../assets/fmri-analysis-workflow.png)\n</code></pre></p> </li> <li> <p>If your file is in a subdirectory of <code>docs</code> (e.g., <code>docs/research/</code>):  <pre><code>![fMRI Analysis Workflow](../../assets/fmri-analysis-workflow.png)\n</code></pre></p> </li> <li> <p>If your file is in a sub-subdirectory (e.g., <code>docs/research/fmri/</code>):  <pre><code>![fMRI Analysis Workflow](../../../assets/fmri-analysis-workflow.png)\n</code></pre></p> </li> </ul> </li> <li> <p>Always include descriptive alt text for accessibility:    <pre><code>![Diagram showing steps of fMRI analysis](../assets/fmri-analysis-workflow.png)\n</code></pre></p> </li> <li> <p>Optionally, specify image dimensions using HTML:    <pre><code>&lt;img src=\"../assets/fmri-analysis-workflow.png\" alt=\"fMRI Analysis Workflow\" width=\"500\"&gt;\n</code></pre></p> </li> </ol>"},{"location":"contribute.html#best-practices-for-linking","title":"Best Practices for Linking","text":"<ol> <li>Use descriptive link text that gives users an idea of where the link will take them.</li> <li>Check your links after creating them to ensure they work correctly.</li> <li>For external links, consider opening them in a new tab:    <pre><code>[Hoplab Website](https://www.hoplab.be/){target=\"_blank\"}\n</code></pre></li> <li>When linking to specific sections within long documents, use anchor links to improve user experience.</li> <li>For images, always use relative links and store images in the <code>docs/assets</code> folder to maintain a self-contained Wiki.</li> </ol>"},{"location":"contribute.html#how-to-contribute","title":"How to Contribute","text":"<p>We offer two workflows for contributing to the Hoplab Wiki: an Easy Workflow for quick changes to single files, and an Advanced Workflow for more extensive changes to multiple files.</p>"},{"location":"contribute.html#easy-workflow-for-quick-changes","title":"Easy Workflow (for Quick Changes)","text":"<p>This workflow is ideal for making small, quick changes to a single file. It can be done entirely through your web browser and doesn't require any local setup.</p> Edit directly from this page! <p>Existing pages can be edited directly through the Wiki! If you need to edit or add information to any page, look for the paper and pencil symbol  at the top-right of the page, next to the page title. This will make you edit the page and open a PR either by creating a new branch on the main repo (if you are part of the Hoplab organization on GitHub) or by forking your own copy of the repo (if you are an external contributor). Make sure to submit a PR after your changes are made.</p>"},{"location":"contribute.html#step-1-make-your-changes","title":"Step 1: Make your changes","text":"<ol> <li> <p>To edit an existing page:</p> <ol> <li>Navigate to the <code>HOPLAB-LBP/hoplab-wiki</code> repository.</li> <li>Click on the file you want to edit (usually, in <code>docs/</code>).</li> <li>Click on the pencil icon (\u270f\ufe0f) at the top right to edit the file.</li> </ol> </li> <li> <p>To create a new page: </p> <ol> <li>Navigate to the <code>mkdocs.yml</code> file.</li> <li>Click on the pencil icon (\u270f\ufe0f) at the top right to edit the file.</li> <li>Add the new page (e.g., <code>docs/new-page.md</code>) to the <code>nav</code> section and commit (follow the steps in the section 2 below).</li> <li>In the <code>docs</code> folder, click on \"Add file\" &gt; \"Create new file\".</li> <li>Enter a name for your file in the <code>docs</code> directory (the same you used before, e.g., <code>docs/new-page.md</code>).</li> </ol> </li> </ol> <p>You can then add/edit your content in Markdown format (see Editing the Wiki for more info), and click on \"Preview\" next to the \"Edit\" tab to see how your changes will look like.</p>"},{"location":"contribute.html#step-2-commit-changes-to-a-temporary-branch","title":"Step 2: Commit changes to a temporary branch","text":"<ol> <li>Click on \"Commit changes\" after any necessary adjustments.</li> <li>In the pop-up window, add a commit message and description for your changes.</li> <li>Select \"Create a new branch for this commit and start a pull request\".</li> <li>Click on \"Propose changes\".</li> </ol>"},{"location":"contribute.html#step-3-submit-a-pr-with-your-proposed-changes","title":"Step 3: Submit a PR with your proposed changes","text":"<ol> <li>In the \"Open a pull request page\", add an informative title and a description of the changes in the PR.</li> <li>In the right panel, make sure to assign an admin (as of July 2024, @costantinoai) to review your changes.</li> <li>Click on \"Create pull request\" to submit your changes.</li> </ol> Add multiple commits to a single PR <p>If you want to make additional changes related to an already opened PR (e.g., you need to change info in two separate files, or make additional adjustments), you do not need to open a new PR. Just go in the main page of the branch your created (you can find the branch in the branches list) and keep editing your files in this branch. Every new commit you make in this branch will have the option to \"Commit directly to the  branch\" or \"Create a new branch for this commit and start a pull request\". Make sure you select the first option to include your new commits to the original PR. Importantly, if you plan to add several commits to a PR this way, make sure you assign a reviewer only after your last commit to avoid merging PRs halfway in the process, or you can create a draft PR until all your changes are included. <p>These steps above will create a new branch in the repository, that will be visible in the branches list, and a new PR visible in the PRs list. Once the PR is approved by at least one reviewer and merged into the main branch, the newly created branch will be automatically deleted and the changes will go live.</p>"},{"location":"contribute.html#advanced-workflow-for-extensive-changes","title":"Advanced Workflow (for Extensive Changes)","text":"<p>The preferred way to contribute if you need to make significant/multiple changes, but it requires some familiarity with git, Python, and Conda environments. If you are not a Wiki maintainer, this workflow is probably overkill. </p> <p>With this workflow, you will make and preview all the edits locally (on your computer). This allows for more control and flexibility, as it lets you see your changes in a live session. </p> <p>How should I organize my PR?</p> <p>A Pull Request (or PR) \"is a proposal to merge a set of changes from one branch into another\". Ideally, a PR should include all the commits for a specific feature or bugfix from end-to-end. Avoid making PRs that contain multiple unrelated changes. For instance, if you are working on a feature that requires modifications across multiple files, ensure all those changes are included in the same PR. Conversely, avoid combining changes for different features (e.g., adding unrelated updates to the fMRI workflow and the getting started section) in a single PR. Each PR should represent a cohesive unit of work.</p> <p>Here's a step-by-step guide that includes forking and cloning the repository, making and testing changes locally, and then submitting those changes for review through a pull request.</p>"},{"location":"contribute.html#step-1-forking-the-repository-and-cloning-your-fork","title":"Step 1: Forking the Repository and Cloning Your Fork","text":"Using the CLIUsing GitHub Desktop <ol> <li> <p>Navigate to the Original Repository:</p> <p>Open your web browser and go to the GitHub page for the <code>hoplab-wiki</code> repository located under the <code>HOPLAB-LBP</code> organization.</p> </li> <li> <p>Fork the Repository:</p> <p>Click the \"Fork\" button at the top right corner of the repository page. This will create a copy of the repository under your GitHub account.</p> </li> <li> <p>Clone Your Fork:</p> <ol> <li>Click the \"Code\" button on your forked repository page and copy the URL.</li> <li>Open your terminal (Command Prompt on Windows, Terminal on macOS and Linux) and navigate to the directory where you want to store the project, then type:    <pre><code>git clone https://github.com/your-username/hoplab-wiki.git\n</code></pre></li> <li>Change into the directory of the cloned repository:    <pre><code>cd hoplab-wiki\n</code></pre></li> </ol> </li> </ol> <ol> <li> <p>Navigate to the Original Repository:</p> <p>Open your web browser and go to the GitHub page for the <code>hoplab-wiki</code> repository located under the <code>HOPLAB-LBP</code> organization.</p> </li> <li> <p>Fork the Repository:</p> <p>Click the \"Fork\" button at the top right corner of the repository page. This will create a copy of the repository under your GitHub account.</p> </li> <li> <p>Open GitHub Desktop:</p> <p>If you do not have GitHub Desktop installed, download and install it from GitHub Desktop's official website.</p> </li> <li> <p>Clone Your Fork Using GitHub Desktop:</p> <ol> <li>Open GitHub Desktop.</li> <li>In the top menu, click on <code>File &gt; Clone Repository</code>.</li> <li>In the \"URL\" tab, paste the URL of your forked repository from your GitHub account into the \"Repository URL\" field.</li> <li>Choose the local path where you want to store the repository on your computer.</li> <li>Click \"Clone\".</li> </ol> </li> </ol>"},{"location":"contribute.html#step-2-setting-up-your-local-environment","title":"Step 2: Setting Up Your Local Environment","text":"<ol> <li> <p>Install Conda:</p> <p>If you don't have Conda installed, download and install it from Conda's official website.</p> </li> <li> <p>Create and Activate a Conda Environment:</p> <pre><code>conda create --name hoplab-wiki python=3.9\nconda activate hoplab-wiki\n</code></pre> </li> <li> <p>Install Necessary Packages:</p> <pre><code>pip install mkdocs mkdocs-material mkdocs-task-collector mkdocs-git-revision-date-localized-plugin mkdocs-git-authors-plugin\n</code></pre> </li> </ol>"},{"location":"contribute.html#step-3-making-changes","title":"Step 3: Making Changes","text":"<ol> <li>Edit Documentation:      You can now make changes to your local clone of the documentation. Use a text editor or an IDE to open and edit the Markdown files in the repository. If changes are extensive, consider splitting them into smaller, manageable commits that focus on specific pages or sections for clarity and ease of review.</li> </ol>"},{"location":"contribute.html#step-4-testing-your-changes-locally","title":"Step 4: Testing Your Changes Locally","text":"<ol> <li>Serve the Documentation Locally:</li> <li>While in your project directory and with the Conda environment activated, launch the local server by typing:       <pre><code>mkdocs serve\n</code></pre></li> <li>Open a web browser and navigate to <code>http://127.0.0.1:8000/</code>. This allows you to see your changes as they would appear on the live site.</li> <li>Keep this server running as you make changes; refresh your browser to update the preview.</li> </ol>"},{"location":"contribute.html#step-5-closing-the-local-server","title":"Step 5: Closing the Local Server","text":"<ol> <li>Stop the Server:     When you are done previewing and editing and you are done with the changes, go back to the terminal where your server is running and press <code>Ctrl+C</code> to stop the server.</li> </ol>"},{"location":"contribute.html#step-6-committing-your-changes","title":"Step 6: Committing Your Changes","text":"Using the CLIUsing GitHub Desktop <ol> <li>Stage and Commit Your Changes:<ol> <li>From your terminal, add all modified files to your commit:   <pre><code>git add .\n</code></pre></li> <li>Commit the changes, including a clear message about what was modified and why:   <pre><code>git commit -m \"Detailed description of changes\"\n</code></pre></li> </ol> </li> <li>Push your commits to the forked repository on GitHub:       <pre><code>git push origin main\n</code></pre></li> </ol> <ol> <li> <p>Stage and Commit Your Changes:</p> <ol> <li>In GitHub Desktop, you should see the list of changed files in the left sidebar.</li> <li>Review the changes by clicking on each file.</li> <li>Once you are ready to commit, write a summary of the changes in the \"Summary\" field at the bottom left.</li> <li>Add a more detailed description in the \"Description\" field if necessary.</li> <li>Click the \"Commit to main\" button.</li> </ol> </li> <li> <p>Push Your Changes:</p> <ol> <li>In GitHub Desktop, click on the <code>Push origin</code> button at the top to push your commits to GitHub.</li> </ol> </li> </ol>"},{"location":"contribute.html#step-7-creating-a-pull-request","title":"Step 7: Creating a Pull Request","text":"<ol> <li>Navigate to your forked repository on GitHub.</li> <li>Click on the \"Pull requests\" tab.</li> <li>Click on \"New pull request\".</li> <li>Choose the original repository's <code>main</code> branch as the base, and your fork's <code>main</code> branch as the compare.</li> <li>Fill out the form to describe the changes.</li> <li>In the right panel, make sure to assign an admin (as of July 2024, @costantinoai) to review your changes.</li> <li>Click on \"Create pull request\" to submit your changes.   </li> </ol> <p>Automatic Deployment with GitHub Actions</p> <p>This repository is set up to use GitHub Actions for automatic deployment. This means that every time changes are merged into the <code>main</code> branch, the documentation will automatically be built and deployed to GitHub Pages. You do not need to manually run the <code>mkdocs gh-deploy</code> command each time you make changes. Simply push your changes to the <code>main</code> branch, and GitHub Actions will handle the deployment.</p>"},{"location":"contribute.html#reviewing-and-accepting-pull-requests-for-admins","title":"Reviewing and Accepting Pull Requests (for Admins)","text":"<ol> <li>Go to the <code>hoplab-wiki</code> repository on GitHub.</li> <li>Click on the \"Pull requests\" tab.</li> <li>Review the pull request (Approve changes or suggest edits)</li> <li>When the changes are satisfactory, approve the changes and click \"Merge pull request\". This will delete the temporary branch.</li> </ol>"},{"location":"contribute.html#troubleshooting","title":"Troubleshooting","text":""},{"location":"contribute.html#permission-denied-or-authentication-issues","title":"Permission Denied or Authentication Issues","text":"<p>If you encounter issues with pushing to the repository, you may need to use a personal access token. Follow these steps:</p> <ol> <li>Create a fine-grained personal access token here.</li> <li>Use this token for authentication when pushing to the repository. More information on how to do so can be found on this issue. Please, first get a fine-grained Personal Access Token as described in the link above, and then follow the instructions in the \"Manually temporary resolving this issue for a single git repository\" section.</li> </ol>"},{"location":"contribute.html#additional-help","title":"Additional Help","text":"<p>For further assistance, refer to the following resources:</p> <ul> <li>MkDocs Documentation</li> <li>MkDocs Material Theme</li> <li>GitHub Pages Documentation</li> </ul> <p>Or ping me.</p> <p>Thank you for contributing to the Hoplab Wiki!</p>"},{"location":"outreach.html","title":"Do great science and show it to the world","text":"<p>(We'll start small and go bigger)</p>"},{"location":"outreach.html#lab-meetings","title":"Lab meetings","text":""},{"location":"outreach.html#types-of-lab-meetings","title":"Types of lab meetings","text":"<p>There are different types of lab meetings that happen throughout the academic year.</p> Individual meetingsQuick updatesConference updatesNew papers <p>On a rotation basis, each lab member is assigned with a slot and is in charge of the presentation. On this occasion, you can present an update on your research, an interesting / relevant paper for a Journal Club (JC), or other important topics (practicing an upcoming talk or interview, for example).</p> <p>Once per month, lab memebers assigned to a specific batch will give a quick (1-2 slides, 15 minutes) update on the latest development in their work. This meeting is an occasion to ask for help if you are stuck on a particular step, method, analysis, or to just keep each other in the loop. If your individual meeting is scheduled for the week before or the week after your batch, you can skip the quick update for the longer one.</p> <p>This type of lab meeting is usually scheduled after a lab member is back from a conference / workshop. The idea is for that person (or those people) to give an overview of the conference and present studies of interest for the lab. This type of meeting does not have a regular frequency.</p> <p>Once every two months, we meet to discuss new papers that came out recently. This is an occasion to discuss new topics, new methods, or just interesting work that you might have seen around. There is no fixed presenter, we will go over the list of papers one by one and the person who added it will introduce it. At any time, if you see an intersting paper you can add it to the reading list.</p>"},{"location":"outreach.html#schedule","title":"Schedule","text":"<p>Lab meetings usually happen once per week on Mondays, after lunch. On that day, we have lunch together in the meeting room and then move to the more science-y affairs.  The meeting room will be specified in a reminder email that is sent every Thursday before the lab meeting and can be seen in the meeting schedule. The schedule is made at the beginning of the academic year and consists of a mix of meetings with updates and others with more fixed topics.</p>"},{"location":"outreach.html#attendance","title":"Attendance","text":"<p>You can attend the meetings in person or online, there will be always a link to a Teams call. If you will be online, or absent, let the lab meeting manager know (as of August 2024, Filippo Cerpelloni). </p>"},{"location":"outreach.html#who-is-presenting","title":"Who is presenting","text":"<p>Each lab member is part of the standard rotation of presenters for the individual meetings. Additionally, they are assigned to one of the batches that will alternate in the quick updates. Interns are usually not part of the standard roations, but will be assigned to a batch. </p> <p>The rotation of presenters is made by randomizing the order of the names, but can be adjusted based on anyone's availability. If you want / need to switch your slot, you can directly contact the person you would like to switch with and then let the lab meeting manager know about the change. If you would like to change with a slot assigned for a group meeting, ask the lab meeting manager directly.  </p>"},{"location":"outreach.html#presentation-guidelines","title":"Presentation Guidelines","text":"<p>To keep our lab meeting presentations organized, please follow these guidelines:</p> <p>Naming Convention for Individual Lab Meetings</p> <p>Use the format: <code>YYYY-MM-DD_presenter_topic.pdf</code></p> <p>Example: <code>2024-08-24_andrea_dnns-in-vision.pdf</code></p>"},{"location":"outreach.html#storage-instructions","title":"Storage Instructions","text":"1-Slide UpdatesIndividual MeetingsNew Papers Meetings <ul> <li> <p>Before the meeting:    Store your slides in:   <pre><code>Hoplab &gt; Science outreach &gt; Lab meetings &gt; 1-slide updates\n</code></pre>   This allows all updates to be presented from one computer.</p> </li> <li> <p>After the meeting:   Move your presentation to:   <pre><code>Hoplab &gt; Science outreach &gt; Lab meetings &gt; Past LM presentations\n</code></pre></p> </li> </ul> <ul> <li>After the meeting:   Store your presentation in:   <pre><code>Hoplab &gt; Science outreach &gt; Lab meetings &gt; Past LM presentations\n</code></pre></li> </ul> <ul> <li>Before the meeting:   Add papers of interest to:   <pre><code>Hoplab &gt; Science outreach &gt; Lab meetings &gt; Papers\n</code></pre>   This allows lab members to review them before the meeting.</li> </ul>"},{"location":"outreach.html#useful-links","title":"Useful Links","text":"<ul> <li> <p> Meeting Schedule</p> <p>View the specific and updated schedule for lab meetings</p> <p> Open Schedule</p> </li> <li> <p> Presenters and Batches</p> <p>Check the list of presenters and batch divisions</p> <p> View List</p> </li> <li> <p> New Papers List</p> <p>Access the list of new papers to discuss in meetings</p> <p> Browse Papers</p> </li> </ul> <p>Access Required</p> <p>These files are located in the NeuroSPACE / Hoplab Team organizational folders. You need access to the Teams group to view them.</p>"},{"location":"outreach.html#conference-posters","title":"Conference Posters","text":""},{"location":"outreach.html#useful-resources","title":"Useful Resources","text":"<ul> <li> <p> Design Guidelines</p> <p>Learn best practices for creating effective academic posters</p> <p> View Guidelines</p> </li> <li> <p> Printing Services</p> <p>Information about university printing options</p> <p> Printing Services  Additional Info</p> </li> <li> <p> KU Leuven Templates</p> <p>Access official KU Leuven poster templates</p> <p> Browse Templates</p> </li> <li> <p> Printing Request Form</p> <p>Submit your poster for printing</p> <p> Open Form</p> </li> <li> <p> Tips and Tricks</p> <p>Learn do's and don'ts for creating effective posters</p> <p> Read Tips</p> </li> </ul>"},{"location":"outreach.html#poster-printing-request","title":"Poster Printing Request","text":"<p>To print your poster, submit a \"Large-format printing request\" using this form. Follow these steps:</p> <ol> <li> <p>Choose paper type:</p> <ul> <li><code>140gr</code>: Standard paper</li> <li><code>Glanzend</code>: Shiny version</li> <li><code>Canvas</code>: Foldable, thick canvas (good for travel)</li> </ul> </li> <li> <p>Select size and quantity</p> </li> <li> <p>Upload your PDF file</p> </li> <li> <p>Additional options:</p> <ul> <li>Poster tube requirement</li> <li>White border trimming</li> </ul> </li> <li> <p>Pick-up location</p> </li> <li> <p>Finalize request:</p> <ul> <li>Ask for an invoice</li> <li>Use An Van Kets' u-number (<code>u0057838</code>) when finalizing your request.</li> </ul> </li> </ol>"},{"location":"outreach.html#present-your-work-and-announce-it","title":"Present your work (and announce it)","text":""},{"location":"outreach.html#presentation-templates","title":"Presentation Templates","text":"<p>You can find KU Leuven PowerPoint and L<sup>a</sup>T<sub>e</sub>X templates for presentations here. </p> <p>Please consult this page to correctly use the official KU Leuven brand templates.</p>"},{"location":"outreach.html#lbp-social-media","title":"LBP social media","text":"<p>The Laboratory of Biological Psychology has its own  profile!</p> <p> @biolpsychol</p> <p>If you are active on :</p> <ul> <li>Tweet about your lab's and your own achievements</li> <li>Share conference presentations / posters</li> <li>Announce pre-prints and new papers</li> <li>Highlight any relevant scientific wins</li> </ul> <p>Tip</p> <p>Remember to tag @biolpsychol in your tweets, or DM LBP for a re-tweet to boost visibility!</p>"},{"location":"outreach.html#ppw-faculty-calendar","title":"PPW Faculty calendar","text":"<p>It's good practice to announce your PPW presentations in the faculty calendar. </p> <p>Typically, Kirsten Blommaerts coordinates B&amp;C level announcements. If she's unavailable, follow these steps:</p> <ol> <li>Go to the PPW faculty calendar</li> <li>Log in with your KU Leuven credentials</li> <li>Click \"Add new items (Dutch)\"</li> <li>Select the year of your presentation</li> <li>Click \"+ Nieuw\" &gt; \"Agenda-item\" </li> <li>Add your presentation details (title, abstract, time, location)</li> <li>Save your changes</li> </ol> <p>Note</p> <p>After submission, there's a brief moderation period before your announcement appears online.</p> <p>Having issues? Check the manual for help.</p>"},{"location":"outreach.html#example-announcements","title":"Example announcements","text":"<p>Below you can find an example announcement for a general seminar:</p> <p></p> <p>Below you can find an example announcement for a doctoral school presentation:</p> <p></p>"},{"location":"outreach.html#science-communication-scicomm","title":"Science communication (SciComm)","text":""},{"location":"outreach.html#reasons-to-start-engaging-in-scicomm","title":"Reasons to start engaging in SciComm","text":"<p>If you are already interested in science communication, that's great! If you need some more convincing, here are some good reasons to start engaging:</p> <ul> <li>It allows you to connect with other researchers and stakeholders, which can boost your motivation and lead to new collaborations.</li> <li>It helps you to develop skills relevant to your future career, such as public speaking, explaining complex concepts, writing and networking. </li> <li>Funders (like the KU Leuven, FWO and ERC) value SciComm efforts.</li> <li>You are funded by society, so it's crucial for the public to know about your research.</li> <li>Despite the fact that it can be stressful, it is also enjoyable and very rewarding!</li> </ul>"},{"location":"outreach.html#straightforward-ideas-for-scicomm-participation","title":"Straightforward ideas for SciComm participation","text":"<p>The easiest and most straightforward ideas to start participating in SciComm yourself are: </p> <ul> <li>Being active on social media (e.g., on X)</li> <li>Creating video abstracts for your paper and starting a Youtube channel</li> <li>Writing a press release if you have done newsworthy research (ask the KU Leuven press office for help) </li> <li>Writing and publishing a blog post about your research (e.g., on EOS blogs, see for example Klara's blog)</li> <li>Making a podcast about your research</li> </ul>"},{"location":"outreach.html#training-and-opportunities","title":"Training and opportunities","text":"<p>Check out the following sources if you want to train yourself:</p> <ul> <li>Visuals and slide design: Principiae. Jean-Luc Doumont is a great speaker and frequently gives workshops at KU Leuven on how to create effective slides, posters, presentations, etc.</li> <li>Pitching, writing and presenting: The Floor is Yours. They offer workshops and coaching on how to tell your story in a clear and convincing manner, can help you bring your research in the media or make policy impact.</li> <li>Crash course on SciComm: Let's Talk Science summer school. A must-do three-day event all about communicative competences.</li> <li>Infographics: Baryon. Company of Koen Van den Eeckhout (PhD in physics), who provides workshops on how to visually present complex data.</li> <li>All things SciComm: SciMingo. One of the driving forces of SciComm in Flanders. They are the driving force behind many initiatives, such as Science Figured Out, the Flemish PhD Cup and the Scicomm Academy (see below). They also offer lots of workshops (e.g., for podcasting).</li> <li>SciComm in the form of theater: ERLNMYR. Company of Ben Verhoeven (PhD in computational linguistics), who uses methods from improvisational theater to improve science communication.</li> <li>Science videos: Amazink. Company of Rob Zink (PhD in biomedical signal processing), who offers a variety of freelance visualization services.</li> </ul>"},{"location":"outreach.html#engaging-initiatives","title":"Engaging initiatives","text":"<p>If you can't wait to start engaging, check out the following initiatives:</p> <ul> <li>Science Figured Out (SciMingo) is a project in which you are coached to record a 3-minute pitch about your research. A professionally edited video is afterwards published on several social media channels. For example, check out Klara's video here.</li> <li>Dag van De Wetenschap is the biggest yearly science event in Flanders, to which you can participate with your research group and organize something fun!</li> <li>Kinderuniversiteit organizes yearly workshops for children to get acquainted with research.</li> <li>Science is Wonderful! gives primary and secondary school students the change to interact with EU-funded researchers in an engaging format.</li> <li>Falling Walls Lab is an international pitching competition for researchers (with coaching). The winner goes to Berlin!</li> <li>The Flemish PhD Cup is a competition for freshly promoted PhD'ers, including media training at VRT NWS. The winner gets a lot of media attention, can give a video lecture at the Universiteit van Vlaanderen and can publish a book.</li> <li>The Battle of the Scientists is a competition where you explain your research to children in schools.</li> <li>Nerdland Festival is the biggest science festival in Flanders hosted by Lieven Scheire, to which you can participate with cool ideas.</li> </ul> <p>(It should be mentioned that all credits for this section go to Klara's former colleague Simon Geirnaert!)</p>"},{"location":"get-started/index.html","title":"Welcome to HOPLAB","text":"<p>We are thrilled to have you join our team at HOPLAB, where we delve into the fascinating world of visual cognition and learning. Our lab is dedicated to exploring how the brain processes and interprets complex visual scenes, integrating insights from neuroscience, psychology, and computational science. As part of our team, you\u2019ll contribute to cutting-edge research that bridges human cognition with artificial intelligence. We look forward to your contributions and to working together on exciting discoveries.</p>"},{"location":"get-started/index.html#getting-started-at-hoplab","title":"Getting Started at HOPLAB","text":"<p>On this onboarding page, you'll find all the information you need to navigate the KU Leuven environment and adapt to our lab\u2019s practices. We\u2019ll guide you in setting up both your physical and digital workspaces, and offer step-by-step instructions for the most common administrative procedures at KU Leuven. Additionally, we\u2019ve curated a selection of resources to give you a strong foundation as you start your journey with us.</p>"},{"location":"get-started/index.html#quick-links","title":"Quick Links","text":"<p>To help you get settled quickly, here are some essential resources:</p> <ul> <li> <p> Setting Up Your Digital Workspace</p> <p>Get started with your computer, software installations, and network access.</p> <p> Computer Setup Guide</p> </li> <li> <p> Setting Up Your Physical Workspace</p> <p>Learn how to access the lab, get keys, and set up your office space.</p> <p> Practical Setup Guide</p> </li> <li> <p> Administrative Procedures</p> <p>Navigate the KU Leuven systems for HR tasks, reimbursements, leave requests, and more.</p> <p> Admin Procedures</p> </li> <li> <p> Mailing Lists</p> <p>Stay informed by subscribing to important lab and university mailing lists.</p> <p> Mailing Lists Guide</p> </li> <li> <p> Student Starter Pack</p> <p>Essential resources for students, including coding tutorials and academic writing tips.</p> <p> View Starter Pack</p> </li> <li> <p> Useful Links</p> <p>A curated list of links to university platforms, lab tools, and external resources.</p> <p> View Useful Links</p> </li> </ul>"},{"location":"get-started/index.html#need-help","title":"Need Help?","text":"<p>If you have any questions or run into issues while getting set up, the following resources are available:</p> <ul> <li>ICT Helpdesk: For technical issues related to your computer or network access. ICT FAQ</li> <li>HR Advisor: Find your HR advisor's details in your KU Loket profile.</li> <li>Lab Contact: For questions specific to lab operations, reach out to Ying Cai for assistance with equipment and orders.</li> </ul>"},{"location":"get-started/index.html#get-involved","title":"Get Involved","text":"<ul> <li>Visit the HopLab Website for information on our research projects, team members, and recent publications.</li> <li>Contribute to this Wiki: Your insights are valuable! If you spot missing information or have suggestions for improvement, please let us know.</li> </ul> <p>We hope this guide helps you settle into your new role. Dive in, and enjoy your journey with HOPLAB!</p> <p>TODO: [Klara] Add info on how/where to rent lab coats and how the laundry service works (e.g. for kitchen towels and EEG towels) TODO: [Klara] Add info on the remote work policy (of KU Leuven but also of the lab specifically) TODO: [Klara] Add info on how to find your phone number TODO: [Klara] Add safety and security info, such as emergency numbers and procedures, info on how to report technical defects (KU Loket / HSE &amp; Spaces / Reporting technical defects / New notification), where to find the first aid box, info on who the lab's first aid and EIP responsible is, info on shredding paper with sensitive information,... TODO: [Klara] Add PhD related info (milestones?) TODO: [Klara] Add page on how to deal with stress at work/psychosocial support in the lab or at KU Leuven TODO: [Klara] Make a list of office spaces and who can be found where TODO: [Klara] Specify how to encrypt your (external) hard drive TODO: [Klara] Explain how you can forward emails from your student mailing address to your professional mailing address (for PhD'ers)</p>"},{"location":"get-started/admin-procedures.html","title":"Admin 101","text":"<p>On this page, we will specify the procedures for the most common administrative procedures you might need to follow. If something is missing, please contact us so we can add it and keep this page up to date (and your lives easier).</p> <p>KU Loket is the university portal through which many administrative things are done. You can access it here.</p>"},{"location":"get-started/admin-procedures.html#consult-your-personnel-file","title":"Consult your personnel file","text":"<p>Log in to KU Loket and go to \"Personnel\", then click on \"My details\" (shown in red below):</p> <p></p> <p>At the very top of this page, you can find the name of your HR advisor (1). Your HR advisor offers you a listening ear, provides clarifying advice on HR-related matters and supports you with the administrative obligations that come along with employment at KU Leuven.</p> <p>Below, you can edit your personal details (2), such as adding a new private address, updating your family situation, adding emergency contacts or adding a new bank account number by clicking on the pencil in the top right corner of the corresponding section.</p> <p>Browse through the other tabs to find out and/or change information on communication means (3), insurances and other financial advantages you are entitled to (4), your contract details (5), mobility (e.g., to order a KU Leuven bike, get a refund for public transportation commuting costs, or to register your personal vehicle for work use) (6) and your curriculum at KU Leuven (7).</p> <p>Through your personnel file, you can also apply for teleworking allowances (for KU Leuven staff only) (8) and/or apply for a bicycle allowance if you bike (part of) your home-work journey (9). If you are financed by FWO, check out this page. If you are looking for information on the parking policy of KU Leuven, go here.</p>"},{"location":"get-started/admin-procedures.html#reimbursement-for-professional-expenses","title":"Reimbursement for professional expenses","text":"<ol> <li>Log in to KU Loket and go to \"Finance &amp; Purchasing\"</li> <li>Click on \"Professional expenses\" (shown in red below)</li> <li>Click on \"Forms\", create a \"+ New form\" and give it an informative name (e.g., congres X)</li> <li>Add all your expenses to the form (e.g., train tickets, dinner expenses, the registration fee)</li> <li>Link a digital proof to each expense</li> <li>Couple the appropriate financial antenna to your form (An Van Kets, u0057838)</li> <li>Add information on which fund your expenses should be paid from (ask  your PI)</li> </ol> <p>For more information, check out the available demo videos and/or read the FAQ. If you have specific questions concerning this procedure, contact An (an.vankets@kuleuven.be) or go find her in office 02.80.</p>"},{"location":"get-started/admin-procedures.html#register-personal-leave","title":"Register personal leave","text":"<p>There are a couple of things we usually do in the lab when we take a holiday:</p> <ol> <li>Notify Hans by sending an email with the subject \"Holiday\", to keep an official trace of your holiday request (that also helps him keep track of who\u2019s on leave).</li> <li>Mark the days you\u2019re off in the Hoplab Google calendar, so everyone is aware of your absence.</li> <li>Notify your employer, which can be different depending on your contract (the procedure below is for KU Leuven employees, for instance).</li> </ol>"},{"location":"get-started/admin-procedures.html#procedure-for-ku-leuven-employees","title":"Procedure for KU Leuven employees","text":"<p>The procedure for KU Leuven employees is as follows (If you are financed by FWO, check out this page). When you plan your holiday, you have to register this in KU Loket and get it approved. To do this, follow these steps:</p> <ol> <li>Log in to KU Loket and go to \"Personnel\"</li> <li>Navigate to \"My Leave\" and click on \"Requesting leave\"</li> <li>Click on a day and fill in the appropriate start and end date of your holiday period</li> <li>Click on the arrow, choose how many hours of each type of leave you are entitled to you want to use</li> <li>Submit your request to your approver</li> </ol> <p></p> <p>To register other kinds of personal leave (e.g., short-term or social leave or sick leave), check out the corresponding links. For further questions on this topic, browse to this page.</p>"},{"location":"get-started/admin-procedures.html#register-professional-leave","title":"Register professional leave","text":"<p>This has to be done (in advance) for absence in the context of any work-related event (national and international), such as a conference or the annual LBP retreat. This registration is needed in order to claim professional expenses made during this trip, to make sure you are correctly insured and to allow the KU Leuven to monitor the safety level of the trip.</p> <p>Proceed as follows:</p> <ol> <li>Log in to KU Loket and Go to \"Personnel\"</li> <li>Navigate to \"Register missions\" and click on \"New request\"</li> <li> <p>Fill out the required information on (amongst others):</p> <ul> <li>When you will be absent</li> <li>Where you will be</li> <li>How you will get there</li> <li>Why you are going</li> </ul> </li> <li> <p>Add the correct financial antenna to the form (An Van Kets, u0057838)</p> </li> <li>Submit the form</li> </ol> <p></p> <p>For more information, check out this page. If you are using your own vehicle for the trip, please make sure it is registered for insurance reasons. To do so, follow the steps on this page.</p>"},{"location":"get-started/admin-procedures.html#reserve-a-room-for-a-meeting","title":"Reserve a room for a meeting","text":"<p>In order to book a room, contact Ying. You can check which rooms are available yourself through KU Loket:</p> <ol> <li>Go to KU Loket, navigate to the tab \"HSE &amp; Spaces\" and click on \"Classroom reservations\" (Dutch only)</li> <li>Click \"Zoek op naam\" and enter <code>PSI</code> to find all the rooms in the building.</li> <li>Select the rooms that fit your needs</li> <li>Click \"toon reservaties\"</li> <li>Browse to the date &amp; time when you need the room</li> <li>Look for an available room and send this info to Ying</li> </ol> <p></p>"},{"location":"get-started/admin-procedures.html#reserve-equipment-or-a-room-for-testing","title":"Reserve equipment or a room for testing","text":"<p>The standard booking tool for testing rooms and equipment (testing booths, EEG caps, etc.) in our faculty is Clustermarket.</p> <ul> <li>To access Clustermarket you need to make a user account using an invitation link. This link decides to which infrastructure you have access to and is different for every research unit/group. For our group (B&amp;C Human), you can get the link by sending an email to Christophe Bossens (christophe.bossens@kuleuven.be).</li> <li>When you have access, choose the option to log in via your organization, so you can access it through the KU Leuven login tool.</li> <li>Make sure to use Clustermarket to book your testing time slots when you use common rooms or material. Request access to the items you don\u2019t have permission to in case you need it. You can find more information on how to use Clustermarket in this presentation.</li> <li>The faculty also has their own MS Teams <code>GHUM PPW - Research rooms and equipment</code> where you can find more detailed information on the available research infrastructure as well as a manual on how to book infrastructure with Clustermarket (for more info, check out this page).</li> </ul>"},{"location":"get-started/admin-procedures.html#order-stuff","title":"Order stuff","text":"<p>Please contact Ying for assistance with arranging and/or ordering and/or paying for the following things:</p> <ul> <li>Hotel reservations</li> <li>Flight bookings</li> <li>Online purchases</li> <li>Computer equipment</li> <li>Physical mail and packages (post)</li> </ul> <p>General orders (e.g., milk, coffee, office material) are also handled by Ying. In case of bigger purchases, make sure to include the financial antenna (An Van Kets) in the process.</p> <p>The IT department handles orders related to computer supplies (ppw.dict@kuleuven.be). All computer equipment needs to be bought through the official university providers by the financial antenna An Van Kets). Therefore, when computer supplies need to be bought, make sure to contact them both. It can also be useful to include Ying in CC in that case.</p> <p>If you need technical assistance for your order (e.g., you want to order an EEG-cap), you can contact Klara or send an email to neurospace@kuleuven.be (general mailing address to reach the support staff of the Methusalem project).</p>"},{"location":"get-started/admin-procedures.html#arrange-a-parking-spot-for-a-visitor","title":"Arrange a parking spot for a visitor","text":"<ul> <li>If you need to arrange parking for a visitor in the city center, you can do so by requesting a day code for the visitor to operate the barriers of the KU Leuven personnel parkings. For more information, check out this page. It is worth noting that the car park underneath the Herman Servotte Residence located on the Social Sciences campus (Parkstraat 39-53, 3000 Leuven) can be accessed outside of working hours (18h-24h) and during holidays with your staff card.</li> <li>Parking spots at the university hospital (UZ Leuven campus Gasthuisberg) can be refunded in the form of a parking ticket that visitors can use to pay their parking fee. We can buy these tickets (in batches) in advance, so make sure to check beforehand with Klara (from December 2024 on, if you need them beforehand, ask Andrea/Joan) if we have tickets left or not. New tickets can be ordered by Ying.</li> </ul>"},{"location":"get-started/admin-procedures.html#what-to-do-when-you-leave","title":"What to do when you leave","text":"<p>We are very sad to see you leave! But since you do, make sure to tick the following boxes.</p> <ol> <li> <p>Return the following items to Ying:</p> <ul> <li>Any pc material (laptop, mouse, keyboard, etc.)</li> <li>Your external hard drive (and potential USB-key)</li> <li>Your key(card)</li> <li>Your Lync phone</li> </ul> </li> <li> <p>Make sure your data is organized and backed up correctly. That mostly means having back-ups in different locations and different ways. If you need advice on this, refer to the person in charge of data storage (as of December 2024, that is Klara).</p> </li> <li>For more information on what to do when you leave, check out this link for ICT-related info, this link for HR-related info and this link if you are an international researcher leaving Belgium.</li> </ol>"},{"location":"get-started/computer-setup.html","title":"Setting up your digital working environment","text":"<p>Please read the Welcome to ICT@PPW three-pager to get up and running with IT at our faculty. In case of ICT-related problems, make sure to check the FAQ page of PPW Dienst ICT here.</p>"},{"location":"get-started/computer-setup.html#using-a-computer-managed-by-the-university","title":"Using a computer managed by the university","text":"<p>Faculty issued computers can be recognized by their name starting with GHUM. To set you up, follow these steps:</p> <ol> <li>Login:<ul> <li>You can log in to faculty issued computers with your intranet account.</li> <li>Use your u-number (or r-number in case you are a student) and the password of your e-mail address to do so.</li> </ul> </li> <li>Internet access:<ul> <li>To access the university's wireless network, look for campusroam in the list of available networks. This network offers the broadest access to faculty resources but only accepts u-numbers. When asked to authenticate, enter your u-number followed by @kuleuven.be and your intranet password. If you have an r-number, you can connect to the eduroam network, but this network does not allow access to PPW faculty file shares or printers.</li> <li>To gain access to the wired network in the PPW-buildings, get your network outlet activated by completing this form (in case it is not pre-activated).</li> </ul> </li> <li>Administrator access:<ul> <li>If you are not already, contact dICT (dict@ppw.kuleuven.be) to make you administrator for the computer you are going to work on. You need to provide them the hostname of your pc (GHUM-\u2026) and your u-number.</li> <li>Alternatively, if someone else is already administrator, ask them to add you (Windows control panel &gt; Change account type &gt; Add &gt; Add a new LUNA account).</li> </ul> </li> <li>Multifactor authentication:<ul> <li>To access KU Leuven intranet pages, you will need to log in with KU Leuven Authenticator. You can register your device with a smartphone or tablet via the KU Leuven Authenticator App (read the instructions).</li> <li>If you are having issues with MFA, check this FAQ page.</li> </ul> </li> </ol> Where do I find the hostname of my pc? <p>The hostname is usually printed on a sticker on the computer. If not, go to Start, right click on \"This PC\", choose properties, and check the \"Device name\" field.</p>"},{"location":"get-started/computer-setup.html#installing-matlab","title":"Installing MATLAB","text":"<p>The installation process differs for students and personnel. Please follow the instructions in the appropriate tab below:</p> StudentsPersonnel <ol> <li>Register on the MathWorks website using your KU Leuven student email address.</li> <li>After registering, download the software directly from the MathWorks website.</li> </ol> <ol> <li> <p>Choose the appropriate MATLAB license:</p> <ul> <li> <p>Individual License: Recommended for most users. This license allows you to use MATLAB on multiple computers (up to 2 simultaneously) and includes access to MATLAB desktop software and online services (e.g., MATLAB Online, Add-Ons, and MATLAB online training). This option in suited for individual personnel.</p> </li> <li> <p>Designated Computer License: Use this license if MATLAB is to be installed on a computer that is permanently offline or where users cannot log in under their own account. It allows any number of users to access MATLAB on that specific computer, though not simultaneously. This option is generally suited for lab/shared computers.</p> </li> </ul> <p>The license fee can be covered using individual professional funding sources (e.g., bench fees, grant money, etc.), depending on your contractual situation. For more details, please discuss with your PI.</p> Transition to \u2018Individual License <p>The old '5pack' license will no longer be available after October 31, 2024. To continue using MATLAB, users must switch to an 'Individual License' or 'Designated Computer License'. It is recommended to remove any older versions of MATLAB and install the most recent version as an 'Individual License' user. For newer versions (from R2023b onwards), you can easily switch licenses by placing a new license file. Detailed instructions are available here.</p> </li> <li> <p>Download MATLAB:</p> <ul> <li>Get the MATLAB installation files from the ICTS License Catalogue.</li> <li>Follow the instructions to download the installer for your operating system.</li> </ul> </li> <li> <p>Install and activate MATLAB:</p> <ul> <li>Run the MATLAB installer and follow the on-screen instructions.</li> <li>During the activation process, select \"Individual License\" and log in with your MathWorks account.</li> <li>Input the license key provided through the ICTS License Catalogue when prompted.</li> </ul> </li> </ol> Updating Your PC Registration <p>To change your registered computer name or IP address:</p> <ol> <li>Go to https://icts.kuleuven.be/apps/license</li> <li>Click the pencil icon under \"register your PC\"</li> <li>Update your hostname and IP address as needed</li> </ol>"},{"location":"get-started/computer-setup.html#frequently-used-software","title":"Frequently used software","text":"<p>Here are some software programs we frequently use in the lab, which you might find useful to download:</p> <ul> <li> <p>Google Calendar: Make sure you have writing access to the lab's Google calendar (ask the person in charge of this, as of today, that is Andrea).</p> </li> <li> <p>TeamViewer: For remote access to a desktop PC, e.g. the fMRI PC to run your analyses.</p> TeamViewer Setup Guide <ol> <li>Download the free private version from the official website.</li> <li>Create an account:<ul> <li>Open TeamViewer and click \"Sign Up\".</li> <li>Enter your email, name, and a strong password.</li> <li>Verify your email address.</li> </ul> </li> <li>Add a computer:<ul> <li>Sign in and go to \"Computers &amp; Contacts\".</li> <li>Click \"Add Computer\".</li> <li>Name the computer (e.g., \"Lab Desktop\").</li> <li>Click \"Add\" to save.</li> </ul> </li> <li>Connect:<ul> <li>Open TeamViewer and log in.</li> <li>Find the computer in your list.</li> <li>Double-click to connect.</li> <li>Enter the remote computer's password when prompted.</li> </ul> </li> </ol> </li> <li> <p>AnyDesk: A good alternative if TeamViewer is inaccessible. Install the free private version. It is advisable to install and configure both TeamViewer and AnyDesk to avoid being locked out if one of them is not accessible.</p> </li> <li> <p>Google Chrome: This is the preferred web browser. For example, the MR calendar is only compatible with this browser.</p> </li> <li> <p>Slack: Slack is used for communication within the lab. Ask any lab member to add you to the relevant channels.</p> </li> <li> <p>Skype for business and Microsoft Teams: KU Leuven offers both Skype for business and MS Teams for communication purposes. See this table for a comparison between the different platforms. Currently, MS Teams is the newer and preferred option, however, it only allows its users to reach other MS Teams users. With MS Teams, it is currently not possible to call (or be called by) telephone numbers (landline and mobile). You can use Skype for this.</p> </li> <li> <p>SSL VPN Pulse Client / Ivanti Secure Access Client: The VPN offered by the university. For more information, check out this link.</p> </li> <li> <p>Overleaf: An online L<sup>a</sup>T<sub>e</sub>X editor for collaborative writing and publishing.</p> Why use Overleaf? <p>Overleaf is a powerful tool for academic writing, especially for scientific papers and theses. Here's why it's important:</p> <ol> <li>L<sup>a</sup>T<sub>e</sub>X-based: Produces high-quality, professional-looking documents with complex equations and formatting.</li> <li>Collaboration: Real-time collaboration with co-authors, similar to Google Docs.</li> <li>Version control: Tracks changes and allows reverting to previous versions.</li> <li>Journal templates: Many journals provide L<sup>a</sup>T<sub>e</sub>X templates that can be directly used in Overleaf, streamlining the submission process.</li> <li>Integration: Works with reference managers like Mendeley and Zotero.</li> <li>Accessibility: Web-based, so you can work from any computer without installing software.</li> </ol> <p>While L<sup>a</sup>T<sub>e</sub>X has a learning curve, investing time in learning it can significantly improve your academic writing workflow and the quality of your documents.</p> </li> </ul> <p>Administrative privileges on KU Leuven PCs</p> <p>In case you have issues installing software (e.g., because of lack of administrator access), you can double click the \"Make Me Admin\" icon on your Windows desktop and follow the instructions to get temporary administrator rights on your computer. Additionally, make sure to install the software in <code>C:\\Workdir\\MyApps\\</code>. Please contact the ICT helpdesk if problems persist.</p>"},{"location":"get-started/computer-setup.html#data-storage","title":"Data storage","text":"<p>All KU Leuven staff and students have their own OneDrive environment with 2 TB of online storage space to store personal work files. The files on OneDrive are synced to a folder on your local device (Windows Explorer), but can be accessed from various devices from any location. It is also possible to share documents with someone else and work together on the same document.</p> <p>Back up your data twice</p> <p>Keep your data in one main folder (folder name = your first name) if you are an intern, or on your PC if you are personnel, and back-up this data to:</p> <ol> <li>A portable hard drive (shared between interns, or ask Ying if you are personnel). Don\u2019t forget to give the external drives back to your supervisor when your role ends.</li> <li>Your online OneDrive folder. To get started with OneDrive, check out this page.</li> </ol>"},{"location":"get-started/computer-setup.html#printing","title":"Printing","text":"<p>Find info on how to install printing services on your computer here. The printer names are:</p> <ul> <li>PRLBP (Black &amp; White printer)</li> <li>PRLBP2 (Color printer)</li> </ul> <p>If the installation doesn\u2019t work, use a USB key to print on the black and white printer in room 02.28. You can also get permanent access by asking Ying to add you to the list of users.</p> <p>For mac users, follow the instructions on this page to print from your personal computer. More generally, this manual tries to give an overview of most frequently asked questions concerning configuration and initial setup of a secure work environment on Mac OS X.</p>"},{"location":"get-started/mailing-lists.html","title":"Some useful mailing lists","text":"<p>If you just got started in the lab, you might want to make sure you're added on all of the relevant mailing lists that we often use or refer to.</p> The essentialThe recommendedThe optional <p>Here are the mailing lists you need to be subscribed to.</p> <ol> <li>The LBP mailing list (PSYLBP@LS.KULEUVEN.BE). The most important mailing list administratively. Any first-hand administrative communication will go through there, including building-, retreat-, and kitchen-related information. You will need to find the LBP technician (as of August 2024, this is Ying Cai) and ask to be registered. Use this email when you need to communicate something at the LBP level.</li> <li>The HopLab group email (hop_lab@googlegroups.com). Many important communications are made lab-wise through it. Most importantly, lab meeting details are sent through there, alongside all of the communication that cannot be made via chat. Use this email to send something to the lab that is not more easily shared on our chat platform (Slack), or to forward important emails. Ask the lab website responsible person (as of January 2022, that is Tim, from December 2024 on, this will be Klara) to add you.</li> <li>The NeuroSPACE mailing list (NEUROSPACEMEMBERS@LS.KULEUVEN.BE). This is a mailing list containing all members of the teams of profs. Hans Op de Beeck (HOPLAB), Bert De Smedt (MATHLAB), C\u00e9line Gillebert (Neuropsychology Lab Leuven) &amp; Kobe Desender (DesenderLab), which was created in the context of the Methusalem grant uniting all four research groups. Ask the scientific support staff working on this project to add you to this list (Klara / Silke). </li> </ol> <ol> <li>The LBI newsletter (register through this website) communicates any event the Leuven Brain Institute organises. This is mostly important to stay updated on things like the annual LBI scientific meeting, but also interesting science communication events.</li> <li>The BAPS newsletter (register on their main page) can be of relevance for Belgium-wise psychological science events &amp; news. For instance, the yearly BAPS meeting will be shared through this channel.</li> <li>The MRI mailing list (MRI@LS.KULEUVEN.BE) will report any news concerning the MR8 scanner at the hospital. If you scan or plan on scanning, this is a must. It will tell you if the scanner breaks down, if there are any new guidelines to follow, or more commonly, if any booked timeslot is cancelled. This is a KU Leuven-based mailing list, which you can register to on this website.</li> </ol> <ol> <li>The visionlist is the main community-wide newsletter for vision sciences. Any opening position, conference, summer school you might be interest in will be on there (more info here).</li> <li>The CVnet mailing list communicates about everything colour and vision-related. Conferences, positions, community news will be posted on there (more info here).</li> <li>If you're a PhD student, the Doctoral school mailing list (ppw.doctoraten@kuleuven.be) can be useful to you. You can find it on the KU Leuven mailing list server. </li> </ol>"},{"location":"get-started/practical-setup.html","title":"Setting up your real life workspace","text":""},{"location":"get-started/practical-setup.html#keys","title":"Keys","text":"<p>Ask the LBP lab technician (As of August 2024, this is Ying Cai), whom you can find in room 02.37, for the key to your new office.</p>"},{"location":"get-started/practical-setup.html#staff-card","title":"Staff card","text":"<p>The staff card (different from the student card if you\u2019re an intern or a PhD researcher) can be used to access the PSI building at all time. Just badge it on the card reader at the main entrance (Tiensestraat 102) when you need access outside of working hours. You will receive it by mail in the first weeks of your contract.</p>"},{"location":"get-started/practical-setup.html#office-set-up","title":"Office set-up","text":"<p>For each new member, a laptop and other pc material (e.g., an external hard drive, computer screen, mouse, keyboard, etc.) will be ordered or be made available. If you are missing something or need something specific, please contact Ying before ordering anything new.</p>"},{"location":"get-started/practical-setup.html#phone","title":"Phone","text":"<p>If you need to call or be called by external numbers, Skype for business can be used and also has a voicemail system associated to it. For good quality calls, you can use a headset, forward the calls to your personal phone number or opt for an old-school stationary phone linked to your Skype for business account (e.g., if you need to make a lot of calls and you only want to be reachable from your desk). You can get a phone from Ying. If you do, make sure you submit the serial number here.</p>"},{"location":"get-started/student-starter-pack.html","title":"Student starter pack","text":"<p>If you're a student newly starting in the lab, this page is made for you. It is packed with resources and knowledge that you will find useful during your time with us. Enjoy!</p> <p>The starter pack is divided into three sections. In no order of importance, you will find important papers from authors we might refer to every once in a while, coding tutorials to get up to speed with Python and develop your programming skills, and miscellaneous resources that don't fit in these two categories but are still relevant.</p>"},{"location":"get-started/student-starter-pack.html#coding-tutorials","title":"Coding tutorials","text":"<p>Developing strong coding skills is crucial for success in our lab. Here are some excellent resources to help you improve your Python programming and data science skills:</p> <ol> <li> <p> The Good Research Code Handbook: This is a must-read for anyone joining the lab. It covers essential knowledge on how to structure and write your code in research, suitable for both beginners and experienced researchers.</p> </li> <li> <p>You can find some fun and interactive Python tutorials on DataCamp and Codecademy.</p> </li> <li> <p>Software Carpentry Python Fundamentals: Basic Python concepts for beginners.</p> </li> <li> <p>EdX: Using Python for Research: Free course on Python applications in research.</p> </li> <li> <p>Scientific Python Lectures: Advanced course for confident programmers.</p> </li> <li> <p>Python Data Science Handbook: Comprehensive guide to data science with Python.</p> </li> <li> <p>If you know nothing about it, take some time to learn the Unix Shell and the essentials of Git &amp; GitHub.</p> </li> </ol>"},{"location":"get-started/student-starter-pack.html#miscellaneous","title":"Miscellaneous","text":"<ul> <li> <p> Academic Writing</p> <p>Learning how to write is fundamental to academic training. If you're struggling with writing or structuring your papers, check out:</p> <p> Ten Simple Rules for Structuring Papers</p> </li> <li> <p> Machine Learning Fundamentals</p> <p>To understand the basics of machine learning and modeling, this Coursera class is a must:</p> <p> Machine Learning Specialization</p> </li> <li> <p> Awesome PhD Resources</p> <p>A curated list of carefully selected tools and resources for both early career and senior researchers:</p> <p> Awesome PhD Repository</p> </li> <li> <p> Awesome Neuroscience Resources</p> <p>Curated list of awesome neuroscience libraries, software and any content related to the domain.</p> <p> Awesome Neuroscience Repository</p> </li> </ul>"},{"location":"get-started/student-starter-pack.html#papers-lectures","title":"Papers &amp; lectures","text":"<p>This section contains some foundational papers to give you some background on the research going on in the lab, as well as interesting lectures if you can't find anything to watch on Netflix. This list might not always be up to date, but you can find our latest publications on the lab website.</p> Some reviewsClassic papersfMRI studies we refer toDNN papersLectures <p>Bracci &amp; Op de Beeck 2023</p> <p>Grill-Spector and Weiner 2014</p> <p>DiCarlo et al 2012</p> <p>Kravitz et al 2013</p> <ul> <li> <p>The classic publication by Felleman &amp; Van Essen 1991 covers the intricate pattern of connectivity that characterises the ventral stream and the visual system in general. </p> </li> <li> <p>This publication by Roger Shepard 1980 is a pioneer in the development of multivariate analyses.</p> </li> </ul> <ul> <li> <p>The study by Bracci et al. 2016 is a good illustration of how we use carefully crafted stimulus sets in combination with multivariate fMRI to answer questions about visual representations in the brain.</p> </li> <li> <p>The foundational paper by Kriegeskorte et al 2008 introduced the use of representational similarity analysis (RSA) to compare representations across brains, species, models and more.</p> </li> </ul> <ul> <li> <p>If you feel like DNNs and brains are a great match, check out this reading list by Anna Wolff and Martin Hebart.</p> </li> <li> <p>The fundamental papers of Yamins et al and Khaligh-Razavi &amp; Kriegeskorte both published in 2014 showed for the first time that DNNs develop similar representations to the brain.</p> </li> <li> <p>Among the very often citer papers is the publication by Geirhos et al 2022 which showed that DNNs are biased towards texture.</p> </li> <li> <p>Opinions diverge on how to use modelling to further our understanding of the brain. This 2023 BBS paper by Bowers et al surely started a serious discussion on that topic.</p> </li> </ul> <ul> <li>A visual and intuitive understanding of deep learning is a great lecture to begin with if you feel like convolutional neural networks are still obscure to you.</li> </ul>"},{"location":"get-started/useful-links.html","title":"Useful links when getting started","text":"<p>Luckily, you have found the most useful link of all, i.e., the link to this Wiki! Besides this, there are some other links worth checking out.</p> <p>Info</p> <p>In the Wiki, we frequently will refer you to shared documents in the lab's MS Teams folder, which you can find here.</p>"},{"location":"get-started/useful-links.html#getting-started-at-ku-leuven","title":"Getting started at KU Leuven","text":"<ul> <li> <p> First Steps</p> <p>For information on the first administrative steps upon arrival for international students/staff</p> <p> Link</p> </li> <li> <p> Orientation Days</p> <p>For information on welcome activities (KU Leuven Orientation Days) specifically aimed for new international students/staff</p> <p> Link</p> </li> <li> <p> My KU Leuven</p> <p>For all administrative tasks and more</p> <p> Link</p> </li> <li> <p> KU Loket</p> <p>For accessing a wide range of university services and resources</p> <p> Link</p> </li> <li> <p> Toledo</p> <p>For all course-related things</p> <p> Link</p> </li> <li> <p> Filesender</p> <p>For safely transferring large files</p> <p> Link</p> </li> </ul>"},{"location":"get-started/useful-links.html#getting-started-at-hoplab","title":"Getting started at Hoplab","text":"<p>Apart from this Wiki, we try to keep the HopLab website up to date, and that includes new people. Send a picture of yourself and a short introductory text (see the members page for inspiration) to the person in charge of the Lab website (as of January 2022, this is Tim, from December 2024 on, this will be Klara) along with useful links if wanted (ORCID, LinkedIn, Scholar, Twitter,\u2026).</p> What is ORCID? <p>ORCID is a unique digital identifier system for researchers, used by most journals during paper submission. To create your ORCID ID, go here, select \"Sign In/Register\", choose \"Access through your institution\" and select \"KU Leuven Association\". Follow the site's instructions. For assistance, check out their support page.</p>"},{"location":"research/index.html","title":"Research at the Hoplab","text":"<p>Welcome to the central hub for all research activities at the Hoplab. This page serves as your gateway to our research methodologies, data analysis procedures, and resources. Whether you're involved in behavioral studies, EEG, eye-tracking, or fMRI, you'll find the essential guidelines and workflows here.</p> <ul> <li> <p> Behavioral Research</p> <p>Explore our experimental setups, participant management, and best practices for conducting behavioral research.</p> <p> Learn more</p> </li> <li> <p> Coding Resources</p> <p>Access coding guides, scripts, and resources for various research tools, including fMRI and behavioral experiments.</p> <p> View coding resources</p> </li> <li> <p> Deep Neural Networks (DNN)</p> <p>Dive into our research on deep neural networks and their application in cognitive and neuroscience research.</p> <p> Explore DNN research</p> </li> <li> <p> EEG Studies</p> <p>Find protocols, analysis workflows, and tips for conducting and analyzing EEG studies in the lab.</p> <p> Access EEG resources</p> </li> <li> <p> Ethics and Approvals</p> <p>Get guidance on the ethical procedures and approval processes required for research in our lab.</p> <p> Review ethical guidelines</p> </li> <li> <p> Eye-tracking Research</p> <p>Learn about our setup and analysis techniques for eye-tracking experiments, including equipment calibration and data processing.</p> <p> Discover eye-tracking methods</p> </li> <li> <p> Functional MRI (fMRI)</p> <p>Find everything from fMRI scan setup to data analysis workflows and coding resources.</p> <p> fMRI resources</p> </li> </ul>"},{"location":"research/index.html#quick-links-to-resources","title":"Quick Links to Resources","text":"<p>Here are some additional links to key research resources, tutorials, and tools:</p> <ul> <li>SPM Software Guide</li> <li>EEGLAB Documentation</li> <li>Nilearn for Machine Learning in Neuroimaging</li> <li>BIDS Specification for Neuroimaging</li> <li>MNE Python for EEG Analysis</li> </ul> <p>TODO: [Klara?] Add information on room booking, in particular ClusterMarket.</p> <p>TODO: [Klara] Add more recommended software (e.g., Mendeley/Endnote, R, Text editors, Image editing software, Git, LaTeX, Pandoc, markdown, Python, Overleaf, RBA, BioSemi, PsychoPy, the lab\u2019s own software?)</p> <p>TODO: [Klara] Add info on interesting conferences to attend, suggested reading (books, papers, websites), suggested courses (soft skills, programming, EEG/fMRI, version control, stats, science, etc.)</p> <p>TODO: [Klara] Add links to nice data visualisation tools and (AI) tools to find papers</p> <p>TODO: [Klara] Add info on existing focus groups (e.g., EEG, MRI) which people can attend</p> <p>TODO: [Klara] Make list of hardware available in/to the lab</p> <p>TODO: [Klara] Explain how Lirias works/what it is used for</p> <p>TODO: [Klara] Explain how to download papers from home</p> <p>TODO: [Klara] Add context for the stuff on OSF and Github (touch on topics as open science, reproducibility)</p> <p>TODO: [Klara] Add (general) info on how to store your data (eg BIDS) \u2192 this is in the fmri section for now. perhaps we can link it?</p> <p>TODO: [Klara] Refer to the resources for researchers on this page</p>"},{"location":"research/behaviour/index.html","title":"Behavioural Research","text":"<p>Our lab focuses on understanding human behaviour through controlled experiments, from recruitment and experimental setup to data collection and analysis. This section will guide you through the key aspects of running behavioural studies in our lab, offering resources and step-by-step guides to ensure your research is carried out smoothly.</p> <p>Here, you\u2019ll find everything you need for setting up experiments, recruiting participants, and ensuring compliance with ethical guidelines. Use the quick links below to dive into specific topics or read through the guides to get a comprehensive understanding of our procedures.</p> <p>We hope this section helps you conduct your behavioural research with ease and precision. Happy researching!</p> <ul> <li> <p> Experimental Setup</p> <p>Learn how to prepare your experimental environment, including online and in-person setups.</p> <p> View Experimental Setup Guide</p> </li> <li> <p> Participant Recruitment</p> <p>Find detailed information on recruiting participants, using the EMS system, and managing consent.</p> <p> Participant Recruitment Guide</p> </li> <li> <p> Ethics Approval</p> <p>Ensure your study complies with KU Leuven's ethical standards and obtain necessary approvals.</p> <p> Ethics Guide</p> </li> <li> <p> Reimbursement &amp; Compensation</p> <p>Guidance on compensating participants, including credit and payment processes.</p> <p> Reimbursements Guide</p> </li> </ul>"},{"location":"research/behaviour/experimental-setup.html","title":"Index","text":"<p>TODO: Add info on how to set-up an (online) experiment </p>"},{"location":"research/behaviour/participants.html","title":"Participant recruitment","text":"<p>TODO: Check whether this info is still up to date today (info dates from 09/2022, I don't have a researcher account unfortunately)</p> <p>TODO: Add info on how to recruit other types of participants (e.g., elderly, patients, children, experts, etc.)</p> <p>Before starting participant recruitment, ensure your study is formally approved by the ethical committee (if you didn't do this yet, check out this page). Prepare this well in advance. All recruitment materials (e.g., flyers, posters) must include the study's end date as specified in the ethics application.</p> <p>(Healthy young-adult) participants can be recruited in different ways:</p> <ol> <li> <p>Through the laboratory's participant database:</p> <ul> <li>Including previous participants and individuals who have expressed interest in participating through word-of-mouth referrals TODO: check whether this formally exists and if yes, where</li> </ul> </li> <li> <p>Through social connections of the researchers involved and/or by sharing your announcement via social media:</p> <ul> <li>For example, announce your experiment on this facebook page, which collects the latest info on psychological experiments at KU Leuven</li> <li>Make sure to read the guidelines on recruiting participants via social media provided by the ethical committee that approved your study (guidelines SMEC, guidelines EC onderzoek)</li> </ul> </li> <li> <p>Through the online recruitment system of the faculty (see below)</p> </li> </ol>"},{"location":"research/behaviour/participants.html#recruitment-through-the-facultys-online-recruitment-system","title":"Recruitment through the faculty's online recruitment system","text":"<p>The Experiment Management System (EMS) of the faculty is an online platform used to facilitate the management of experimental research and the recruitment of participants. As it is managed by Sona Systems, it is often referred to with this name as well. It can be accessed through this link. Here is some general info about the system:</p> <ul> <li>The EMS can be used to schedule the experiment, set time slots, and easily manage the availability of participants. It can also facilitate communication between researchers and participants, such as sending reminders for scheduled experiments or sharing important information. The system provides a clear overview of available experiments, the status of participation, and accredited course credits.</li> <li>All first-year psychology students can participate in experimental research by signing up through the EMS as part of their research methods course (typically between mid October and the end of May and in July).</li> <li>A credit system is used in which they can earn course credits (18 research participation points) by participating in collective (max. 12 points) and/or individual testing sessions.</li> <li>Students can also opt to do an alternative assignment to earn 2 course credits (i.e., writing a 1-2 page description of the participant experience from the methods section of a recent empirical paper). In this way, students can earn the same course credits as they would for participating in an experiment. This option is provided to ensure voluntariness of participation at all times.</li> <li>In addition, both students and non-students can sign up through the EMS for paid studies throughout the entire year.</li> </ul> <p>PPW-affiliated researchers (you!) can offer their (on-site as well as online) experiments on the platform through a researcher account:</p> <ul> <li>To request such an account, send an email to ioco@kuleuven.be, and provide the following information: [firstname], [lastname], [u-number]@kuleuven.be, [firstname].[lastname]@kuleuven.be).</li> <li>Master's thesis students supervised by PPW staff are also allowed to access the participant pool, but supervisors need to request an account on their behalf.</li> <li>Participants can create an account themselves by following the instructions on the website of the EMS.</li> </ul> <p>If you or your participants have any questions or problems related to the EMS, please check out these Youtube tutorials (for participants, for researchers) and/or rely on peer support (fellow students/researchers) before addressing the system administrator at ioco@kuleuven.be.  </p> <p>Recruitment Bias</p> <p>It is important to consider potential recruitment biases when using the EMS. Since the pool primarily draws from university students, particularly first-year psychology students, the sample may not be fully representative of the general population. Additionally, there is often a higher proportion of female students in our faculty, which can introduce gender bias into the research findings. You should take this into account when designing studies and interpreting results when drawing from this participant pool.</p>"},{"location":"research/behaviour/participants.html#create-a-new-experiment-on-the-platform","title":"Create a new experiment on the platform","text":"<p>As students rely on these experiments to collect the necessary research participation points for their research methods course (pass/fall evaluation, 1 ECTS), make sure to think about inclusivity and accessibility. Always specify whether the study location is wheelchair accessible and if students with disabilities can participate (e.g., motor, visual impairments).</p> <p>To add a new study, provide the following information (for more detailed explanations, please watch this):</p> <ol> <li>Study type: In case the experiment is online only, choose \"Online External Study\"</li> <li>Choose between a paid or credit study (in case both are options, \"credit\" must be selected)</li> <li> <p>Study information:</p> <ul> <li>Study name: Include the type of compensation in the title</li> <li>Brief abstract</li> <li>Detailed description</li> <li>Eligibility requirements: Can be linked to the pre-screen participants fill out when signing up</li> <li>Session duration</li> <li>Credits: The total credit cap (= a technical matter on PI basis) can be set at 999 (if this is reached, email Tom Beckers to increase it)</li> <li>Preparation: What to bring and/or how to prepare</li> <li>Researcher &amp; PI details</li> <li>SMEC or EC approval number and expiration date</li> <li>Approval status: The study needs to be approved by the system administrator when it's added</li> <li>Activity status: Switch to inactive when you are not actively recruiting, toggle back when you resume</li> </ul> </li> <li> <p>Advanced settings (optional):</p> <ul> <li>Pre-requisite and disqualifier studies</li> <li>Course restrictions, select either</li> <li>Payed volunteer (\"betaalde vrijwilliger\"), to make sure participants expect payment, or</li> <li>The ongoing methods course, to make sure participants expect course credit.</li> <li>Age restrictions</li> <li>Be careful with restrictions, think about inclusivity (be as inclusive as possible)</li> <li>Ensure first-years are eligible by putting the lower age limit at 16 in the ethical dossier</li> <li>Study invitation code</li> <li>Study URL in case of web-based studies</li> <li>Participant sign-up and cancellation deadlines</li> <li>The cancellation deadline must have at least the same duration as the sign-up deadline</li> <li>You cannot cancel participation before you sign up</li> <li>Enable automated e-mails</li> <li>Assign timeslots to a specific researcher</li> <li>Automatic credit granting</li> <li>Frequency of participation</li> <li>Shared and private comments</li> </ul> </li> <li> <p>Add timeslots for your experiment: For online studies, the timeslot is the participation deadline</p> </li> </ol> <p>Make sure to prepare your study carefully before asking for EMS approval, as some changes will require re-approval. To ask for approval, click the \"asking approval\" button. You can start preparing your study in EMS before obtaining ethics approval, but you cannot request EMS approval until you obtain formal ethical approval. Once the latter is obtained, approval in EMS will take 10 days at the very most (usually less than a few days; sending a polite reminder after a few days is fine).</p> <p>Tip</p> <p>The Sona Mobile app can be used to facilitate experiment scheduling (by adding/removing time slots as needed), but not to set up your study.</p>"},{"location":"research/behaviour/participants.html#collective-testing-sessions","title":"Collective testing sessions","text":"<ul> <li>Students can earn up to 12 research participation credits per academic year by participating in collective testing sessions.</li> <li>For such sessions, researchers have to make all necessary arrangements themselves (e.g., rooms, equipment, setting up the study in the EMS, credit granting).</li> <li>In the EMS, you can create collective sessions by allowing multiple participants to access the same time slot.</li> <li>Students are encouraged to participate, but of course this is not mandatory, so you can not imply in your announcement that they have to participate.</li> <li>An overarching informed consent is provided through the EMS as a condition for signing up to a collective session, to allow data pooling across different collective testing sessions. However, individual consent is still necessary for each specific session, along with separate ethics approval.</li> </ul>"},{"location":"research/behaviour/participants.html#screener","title":"Screener","text":"<ul> <li>Upon getting an account, participants need to fill out a pre-screener. In this screener, they are asked to indicate their handedness, gender, vision status, age, availability in weekends and evenings, fluency in Dutch and English and the last digit of their student number (for random assignment).</li> <li>While setting up your experiment, you can set a few pre-screen restrictions to restrict the visibility of your study to participants who fail to meet those restrictions. Vice versa, you can also choose to send an automated email to all students who qualify for the pre-screen restrictions specific to your study.</li> <li>If you want to see more items added to the pre-screen, you can send an email to ioco@kuleuven.be and/or Tom Beckers.</li> </ul>"},{"location":"research/behaviour/participants.html#participant-consent","title":"Participant consent","text":"<p>Before starting the experiment, participants need to be fully informed about the study via a study information sheet, after which they need to sign the informed consent form. In these forms, it is important to make clear that they can withdraw from the study at any time and to provide contact details to give them the opportunity to ask questions (before and/or after the experiment).</p> <ul> <li>In case of on-site experiments, the information sheet as well as the informed consent can be presented (and signed) on paper.</li> <li>In case of online experiments, the information sheet as well as the informed consent can be presented digitally via the EMS. Instead of signing the ICF, participants can then explicitly select whether they agree or not agree to participate.</li> </ul> <p>After participation or after the study is finished, you can choose to debrief participants orally or via mail about the (general) study results and/or discuss their individual task performance during the experimental session.</p>"},{"location":"research/behaviour/participants.html#data-confidentiality","title":"Data confidentiality","text":"<p>Generally, except for gender and age, personal information does not need to be recorded. As all participants receive a system-assigned ID code (EMS code) to log in to the experiment, their participation and research data can remain fully anonymous. Also external people can use the EMS to ensure confidentiality.</p> <ul> <li>To avoid that a link is created between the EMS code and participant identity, please make sure to never ask for any identifying information such as their name or student number. This information will also never be provided by the administrator.</li> <li>Of course, if a person participates in a paid study, you will need to ask for their name, address, email and bank account number to process the payment. This communication can occur through the EMS, such that this information is not shared on any of the online platforms.</li> <li>Likewise, if a student wants to receive an update about the study results after the study is finished, they will need to provide their email address. These personal data should be saved in a password-protected file that will be stored as long as the study is ongoing, but deleted after publication of the research data.</li> </ul> <p>TODO: add (more) guidelines on how to store/manage data (probably best in a separate section)</p>"},{"location":"research/behaviour/participants.html#reimbursement","title":"Reimbursement","text":"<p>Reimbursement can take the following forms:</p> <ul> <li>Credit study: Research participation credits must be assigned in multiples of 0.25, i.e., 0.25 credit per 15 minutes, such that 1h equals 1 credit. Credits cannot be transferred between academic years.</li> <li>Paid study: The standard pay rate is up to 10 euros per hour, without additional incentives. Exceptions are possible for high-effort or aversive studies (e.g., fMRI, ESM).</li> <li>Mixed study: Award 0 credits to those who receive payment.</li> </ul> <p>TODO: Add info on how the procedure for money reimbursement works, found info on this link and this link</p> <p>Of course, all (psychology) students also benefit from participation by gathering insights into the common procedures of psychological research (wink).</p> <p>Please record participant presence (\"show-ups\") and assign credits or pay participants promptly (preferably the same day and always within 1 week). To do so, you will need to collect the student's EMS code.</p> <p>Tip</p> <p>The Sona Mobile app can be used for quick credit granting by scanning the QR code in the reminder email to the participants.</p>"},{"location":"research/behaviour/participants.html#no-shows","title":"No shows","text":"<ul> <li>Participants should contact the researcher if they cannot attend the session, which qualifies as an excused no-show.</li> <li>Unexcused no-shows incur a penalty of -0.5 credit. If a participant has 5 or more no-shows, their account will be inactivated.</li> </ul>"},{"location":"research/coding/index.html","title":"Coding Practices","text":"<p>Welcome to the Coding Practices section! Here, you'll find essential guidance for setting up your coding environment, managing projects, collaborating using GitHub, and following best practices to write clean, maintainable code.</p> <ul> <li> <p> Good coding practices   In the lab, we aim to build tools that are reproducible, reusable, and efficient. Learn more about our general approach to building and managing projects.</p> </li> <li> <p> Setting Up Your Project   Every new project starts with the right environment setup. Find out how to create a proper environment for your coding projects.</p> </li> <li> <p> Understanding Your Code   Encountering inexplicable errors? Want to know what data are you plotting? Don't know how to use a misterious function? Learn how to effectively debug your code using Spyder\u2019s powerful tools.</p> </li> <li> <p> Using Version Control   Discover how to integrate Git and GitHub into your workflow to keep track of changes and collaborate with ease.</p> </li> </ul>"},{"location":"research/coding/index.html#why-coding-practices-matter","title":"Why Coding Practices Matter","text":"<p>When you code for your research project, remember that you're not just coding for yourself today\u2014you\u2019re coding for:</p> <ul> <li>Your future self: Six months from now, you might not remember the specifics of your current project.</li> <li>Other scientists: Your code might be used or reviewed by researchers with varying coding skills and backgrounds. Writing clean and well-documented code ensures that your work can be understood and built upon by others.</li> </ul> <p>Keeping your code tidy, easy to understand, and maintainable is crucial for effective research collaboration and aligns with the principles of Open Science.</p>"},{"location":"research/coding/index.html#recommended-resources","title":"Recommended Resources","text":"<p>Make sure to explore our suggested Coding Tutorials. We especially recommend The Good Research Code Handbook, which provides valuable insights into writing robust research code. Key sections include Writing Decoupled Code and Keeping Things Tidy.</p> <p>By following these practices, you'll not only improve the quality of your research code but also make it easier to share your work with others, enhancing transparency and reproducibility. Invest time in reading and practicing. Developing good coding habits will pay off in the long run by making your work more efficient, easier to understand, and more valuable to the research community. Happy coding!</p> <p>Tip</p> <p>If you're new to coding and many of the terms on this page seem unfamiliar, start by exploring some of the essential tools you\u2019ll use. Check out tutorials on Python, Git, and the Unix Shell on the Student Starter Pack page.</p> <p>What if I code in MATLAB?</p> <p>While the information in this page focuses on Python, the principles of writing clean, maintainable code are universal. Debugging, structuring code, and organizing projects apply just as much to MATLAB as they do to Python. Be sure to apply these practices regardless of the language you're using!</p>"},{"location":"research/coding/index.html#special-note-for-fmri-projects","title":"Special Note for fMRI Projects","text":"<p>If you're working on fMRI projects, you\u2019ll find specific information on setting up your environment in the Set-up your Environment page of the fMRI section. This guide includes additional tips for managing data and code in neuroimaging research.</p>"},{"location":"research/coding/index.html#best-practices-for-organizing-code-and-projects","title":"Best Practices for Organizing Code and Projects","text":"<p>A well-structured project helps in maintaining readability and collaboration. Here are some recommendations:</p>"},{"location":"research/coding/index.html#1-folder-structure","title":"1. Folder Structure","text":"<p>Use a logical structure for your project files:</p> <pre><code>my_project/\n\u251c\u2500\u2500 data/              # Raw data files\n\u251c\u2500\u2500 modules/           # Scripts to store your classes and functions\n\u251c\u2500\u2500 results/           # Output results and figures\n\u251c\u2500\u2500 environment.yml    # Conda environment file\n\u2514\u2500\u2500 README.md          # Project overview\n</code></pre>"},{"location":"research/coding/index.html#2-naming-conventions","title":"2. Naming Conventions","text":"<ul> <li>Files: Use lowercase letters with underscores (e.g., <code>data_processing.py</code>).</li> <li>Folders: Use meaningful names that reflect their contents.</li> <li>Variables: Use descriptive names (e.g., <code>participant_id</code> instead of <code>id</code>).</li> </ul>"},{"location":"research/coding/index.html#3-general-coding-tips","title":"3. General Coding Tips","text":"<p>Tip</p> <p>Write modular code by breaking down tasks into functions and classes. This approach enhances reusability and readability.</p> <ul> <li>Avoid \"Spaghetti Code\": Keep functions short and focused.</li> <li> <p>Use Docstrings to document functions and classes:</p> <pre><code>def load_data(file_path):\n    \"\"\"\n    Loads data from a specified file path.\n\n    Args:\n        file_path (str): The path to the data file.\n\n    Returns:\n        pandas.DataFrame: Loaded data as a DataFrame.\n    \"\"\"\n</code></pre> </li> <li> <p>Follow PEP 8: Use tools like <code>black</code> to ensure code style compliance.</p> </li> </ul>"},{"location":"research/coding/index.html#4-saving-results","title":"4. Saving Results","text":"<p>Organizing your results properly is crucial for reproducibility, collaboration, and long-term maintainability of your research code. This section covers how to structure your results folders, save scripts and logs, and use utility functions to streamline these processes.</p> <p>To keep your project organized, we\u2019ve provided a set of utility functions that automate common tasks like setting random seeds, creating unique output directories, saving scripts, and configuring logging. These functions should be defined in a separate file called <code>utils.py</code> located in the <code>modules/</code> directory of your project.</p> Utility Functions in modules/utils.py <p>The following functions are defined in <code>modules/utils.py</code> (see the box below for the definitions):</p> <ul> <li><code>set_random_seeds(seed=42)</code>: Sets random seeds for reproducibility.</li> <li><code>create_run_id()</code>: Generates a unique identifier based on the current date and time.</li> <li><code>create_output_directory(directory_path)</code>: Creates a directory for saving results.</li> <li><code>save_script_to_file(output_directory)</code>: Saves the executing script to the output directory.</li> <li><code>setup_logger(log_file_path, level=logging.INFO)</code>: Configures logging to log both to the console and a file.</li> </ul> modules/utils.py<pre><code># ./modules/utils.py\nimport logging\nimport os\nimport shutil\nimport random\nimport torch\nimport numpy as np\nimport inspect\nfrom datetime import datetime\n\ndef set_random_seeds(seed=42):\n    \"\"\"\n    Set the random seed for reproducibility in PyTorch, NumPy, and Python's random module.\n\n    This function sets the seed for random number generation in PyTorch, NumPy, and Python's built-in random module.\n    It also configures PyTorch to use deterministic algorithms and disables the benchmark mode for convolutional layers\n    when CUDA is available, to ensure reproducibility.\n\n    :param seed: The random seed. Defaults to 42.\n    :type seed: int\n    \"\"\"\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.set_default_dtype(torch.float32)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\ndef create_run_id():\n    \"\"\"\n    Generate a unique run identifier based on the current date and time.\n\n    This function creates a string representing the current date and time in the format 'YYYYMMDD-HHMMSS'.\n    It can be used to create unique identifiers for different runs or experiments.\n\n    :returns: A string representing the current date and time.\n    :rtype: str\n    \"\"\"\n    now = datetime.now()\n    return now.strftime(\"%Y%m%d-%H%M%S\")\n\ndef create_output_directory(directory_path):\n    \"\"\"\n    Creates an output directory at the specified path.\n\n    This function attempts to create a directory at the given path.\n    It logs the process, indicating whether the directory creation was successful or if any error occurred.\n    If the directory already exists, it will not be created again, and this will also be logged.\n\n    :param directory_path: The path where the output directory will be created.\n    :type directory_path: str\n    \"\"\"\n    try:\n        logging.info(f\"Attempting to create output directory at: {directory_path}\")\n        if not os.path.exists(directory_path):\n            os.makedirs(directory_path)\n            logging.info(\"Output directory created successfully.\")\n        else:\n            logging.info(\"Output directory already exists.\")\n    except Exception as e:\n        logging.error(f\"An error occurred while creating the output directory: {e}\", exc_info=True)\n\ndef save_script_to_file(output_directory):\n    \"\"\"\n    Saves the script file that is calling this function to the specified output directory.\n\n    This function automatically detects the script file that is executing this function\n    and creates a copy of it in the output directory.\n    It logs the process, indicating whether the saving was successful or if any error occurred.\n\n    :param output_directory: The directory where the script file will be saved.\n    :type output_directory: str\n    \"\"\"\n    try:\n        # Get the frame of the caller to this function\n        caller_frame = inspect.stack()[1]\n        # Get the file name of the script that called this function\n        script_file = caller_frame.filename\n\n        # Construct the output file paths\n        script_file_out = os.path.join(output_directory, os.path.basename(script_file))\n\n        logging.info(f\"Attempting to save the script file to: {script_file_out}\")\n\n        # Copy the script and additional files to the output directory\n        shutil.copy(script_file, script_file_out)\n\n        logging.info(\"Script files saved successfully.\")\n    except Exception as e:\n        logging.error(f\"An error occurred while saving the script file: {e}\", exc_info=True)\n\ndef setup_logger(log_file_path=None, level=logging.INFO):\n    \"\"\"\n    Set up a logger with both console and file handlers.\n\n    :param log_file_path: The path for the log file. If None, only console logging is enabled.\n    :type log_file_path: str, optional\n    :param level: Logging level (e.g., logging.INFO, logging.DEBUG).\n    :type level: int\n    :return: Configured logger.\n    :rtype: logging.Logger\n    \"\"\"\n    # Create a logger\n    logger = logging.getLogger(__name__)\n    logger.setLevel(level)\n\n    # Create a formatter for logs\n    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n\n    # Create a stream handler (for console output)\n    stream_handler = logging.StreamHandler()\n    stream_handler.setFormatter(formatter)\n    logger.addHandler(stream_handler)\n\n    # If a log file path is provided, add a file handler\n    if log_file_path:\n        file_handler = logging.FileHandler(log_file_path)\n        file_handler.setFormatter(formatter)\n        logger.addHandler(file_handler)\n\n    # Prevent adding duplicate handlers\n    logger.propagate = False\n\n    return logger\n</code></pre> Using the utility functions in a script <p>To use the functions defined in <code>utils.py</code>, import them in your script and follow the example below. This will ensure reproducibility and proper organization of your experimental results.</p> main.py<pre><code>import os\nfrom modules.utils import (\n    set_random_seeds,\n    create_run_id,\n    create_output_directory,\n    save_script_to_file,\n    setup_logger\n)\n\n# Set random seeds for reproducibility\nset_random_seeds(42)\n\n# Define parameters for the run\nresults_dir = \"./results\"\ndataset_dir = \"./datasets\"\nepochs = 20\nlearning_rate = 1e-5\nbatch_size = 64 * (2**3)\n\nprob_a = 0.2\nprob_b = 0.2\nprob_test = 0.6\ntemperature_model_a = 0.1\ntemperature_model_b = 5\n\n# Create a unique run ID and results directory\nrun_id = f\"{create_run_id()}_train-pair-temp-ws-softmax_proba-{prob_a}_probb-{prob_b}_probtest-{prob_test}_tempa-{temperature_model_a}_tempb-{temperature_model_b}_lr-{learning_rate}\"\nresults_dir = os.path.join(results_dir, run_id)\ncreate_output_directory(results_dir)\n\n# Save the current script to the results directory for reproducibility\nsave_script_to_file(results_dir)\n\n# Set up logging to log both to the console and a file\nlog_file_path = os.path.join(results_dir, \"log_output.txt\")\nlogger = setup_logger(log_file_path)\nlogger.info(f\"Results will be saved in: {results_dir}\")\nlogger.info(\"Run ID: %s\", run_id)\nlogger.info(f\"Starting the experiment with the following parameters:\")\nlogger.info(f\"Learning Rate: {learning_rate}, Epochs: {epochs}, Batch Size: {batch_size}\")\n\n# ... Your training or analysis code here ...\n</code></pre> <p>Example Results Folder Structure</p> <p>After running the script, your results might be structured as follows:</p> <pre><code>results/\n\u251c\u2500\u2500 20241018-153045_train-pair-temp-ws-softmax_proba-0.2_probb-0.2_probtest-0.6_tempa-0.1_tempb-5_lr-1e-5/\n\u2502   \u251c\u2500\u2500 log_output.txt        # Logs of the run\n\u2502   \u251c\u2500\u2500 main_script.py        # Copy of the script that generated the results\n\u2502   \u251c\u2500\u2500 output_data.csv       # Output data generated by the run\n\u2502   \u2514\u2500\u2500 model_weights.pth     # Saved model weights\n</code></pre> <p>Why Create a <code>results</code> Folder for Each Run?</p> <ul> <li>Reproducibility: Ensures that each set of results corresponds to a specific code version and parameters.</li> <li>Comparison: Makes it easier to compare results between different runs with varying parameters.</li> <li>Organization: Keeps your project clean by preventing files from different experiments from mixing together.</li> </ul> <p>With these functions, you can ensure a well-organized, reproducible workflow, making it easier to manage long-term research projects and collaborate with others.</p>"},{"location":"research/coding/index.html#setting-up-a-conda-environment","title":"Setting Up a Conda Environment","text":"<p>Using isolated <code>conda</code> environments ensures that each project has the specific dependencies it needs without conflicts. Follow the steps below to create and manage your environments.</p>"},{"location":"research/coding/index.html#1-install-anacondaminiconda","title":"1. Install Anaconda/Miniconda","text":"<p>Download and install Miniconda or Anaconda.</p> What's the difference? <ul> <li>Miniconda is a minimal version that includes only <code>conda</code> and Python, allowing you to install only the packages you need.</li> <li>Anaconda comes with a full suite of pre-installed packages like <code>numpy</code>, <code>pandas</code>, <code>scipy</code>, and many others, and with a GUI to manage packages and environments.</li> </ul> WindowsMacUbuntu <ul> <li>Download the installer from the Anaconda website.</li> <li>Run the Installer: Double-click the <code>.exe</code> file and follow the installation wizard.</li> <li>Add Conda to PATH: During installation, check the box that says \"Add Anaconda to my PATH environment variable\" if you plan to use <code>conda</code> directly from the command prompt.</li> </ul> <p>Warning</p> <p>Adding Anaconda to PATH can sometimes cause conflicts with other software. Only do this if you are familiar with PATH management.</p> <ul> <li>Download the installer from the Anaconda website.</li> <li>Run the Installer: Open the downloaded <code>.pkg</code> file and follow the installation instructions.</li> <li>Verify Installation:     <pre><code>conda --version\n</code></pre></li> </ul> <p>Tip</p> <p>If you encounter issues with permissions, run the installer with <code>sudo</code>: <pre><code>sudo bash Anaconda3-&lt;version&gt;-MacOSX-x86_64.sh\n</code></pre></p> <ul> <li> <p>Download the installer script from the terminal:     <pre><code>wget https://repo.anaconda.com/archive/Anaconda3-&lt;version&gt;-Linux-x86_64.sh\n</code></pre></p> </li> <li> <p>Run the Installer:     <pre><code>bash Anaconda3-&lt;version&gt;-Linux-x86_64.sh\n</code></pre></p> </li> <li> <p>Follow the prompts: Accept the license terms, specify an installation path, and allow the installer to initialize <code>conda</code>.</p> </li> <li> <p>Activate changes:     <pre><code>source ~/.bashrc\n</code></pre></p> </li> </ul> <p>Info</p> <p>Make sure to replace <code>&lt;version&gt;</code> with the correct version number of the Anaconda installer.</p>"},{"location":"research/coding/index.html#2-create-and-manage-a-conda-environment","title":"2. Create and Manage a Conda Environment","text":"CLIGUI (Anaconda Navigator) <ol> <li> <p>Create a new environment:    Use the following command to create a new environment. Replace <code>myenv</code> with the name of your environment:    <pre><code>conda create --name myenv python=3.9\n</code></pre></p> </li> <li> <p>Activate the environment:    <pre><code>conda activate myenv\n</code></pre></p> </li> <li> <p>Install packages:    Install necessary packages, e.g., <code>numpy</code>, <code>pandas</code>, and <code>matplotlib</code>:    <pre><code>conda install numpy pandas matplotlib\n</code></pre></p> </li> <li> <p>Export environment for reproducibility:    Save your environment to a file:    <pre><code>conda env export &gt; environment.yml\n</code></pre>    This allows others to recreate your environment with:    <pre><code>conda env create -f environment.yml\n</code></pre></p> </li> </ol> <ol> <li> <p>Open Anaconda Navigator: Launch the Anaconda Navigator from your start menu.</p> </li> <li> <p>Create a new environment:</p> <ul> <li>Go to the \"Environments\" tab.</li> <li>Click on \"Create\" and give your environment a name (e.g., <code>myenv</code>).</li> <li>Select the desired Python version.</li> </ul> </li> <li> <p>Install packages:</p> <ul> <li>With your environment selected, click on \"Not installed\" to view available packages.</li> <li>Search for the packages (e.g., <code>numpy</code>, <code>pandas</code>) and install them by checking the boxes and clicking \"Apply\".</li> </ul> </li> </ol>"},{"location":"research/coding/index.html#setting-up-spyder-for-python-projects","title":"Setting Up Spyder for Python Projects","text":"<p>Spyder is a powerful IDE for scientific programming in Python. Here\u2019s how to set it up:</p>"},{"location":"research/coding/index.html#1-install-spyder","title":"1. Install Spyder","text":"Using Conda (Recommended)Using Anaconda Navigator <pre><code>conda install spyder\n</code></pre> <ul> <li>Open Anaconda Navigator.</li> <li>Find Spyder in the \"Home\" tab and click \"Install\".</li> </ul>"},{"location":"research/coding/index.html#2-create-a-project-in-spyder","title":"2. Create a Project in Spyder","text":"Why use Spyder projects? <p>Using a project allows Spyder to set the root folder for your scripts. This means that all imports and file paths are relative to this root, simplifying package management and file organization.</p> <ol> <li> <p>Create a New Project:</p> <ul> <li>Go to <code>File &gt; New Project</code> in Spyder.</li> <li>Select a directory to store your project files.</li> <li>Spyder will set this folder as the root for relative imports.</li> </ul> </li> <li> <p>Organize Your Project:</p> <ul> <li>Use a structure like this:</li> </ul> <pre><code>my_project/\n\u251c\u2500\u2500 data/              # Raw data files\n\u251c\u2500\u2500 modules/           # Scripts to store your classes and functions\n\u251c\u2500\u2500 results/           # Output results and figures\n\u251c\u2500\u2500 environment.yml    # Conda environment file\n\u2514\u2500\u2500 README.md          # Project overview\n</code></pre> </li> <li> <p>Activate Your Environment in Spyder:</p> <ul> <li>Go to <code>Preferences &gt; Python Interpreter</code>.</li> <li>Select the interpreter from your <code>conda</code> environment.</li> </ul> </li> </ol>"},{"location":"research/coding/index.html#understanding-your-code","title":"Understanding your code","text":"<p>Spyder offers powerful tools for debugging, understanding, and navigating your code. Here\u2019s an in-depth guide on how to leverage these features, with examples to make each step clear and actionable.</p>"},{"location":"research/coding/index.html#viewing-all-panes-in-spyder","title":"Viewing All Panes in Spyder","text":"<p>Before diving into debugging and navigation, it's important to set up your Spyder workspace for maximum efficiency. Spyder's default layout includes several panes that provide valuable insights into your code's execution and structure.</p> <ol> <li> <p>Accessing the View Menu:</p> <ul> <li>Go to <code>View &gt; Panes</code> to see a list of available panes.</li> <li>The most useful panes include:<ul> <li>Editor: This is where you write your code.</li> <li>IPython Console: Allows you to run commands interactively.</li> <li>Variable Explorer: Displays all variables in your current environment.</li> <li>Documentation: Shows documentation for selected functions and objects.</li> <li>File Explorer: Browse files and folders in your working directory.</li> <li>Breakpoints: Manage and navigate all breakpoints in your code.</li> </ul> </li> </ul> </li> <li> <p>Enable Recommended Panes:</p> <ul> <li>Ensure that the Variable Explorer, IPython Console, Breakpoints, and Documentation panes are enabled.</li> <li>This setup will help you keep track of variables, navigate breakpoints, and access function documentation easily.</li> </ul> </li> </ol> <p></p>"},{"location":"research/coding/index.html#understanding-the-code-by-debugging","title":"Understanding the Code by Debugging","text":"<p>Using breakpoints and Spyder's debugging tools allows you to:</p> <ul> <li>Pause code execution and inspect variables at critical points.</li> <li>Step through code line-by-line to understand how each operation transforms the data.</li> <li>Use the Variable Explorer for a visual overview of complex data structures.</li> <li>Run quick checks in the IPython console for on-the-fly validation.</li> </ul> <p>These tools are crucial for identifying and fixing bugs in your scripts, whether you're working with simple calculations or more complex data processing tasks. By mastering them, you'll save time and gain deeper insights into your code's behavior.</p> <p>Best Practices for Debugging</p> <ul> <li>Use Breakpoints Strategically: Place breakpoints at critical points in your code to verify data at those stages.</li> <li>Step Through Loops: Use \"Step Over\" and \"Step Into\" to see how data changes inside loops.</li> <li>Log Important Values: If you\u2019re debugging a specific issue, add print statements to log values at various points.</li> </ul> <p>Example Scenario: Debugging a Simple Calculation Script</p> <p>Let\u2019s say you have a script that generates some random numbers, processes them by applying a mathematical operation, and then plots the result. You want to ensure that the numbers are correctly generated and processed before they are plotted. Here\u2019s how you can use breakpoints to achieve this:</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate random data\ndata = np.random.rand(100)\n\n# Process data: apply a mathematical operation\nprocessed_data = data * 2 + 5\n\n# Plot data\nplt.plot(processed_data)\nplt.title('Processed Data')\nplt.show()\n</code></pre>"},{"location":"research/coding/index.html#1-adding-a-breakpoint","title":"1. Adding a Breakpoint","text":"<ul> <li>Set a breakpoint on the line where <code>processed_data</code> is calculated by clicking in the left margin next to the line or using:<ul> <li>Windows/Linux: <code>Ctrl + B</code></li> <li>Mac: <code>Cmd + B</code></li> </ul> </li> </ul> <p>The line will be highlighted in red, indicating that the breakpoint is active.</p> <p>Why use this?: This breakpoint allows you to pause before <code>processed_data</code> is calculated, so you can inspect the <code>data</code> values and verify that the generated numbers look as expected before the transformation is applied.</p>"},{"location":"research/coding/index.html#2-running-code-in-debug-mode","title":"2. Running Code in Debug Mode","text":"<p>Start debugging by clicking the \"Debug\" button (bug icon) in the Spyder toolbar or pressing <code>F5</code>. - The execution will pause when it reaches the breakpoint on <code>processed_data = data * 2 + 5</code>.</p> <ul> <li>Once paused, you can:<ul> <li>Step into a function (<code>Ctrl + F11</code>): This allows you to step inside any function calls to see how they operate internally.</li> <li>Step over (<code>Ctrl + F10</code>): This moves to the next line without diving into the details of function calls\u2014ideal for quickly advancing through simpler lines.</li> <li>Continue (<code>Ctrl + F12</code>): Resumes execution until the next breakpoint or the end of the script.</li> </ul> </li> </ul> <p>Why use this?: Step-by-step execution helps you isolate logical errors or verify how variables change through different stages, especially when debugging a transformation or complex calculation.</p>"},{"location":"research/coding/index.html#3-inspecting-variables-during-debugging","title":"3. Inspecting Variables During Debugging","text":"<ul> <li> <p>With the code paused at the breakpoint, use the Variable Explorer to examine the contents of <code>data</code>:</p> <ul> <li>Look at the array of generated numbers to ensure they are within the expected range (0 to 1 since <code>np.random.rand()</code> generates random floats).</li> <li>After confirming the raw <code>data</code>, proceed with the next step to see how <code>processed_data</code> changes.</li> </ul> </li> <li> <p>Double-click on <code>data</code> in the Variable Explorer to open a detailed view, allowing you to see the entire array and verify its values.</p> </li> </ul> <p>Why use this?: It allows you to visually inspect the contents of arrays, lists, or other data structures without needing to add print statements. This can be especially useful for quickly understanding the state of your data at different points.</p> <p></p>"},{"location":"research/coding/index.html#4-using-the-console-for-interactive-debugging","title":"4. Using the Console for Interactive Debugging","text":"<ul> <li> <p>While debugging, you can interact with variables directly in the IPython console to verify specific values or perform calculations without modifying the script.</p> </li> <li> <p>Example: To see the first few values of <code>data</code>, type:     <pre><code>print(data[:10])\n</code></pre>     This will print the first 10 values of the <code>data</code> array in the console, allowing you to confirm that the random numbers are as expected.</p> </li> <li> <p>Another Example: Check the shape of <code>data</code> to ensure it has the correct number of elements:     <pre><code>data.shape\n</code></pre></p> </li> </ul> <p>Why use this?: This feature allows you to perform ad-hoc checks on variables or run quick tests without altering your script, which is useful for exploring potential issues during debugging.</p>"},{"location":"research/coding/index.html#understanding-by-looking-at-definitions","title":"Understanding by Looking at Definitions","text":"<p>Spyder makes it easy to navigate large codebases and understand how functions, classes, and variables are connected. Using features like \"Go to Definition,\" \"Find References,\" object inspection, and the Documentation Viewer, you can explore and manage complex projects more efficiently.</p> <p>Pro Tips for Code Navigation</p> <ul> <li>Use \"Go to Definition\" to trace complex functions: This helps you see the original implementation without scrolling through files.</li> <li>Use the Variable Explorer for quick checks: It\u2019s a faster way to spot-check variables rather than adding numerous print statements.</li> </ul> <p>Overview:</p> <p>The Go to Definition feature allows you to quickly jump to where a function, class, or variable is defined. This is especially useful when working with large scripts or when using functions imported from other files or libraries. Instead of scrolling through the code to find a definition, you can directly jump to it.</p> <ul> <li>How to Use: Right-click on the function or class name and select \"Go to Definition\" or use the shortcut:</li> <li>Windows/Linux: <code>Ctrl + G</code></li> <li> <p>Mac: <code>Cmd + G</code></p> </li> <li> <p>Why use this?: This feature saves time and makes it easier to understand how a function or class is implemented without losing context in your main script.</p> </li> </ul> <p>Example Scenario: Navigating a Machine Learning Pipeline</p> <p>Suppose you have a script with multiple functions for data cleaning, feature extraction, model training, and evaluation. Using \"Go to Definition,\" you can quickly jump between functions to understand the flow of your code.</p> <pre><code>def clean_data(df):\n    # Data cleaning logic\n    return df\n\ndef extract_features(df):\n    # Feature extraction logic\n    return features\n\ndef train_model(features):\n    # Model training logic\n    return model\n\n# Main script\ndata = clean_data(data)\nfeatures = extract_features(data)\nmodel = train_model(features)\n</code></pre> <ul> <li>Scenario: You want to see the logic inside <code>clean_data</code> while working on the main script.<ul> <li>Right-click on <code>clean_data</code> and select \"Go to Definition.\"</li> <li>Spyder will take you directly to where <code>clean_data</code> is defined, allowing you to review the function without scrolling.</li> </ul> </li> </ul> <p></p>"},{"location":"research/coding/index.html#understanding-by-inspecting","title":"Understanding by Inspecting","text":"<p>Overview: Spyder\u2019s object inspection feature allows you to explore the attributes and methods of objects directly within the editor. This is particularly useful when working with unfamiliar libraries or custom classes, as it enables you to see what functions or properties are available and how to use them. This feature can be a lifesaver when you encounter a function with unclear parameters or complex behavior.</p> <ul> <li>How to Use: Select an object or function in the editor and press:</li> <li>Windows/Linux: <code>Ctrl + I</code></li> <li> <p>Mac: <code>Cmd + I</code></p> </li> <li> <p>Why use this?: This feature provides a quick way to understand the capabilities and usage of an object or method without needing to look up documentation online. It can save time when learning new libraries or debugging issues with complex data structures.</p> </li> </ul> <p>Example Scenario: Inspecting a NumPy Function</p> <p>Suppose you want to generate a set of random integers using the <code>np.random.randint</code> function, but you\u2019re not sure about its input arguments and what it returns. You can use Spyder\u2019s object inspection to quickly get this information without leaving the IDE.</p> <pre><code>import numpy as np\n\n# Generate random integers between 0 and 10\nrandom_numbers = np.random.randint(0, 10, size=100)\n</code></pre> <ul> <li> <p>Scenario: You want to know what arguments <code>np.random.randint</code> accepts and how to use it properly (e.g., what is <code>size</code>, and can you generate a 2D array?).</p> </li> <li> <p>Step 1: Select the Function: Highlight <code>np.random.randint</code> in the editor.</p> </li> <li> <p>Step 2: Press the Shortcut: Use <code>Ctrl + I</code> (Windows/Linux) or <code>Cmd + I</code> (Mac) to bring up the documentation in the Help pane.</p> </li> <li> <p>What You See: The documentation for <code>np.random.randint</code> appears, showing:</p> <ul> <li>Input Arguments: The range of integers (<code>low</code> and <code>high</code>), <code>size</code> for specifying the shape of the output array, and other optional parameters.</li> <li>Description: An explanation of what the function does\u2014generating random integers within a specified range.</li> <li>Returns: Information on what the function outputs (an array of integers).</li> <li>Examples: If available, code snippets showing how to use the function.</li> </ul> </li> <li> <p>Why use this?: This allows you to quickly understand how to use <code>np.random.randint</code> without having to search online. You can verify if the function supports multi-dimensional arrays by checking the <code>size</code> parameter.</p> </li> </ul>"},{"location":"research/coding/index.html#version-control-with-git-and-github","title":"Version Control with Git and GitHub","text":"<p>Version control is crucial for collaborative coding and tracking changes in your projects. Here\u2019s how to set up and use Git and GitHub, including practical tips for effective collaboration.</p> <p>For a beginner-friendly guide, with explanation on main steps and terminology see this page.</p>"},{"location":"research/coding/index.html#1-install-git","title":"1. Install Git","text":"WindowsMacUbuntu <ul> <li>Download the installer from the Git website.</li> <li>Follow the installation wizard, using default options.</li> </ul> <ul> <li>Install via Homebrew:     <pre><code>brew install git\n</code></pre></li> <li>Alternatively, download the Git installer.</li> </ul> <pre><code>sudo apt-get update\nsudo apt-get install git\n</code></pre>"},{"location":"research/coding/index.html#2-configure-git","title":"2. Configure Git","text":"<p>Set up your Git identity using the following commands:</p> <pre><code>git config --global user.name \"Your Name\"\ngit config --global user.email \"youremail@example.com\"\n</code></pre>"},{"location":"research/coding/index.html#3-using-github","title":"3. Using GitHub","text":"GitHub Desktop (GUI)Command Line (CLI) <ol> <li>Download GitHub Desktop.</li> <li>Sign in with your GitHub account.</li> <li>Clone a Repository:<ul> <li>Go to <code>File &gt; Clone Repository</code> and enter the repository URL.</li> </ul> </li> <li>Commit Changes:<ul> <li>Make changes to files, then click <code>Commit</code> to save a snapshot of your changes.</li> </ul> </li> <li>Push to GitHub:<ul> <li>After committing, click <code>Push</code> to sync changes with GitHub.</li> </ul> </li> </ol> <ol> <li>Clone a Repository:    <pre><code>git clone https://github.com/your-username/repo-name.git\ncd repo-name\n</code></pre></li> <li>Stage and Commit Changes:    <pre><code>git add .\ngit commit -m \"Initial commit\"\n</code></pre></li> <li>Push Changes:    <pre><code>git push origin main\n</code></pre></li> </ol>"},{"location":"research/coding/index.html#4-workflow-tips-for-effective-collaboration","title":"4. Workflow Tips for Effective Collaboration","text":"<ol> <li> <p>Always Pull Before Making Changes:</p> <ul> <li>Before starting any work, ensure your local repository is up-to-date with the latest changes:</li> </ul> <pre><code>git pull origin main\n</code></pre> <ul> <li>This prevents merge conflicts and keeps your local version in sync with the remote repository.</li> </ul> </li> <li> <p>Typical Workflow:</p> <ul> <li>Fetch Updates:</li> </ul> <pre><code>git fetch\n</code></pre> <ul> <li>Pull Latest Changes:</li> </ul> <pre><code>git pull origin main\n</code></pre> <ul> <li>Make Edits: Modify files as needed.</li> <li>Stage Changes:</li> </ul> <pre><code>git add .\n</code></pre> <ul> <li>Commit Changes with a clear message:</li> </ul> <pre><code>git commit -m \"Describe the changes made\"\n</code></pre> <ul> <li>Push to Remote:</li> </ul> <pre><code>git push origin main\n</code></pre> </li> <li> <p>Commit Often, but Meaningfully:</p> <ul> <li>Frequent commits help track your progress, but ensure each commit is meaningful and descriptive.</li> </ul> </li> </ol>"},{"location":"research/coding/index.html#common-git-issues","title":"Common Git Issues","text":"Merge Conflict <p>Issue: This occurs when changes are made in the same part of a file in both the local and remote versions.</p> <p>Solution:    - Resolve the conflict manually in the affected file. - Stage the resolved file:    <pre><code>git add &lt;file&gt;\n</code></pre> - Commit the resolution:    <pre><code>git commit -m \"Resolved merge conflict in &lt;file&gt;\"\n</code></pre></p> Detached HEAD <p>Issue: Happens when you are not on a branch but on a specific commit.</p> <p>Solution:  - Switch back to your branch:    <pre><code>git checkout main\n</code></pre></p> Push Rejected <p>Issue: Your push was rejected because the remote has changes that you don't have locally.</p> <p>Solution:  - Pull the latest changes, resolve any conflicts, and try pushing again:    <pre><code>git pull origin main\ngit push origin main\n</code></pre></p> Failed to Push Some Refs <p>Issue: Occurs when there are changes on the remote that need to be merged before pushing.</p> <p>Solution: - Run:    <pre><code>git pull --rebase origin main\n</code></pre> - This replays your changes on top of the pulled changes and then allows you to push again.</p> Changes Not Staged for Commit <p>Issue: Files were modified but not added to the staging area.</p> <p>Solution:  - Add the changes to the staging area:    <pre><code>git add &lt;file&gt;\n</code></pre> - Or add all changes:    <pre><code>git add .\n</code></pre></p> File Deleted Locally, But Not in Remote <p>Issue: A file was deleted locally but still exists in the remote repository.</p> <p>Solution:  - To stage the deletion:    <pre><code>git rm &lt;file&gt;\n</code></pre> - Commit and push the change:    <pre><code>git commit -m \"Deleted &lt;file&gt;\"\ngit push origin main\n</code></pre></p> Authentication Failed <p>Issue: This happens if your credentials are incorrect or have expired.</p> <p>Solution:  - Update your Git credentials:    <pre><code>git config --global credential.helper store\n</code></pre> - Re-run the <code>git push</code> command, and enter your credentials when prompted.</p> Branch Not Found <p>Issue: Occurs when you try to checkout a branch that doesn\u2019t exist locally or remotely.</p> <p>Solution:  - Create the branch:    <pre><code>git checkout -b branch-name\n</code></pre> - Or fetch all remote branches:    <pre><code>git fetch --all\n</code></pre></p> Untracked Files <p>Issue: New files are created locally but not yet added to Git.</p> <p>Solution:  - Stage the files:    <pre><code>git add &lt;file&gt;\n</code></pre> - To ignore certain files, add them to <code>.gitignore</code>.</p> File Size Too Large <p>Issue: Git prevents files larger than 100MB from being pushed.</p> <p>Solution:  - Use Git Large File Storage (LFS) to manage large files:    <pre><code>git lfs install\ngit lfs track \"&lt;file-pattern&gt;\"\ngit add &lt;large-file&gt;\ngit commit -m \"Add large file using Git LFS\"\ngit push origin main\n</code></pre> - Alternatively, remove the large file and add it to <code>.gitignore</code>:    <pre><code>git rm --cached &lt;large-file&gt;\necho \"&lt;large-file&gt;\" &gt;&gt; .gitignore\ngit commit -m \"Remove large file and update .gitignore\"\ngit push origin main\n</code></pre></p> Repository Size Exceeds Limit <p>Issue: GitHub imposes a repository size limit, typically 1GB for free accounts.</p> <p>Solution:  - Clean up your repository by removing large files from history using <code>git filter-branch</code> or tools like BFG Repo-Cleaner:    <pre><code>bfg --delete-files &lt;large-file&gt;\ngit reflog expire --expire=now --all &amp;&amp; git gc --prune=now --aggressive\ngit push --force\n</code></pre> - If large files are essential, consider hosting them elsewhere (e.g., cloud storage) and linking to them.</p> Packfile Too Large <p>Issue: This error can occur when trying to push a repository with a large packfile.</p> <p>Solution:  - Reduce the size of the packfile:    <pre><code>git gc --aggressive --prune=now\n</code></pre> - If the repository is still too large, consider splitting it into smaller repositories.</p> History Contains Large Files <p>Issue: Even if a large file has been deleted, it may still be present in the repository history.</p> <p>Solution:  - Remove the file from history with:    <pre><code>git filter-branch --tree-filter 'rm -f &lt;large-file&gt;' HEAD\ngit push origin --force\n</code></pre> - Note: Use <code>git filter-branch</code> carefully as it rewrites history.</p> <p>By following these practices, you can ensure smoother collaboration and minimize common issues when working with Git and GitHub.</p> <p>We hope this guide helps you establish a solid coding practice. Follow these steps to ensure your code is well-organized, collaborative, and reproducible!</p>"},{"location":"research/dnn/index.html","title":"Index","text":"<p>This is the landing page for this section. Please populate it with appropriate information.</p> <p>TODO: populate this landing page.</p>"},{"location":"research/eeg/index.html","title":"EEG (Electroencephalography)","text":"<p>We have access to two EEG devices that fall under the NeuroSPACE consortium.</p> <p>The first one is a mobile EEG system, currently used mostly by the Neuropsychology Lab (C. Gillebert).</p> <p>The second EEG apparatus is a high-resolution EEG system, used primarily by the Hoplab and the Desenderlab. This is a 128-channel system of BioSemi.</p> <p>The 128-channel EEG is located in room PSI 02.52. It can be booked through the Clustermarket system (see general Research pages), where you can find it as \"BioSemi EEG Lab 00.52\".</p> <p>In the Hoplab we typically set up experiments for multivariate EEG (\"Representational Dynamics\"). Our standard analysis pipeline is described most in detail in Chen et al. (2023, Imaging Neuroscience).</p> <p>This publication is accompanied by an OSF archive that contains the analysis code to do multivariate analysis with the help of Matlab and the CosmoMVPA toolbox.</p> <p>TODO: Add clustermarket info elsewhere;</p> <p>TODO: Create sub-pages;</p> <p>TODO: Add information on how to use the system and to acquire the data;</p> <p>TODO: Add information on the analysis (OSF page of Chen et al has no readme!);</p> <p>TODO: Also describe details of pre-processing (no pre-processing script on OSF);</p>"},{"location":"research/ethics/index.html","title":"General information on the ethical procedure","text":"<p>Before you can start your study, you will need to apply for ethical approval - at least in case your study is not covered by one of the existing approved projects.</p> <ul> <li>For (f)MRI and/or patient studies and/or studies carried out at UZ Leuven, you need to file an application at the Ethical committee research UZ/KU Leuven (EC onderzoek). Most of the research done in our lab falls under prospective academic monocentric research, for which you can find the application guidelines here.</li> <li>For behavioral or tDCS studies, which do not fall under the Human Experiments Act, you need to file an application at the Social and Societal Ethics Committee (SMEC) via the PRET (PRivacy and EThics) platform.</li> <li>If your research is close to another study that has already been approved within UZ/KU Leuven, you can also cover the necessary ethical requirements by filing for an amendment to the existing approval (which is considerably less time-consuming).</li> </ul> <p>It is important to know that in any case, your study cannot begin until it has been approved. If you are hesitating whether and/or where you should apply for ethical approval for your project, you can consult this decision tree. Examples of previous applications can be found in this folder of the lab's Teams channel.</p> <p>For more detailed info, please check out the following pages.</p> <p>TODO: add page on amendments?</p>"},{"location":"research/ethics/MEC.html","title":"Filing your study with the Ethical Committee UZ/KU Leuven","text":""},{"location":"research/ethics/MEC.html#step-1-register-your-study-at-the-uz-leuven-clinical-trial-center-ctc","title":"Step 1: Register your study at the UZ Leuven Clinical Trial Center (CTC)","text":"<ol> <li> <p>Fill in this online form in order to register your study in the UZ/KU Leuven central clinical research database. You can find a user guide on how to do this here. At the minimum, you will need to indicate the study type and upload your research protocol.</p> </li> <li> <p>After submission of the registration form to the CTC, your study will be assigned a study number (the famous S-number), which will be sent to the PI, the identified study contact person at UZ/KU Leuven and the applicant (you) via e-mail. You will need this number for your application to the EC.</p> </li> <li> <p>As soon as an S-number is assigned, supporting UZ Leuven departments (e.g., radiology) from which study-specific support will be required should be contacted, using the relevant forms. You can find more info on how to do this on this flowchart. In addition, the UZ Leuven GDPR questionnaire or KU Leuven PRET questionnaire should be completed. Both the form and the questionnaire are requirements for admissibility to submit your study to the EC.</p> </li> <li> <p>After the internal UZ Leuven stakeholders have reviewed all the documentation and no questions arise during the review process, you will obtain approval from the CTC via an automated validation email. Hooray, you are now ready to submit your study for EC review!</p> </li> </ol> <p>For more info about the CTC, navigate here. If you have questions, you can contact them via email or phone (+32 16 34 19 98).</p>"},{"location":"research/ethics/MEC.html#step-2-apply-for-ec-approval","title":"Step 2: Apply for EC approval","text":"<p>Most likely, you are seeking to get ethical approval for a prospective monocentric (academic) study, for which you can find the application guidelines here. (If you are planning to conducting a different type of study, please start here and navigate to the correct study type to find the corresponding info on the application process.)</p> <p>For a valid application, you are required to upload the following components:</p> <p>Language of documentation</p> <p>All the documentation needs to be written in Dutch, except for the research protocol and the translated versions of the ICFs.</p> <ol> <li> <p>Accompanying letter signed by the PI</p> <ul> <li>Ask for approval (specify the study type) and add a short description of the (goals of the) project</li> <li>Specify where (national/international) and by whom the study will be conducted (your affiliation)</li> <li>Describe the participant group, the recruitment and reimbursement procedure</li> <li>Specify that the informed consent forms will be signed prior to participation</li> <li>Describe the discomfort for the participant and the procedure in case of accidental findings</li> <li>State (in name of the PI) that:<ul> <li>there are no scientific or ethical concerns noted and the study can be executed as described in the protocol</li> <li>no research costs will be charged to the patient, the health insurance or the hospital</li> </ul> </li> <li>Refer to the attached documents</li> </ul> </li> <li> <p>Research protocol including a summary of the protocol in Dutch</p> <ul> <li>Study title, location, rationale and design (incl. study background and objectives)</li> <li>Description of the end points (= primary and secondary outcomes which the study aims to measure)</li> <li>Research method (e.g., behavioral/psychophysical tests and/or neuroimaging)</li> <li>Participant group(s) (incl. inclusion and exclusion criteria)</li> <li>Statistical analysis (incl. software that will be used and sample size calculations)</li> <li>Include an explanation for the sample size, referring to a power analysis</li> <li>In general for typical fMRI studies, a reference to the paper of Friston (2012) is sufficient</li> <li>Any no-fault insurance</li> <li>Quality assurance</li> <li>Direct access to source data</li> <li>Ethical (and any regulatory) approval</li> <li>Method of data processing</li> <li>Publication policy</li> <li>References</li> </ul> </li> <li> <p>Participant recruitment</p> <ul> <li>Describe the procedure that will be used to contact and recruit the study population described in the protocol: where, how, by whom.</li> <li>Make sure to include a justification for the potential recruitment of participants who are unable to give their consent. This info should be provided in a separate document.</li> <li>If recruitment materials (posters, brochures, advertisements, website, etc.) are used, they also have to be submitted under this section. You can read the guidelines on advertising/recruting here.</li> </ul> </li> <li> <p>Informed consent forms (ICFs) (in English and in Dutch)</p> <ul> <li>The EC provides some ICF templates which already include information regarding the legal basis for data processing chosen by UZ/KU Leuven (i.e., \"public interest\", cf. Article 6 of the GDPR), include the necessary contact details of the insurance company, etc. You can find them here (navigate to \"niet-EudraCT studies\").</li> <li> <p>The ICF should be written in clear and understandable language and consist of the following subsections (in a single document):</p> <ol> <li>Essential information to make the decision to participate, such as a clear description of the study project (context, objectives, methodology and procedure), a brief but clear explanation of the participant's rights (voluntary participation, confidentiality, safety precautions, insurance, etc.) and a description of the risks and benefits. Make sure to also include contact details of the PI such that the candidate has a contact point for further questions.</li> <li>The consent form</li> <li>Additional information (appendices) that does not immediately play a role in the decision-making process, such as more detailed information on the study visits (i.e., the number, frequency and content) or on the participant's rights.</li> </ol> </li> <li> <p>Each page in the ICF should be numbered (\"page X\") and mention the full study title and version number and date of the ICF.</p> </li> <li>If the application is covering both behavioral as well as neuroimaging experiments, provide two separate ICFs.</li> </ul> </li> <li> <p>Resume of the Principal Investigator (dated and signed)</p> <ul> <li>The CV should include sufficient information to allow the EC to assess the competence of the PI (i.e., education, current position, professional experience, relevant experience in clinical studies, etc.). This template can be used.</li> <li>The CV should also mention a Good Clinical Practice (GCP) certificate, including the date of certification (no more than 3 years old) and the organization that issued the certificate. GCP training is mandatory for all PIs.</li> </ul> </li> <li> <p>A pdf-version of the completed UZ Leuven GDPR questionnaire or the accepted KU Leuven PRET questionnaire</p> </li> <li> <p>Proof of \"no fault\" insurance, which you can request by sending an email to liability@kuleuven.be</p> </li> <li> <p>Suitability/agreement of the relevant supporting UZ Leuven departments</p> </li> </ol> <p>Once you have written all the necessary documents, you can file your application here by uploading all necessary information. Please not that only 1 (zip)file per component is allowed.</p> <p>TODO: Check whether this still applies \u2192 \"If the medical ethical committee has an issue with the principal investigator not being connected with UZ Leuven (e.g. in case the PI is a professor at the Faculty of Psychology and Educational Sciences); report this to Prof. Dr. Pol Ghesqui\u00e8re.\"</p>"},{"location":"research/ethics/SMEC.html","title":"Filing your study with the Social and Societal Ethics Committee","text":"<p>SMEC evaluates research on human subjects that is not related to health science practices or includes medical or pharmacological procedures.</p> <p>As of February 2020, the SMEC performs an integrated ethics and privacy (GDPR) check on all new applications through the PRET platform (external applicants can download the application form here). For assistance, please make use of the manual on how to use this platform and the SMEC-review checklist for an overview of the aspects that will be assessed during the ethical review. Also, there are ample examples of previous SMEC applications in this folder located on the lab's Teams channel to get you started.</p> <p>Info</p> <p>Please note that there exists a shortened procedure for master's thesis studies in our faculty through this form.</p>"},{"location":"research/ethics/SMEC.html#ethical-review","title":"Ethical review","text":"<p>The SMEC puts a lot of emphasis on a well thought out recruitment and informed consent procedure, for which you can consult their guidelines here. In short:</p> <ul> <li>Researchers should use an information letter, an informed consent form (Dutch example template, English example template) and a GDPR appendix (template) to provide potential participants with the necessary information about the study.  </li> <li> <p>Necessary information in the ICF as well as the information letter includes the following:</p> </li> <li> <p>An invitation to participate in the study</p> </li> <li>Information about the study and the researchers</li> <li>The potential risks and benefits of the study</li> <li>The voluntariness of participation and the possibility of withdrawal at any time without disadvantage</li> <li>Conflicts of interest and plans to commercialize research findings</li> <li>Measures to ensure confidentiality</li> <li>Information on compensation and incentives, as well as plan of action in case of disadvantage</li> <li>If applicable, clarification that the study is not set within the hospital context</li> <li>Contact details of the researchers</li> <li> <p>Ethics committee contact information</p> </li> <li> <p>In some cases, it may be justifiable to use a brief consent form (e.g., a short online questionnaire that is likely to be completed on a small screen). A full consent form might be intimidating in this case or considered a barrier that might limit response rates. A concise consent form should include at least the following elements:</p> </li> <li> <p>Short description of the study and the researchers</p> </li> <li>The voluntariness of participation and the possibility of withdrawal at any time without disadvantage</li> <li>Confidentiality of participants and their data</li> <li>The potential risks of participating in the study</li> <li> <p>Reference and easily accessible link to the information letter with the full info about the study (as listed above)</p> </li> <li> <p>To fully assess the recruitment process, the recruitment materials that will be used (e.g., flyer, poster, call on social media, etc.) should be included in the ethics application. Specific guidelines on recruiting participants through social media can be found here.</p> </li> <li> <p>Specific guidelines on research involving minors can be found here.</p> </li> </ul> <p>For any further questions, you can check out the FAQ section of the SMEC.</p>"},{"location":"research/ethics/SMEC.html#privacy-review","title":"Privacy review","text":"<p>Alongside the ethical review, the privacy impact of the study will be investigated. Here you can find clarifications of the privacy-related questions in the application form.</p>"},{"location":"research/ethics/SMEC.html#outcomes-of-the-reviewing-process","title":"Outcomes of the reviewing process","text":"<p>After the review, you will be informed of the outcome via an automated email from the PRET platform, with three possible results:</p> <ol> <li>Accepted: The ethical approval will remain valid for up to 4 years from its effective date of issue.</li> <li>Minor revisions: Small adjustments are required, after which approval can be granted immediately.</li> <li>Major revisions: Resubmission is required (within 6 months), after which the dossier will be re-reviewed by the SMEC panel.</li> </ol> <p>A flowchart visualising the ethical review process (and its timing) can be consulted here.</p>"},{"location":"research/eyetracking/index.html","title":"Eye-tracking","text":"<p>For setting up the long-range eye-tracking system in the fMRI room (MR8), please consult this page.</p> <p>If you want more information on the stand-alone eye-tracking system to run behavioural experiments, please consult this page instead.</p> <p>NOTE: I am not sure whether we need this eye-tracking section. We could perhaps just keep the ET info within the relevant sections (fmri, behaviour)? Unless there is more general info that does not fit in those sections, e.g. lin to scripts, resources, manuals, overall workflow to collect, process and analyze data (which I would assume is roughly the same between fmri and behaviour).</p>"},{"location":"research/fmri/index.html","title":"Functional MRI","text":"<p>Welcome to the landing page for all things related to functional MRI (fMRI) in our lab. Whether you're a new student, a researcher, or someone interested in learning more about fMRI, you'll find everything you need here\u2014from getting started with your work environment to data analysis.</p> <ul> <li> <p> First steps</p> <p>Everything you need to know before you start scanning, including MRI booking, invoicing, training and ethical approval.</p> <p> Get started</p> </li> <li> <p> Scanning Procedure</p> <p>Detailed guidelines for preparing and conducting fMRI scans, including participants registration, equipment setup, and scan procedures.</p> <p> View procedures</p> </li> <li> <p> Data Analysis</p> <p>The step-by-step workflow we use to pre-process and analyze fMRI data.</p> <p> Start analyzing</p> </li> <li> <p> fMRI Task</p> <p>You need to code your fMRI task and you don't know where to start? Check out this fMRI task template from the Hoplab Github repositories.</p> <p> See the repo</p> </li> </ul>"},{"location":"research/fmri/index.html#quick-links-to-resources","title":"Quick Links to Resources","text":"<p>Here are some helpful links to external resources for fMRI data analysis, tools, and tutorials:</p> <ul> <li>fMRI Prep and Analysis with Andrew Jahn</li> <li>Nilearn for neuroimaging in Python</li> <li>SPM Programming Introduction</li> <li>SPM Scripts on GitHub</li> </ul>"},{"location":"research/fmri/fmri-get-started.html","title":"(f)MRI for newbies","text":""},{"location":"research/fmri/fmri-get-started.html#get-acquainted","title":"Get acquainted","text":"<p>Kickstart your (f)MRI learning journey by engaging in the following key activities:</p> Subscribe to the MR mailing listBrowse documentationParticipate in a study <ul> <li>How to subscribe:   Join the MR mailing list by visiting this link. Make sure you are logged in and click on \"Subscribe or Unsubscribe\" in the menu on the top right. Provide your first and last name and hit the subscribe button. A confirmation request will be sent to your email address. Your subscription will be completed if you respond to this request within 48h.</li> <li>Purpose of the list:   This mailing list is used by the MR Safety Officer to report on the status of the MRI equipment and announce upcoming MR safety courses. It also allows MRI researchers to ask each other questions about MRI practices and possible issues.  </li> </ul> <ul> <li>The lab's resources:   Documentation related to (f)MRI studies is available in this Hoplab Teams folder, including manuals, protocols, and information on safety procedures. Regular updates and additional resources will be added to this folder, so make sure to stay informed by regularly checking the documentation.</li> <li>MRI dropbox folder:   The radiology department of UZ Leuven also provides documentation related to the experimental use of the research MRI scanner (MR8) in this Dropbox folder.</li> </ul> <ul> <li>Get involved:   Interested in participating in an (f)MRI study? Discover ongoing studies within our faculty by visiting this Facebook page or by following this page on X (formerly Twitter). To sign up for a study, simply register through the faculty's Experiment Management System (EMS).</li> <li>What to expect:   As a participant in an (f)MRI study, you'll contribute valuable research data by getting your brain scanned. This is a unique opportunity to gain firsthand experience in how (f)MRI studies are conducted.</li> </ul>"},{"location":"research/fmri/fmri-get-started.html#before-you-start","title":"Before you start","text":"<p>Before diving into your (f)MRI study, make sure you're prepared by following the steps below.</p>"},{"location":"research/fmri/fmri-get-started.html#get-formal-ethical-approval","title":"Get formal ethical approval","text":"<p>Follow the yellow section of the flowchart to make sure everything is in order for you to start scanning.</p> <ol> <li>Register your study at the CTC:    After this you receive an S-number (for more info, we refer you to this page).</li> <li>Register your study at the MR research department:    Upload the application form for support from the Radiology department via this link. Include the Clinical Study Coordinator of Radiology (currently, that is lesley.cockmartin@uzleuven.be) as contact person, who will approve your request via email.</li> <li>Get approval from the ethical committee of UZ/KU Leuven:    For more info, we refer you to this page.</li> <li>Follow the MR safety course:    And become an authorized user of the MRI-scanner (see below).</li> </ol>"},{"location":"research/fmri/fmri-get-started.html#attend-the-mr-safety-course","title":"Attend the MR safety course","text":"<ul> <li>Course dates:    This course is organized twice a year by Dr. Ron(ald) Peeters, the MR Safety Officer. The exact course dates will be announced via the MR mailing list, and are typically in February and September.</li> <li>Preparation:    Before attending, carefully read the <code>Safety notes, rules &amp; procedures</code> document in the MRI dropbox folder, which you can find here. In the dropbox folder, you can also find the slides used in a previous safety course (2020 version). Additionally, in our Hoplab Teams folder, you can find some additional safety information.</li> </ul>"},{"location":"research/fmri/fmri-get-started.html#gain-access-to-mr-facilities","title":"Gain access to MR facilities","text":"<ul> <li> <p>Document submission:    After obtaining ethical approval, send the completed MR Access file and the approved ICF to ilse.roebben@uzleuven.be and silvia.kovacs@uzleuven.be.</p> </li> <li> <p>Safety checklist:    Before entering the Controlled Area for the first time, complete the MRI Safety Checklist and sign this Appendix that states you followed the MR safety course, read the necessary documentation and pledge to follow the local rules of operation. Send both files to ronald.peeters@uzleuven.be along with your details (name, U-number, e-mail address) and the S-number of your study.</p> </li> </ul> Card activation for MR suite access <p>Depending on your current card type:</p> <ul> <li>Old KU Leuven Card (dark blue, \"Katholieke Universiteit Leuven\"): Visit the technical services department \"Toegangsbeheer\" at UZ Leuven (green street, poort 5, level -1) between 8.00 and 16.15 on weekdays for activation of your card.</li> <li>New KU Leuven Card (light blue, \"KU Leuven\"): Obtain a new card at the same location to get access. A deposit is required, refundable upon card return.</li> </ul> <p>Ron should have emailed toegangsbeheer (toegangsbeheer@uzleuven.be) with his permission to activate your card. If everything works out, your card will be functional after 24 hours.</p> <p>TODO: the information above may be not accurate anymore. Laura S should probably update this section, since she is the last doing this?</p>"},{"location":"research/fmri/fmri-get-started.html#training-and-preparation","title":"Training and preparation","text":"<p>Before you can become an Authorized Other User (AOU), you must undergo practical training and testing:</p> <ol> <li> <p>Observational training:   After reviewing all relevant documentation, observe scan procedures by joining sessions of your colleagues. We have an internal slack channel to keep track of upcoming scans, so make sure you are invited to it if you want to be up to date.</p> </li> <li> <p>Testing protocols:    Before your pilot (f)MRI session with an actual participant, set up your sequences and test your experiment script. Book a phantom session by contacting Dr. Ron(ald) Peeters at ronald.peeters@uzleuven.be. If needed, you can find specific info on the projector screen here.</p> </li> </ol> <p>Independent scanning</p> <p>You are allowed to conduct scans independently after attending approximately 10 sessions with experienced personnel (e.g., more senior colleagues). This will help you learn how to control the scanner effectively. After 2 sessions, you should know how to controle the scanner and you are allowed to be the second researcher during a scan session outside office hours.</p>"},{"location":"research/fmri/fmri-get-started.html#during-your-experiment","title":"During your experiment","text":"<p>Understand and follow the detailed MR scan procedures to ensure efficient and safe usage of the MRI facilities.</p>"},{"location":"research/fmri/fmri-get-started.html#scanner-procedures","title":"Scanner procedures","text":"<p>All referenced documents are regularly updated and available in the Hoplab Teams folder. Ensure you read the latest versions before proceeding.</p> <ul> <li> <p>Booking the scanner:   Once you completed all steps above, you can book the scanner via the MRI scientific planning agenda. Details on how to do this can be found in the instructions for use on the planner webiste, the <code>MRI Planning Agenda</code> located in the Hoplab Teams folder and in <code>Safety notes, rules &amp; procedures</code> (pages 8-11) located in the MRI dropbox folder.</p> </li> <li> <p>Using the Scanner:   Operational guidelines for the MR scanner are outlined in the <code>fMRI protocol_MR8_October2019</code> document, available in the Hoplab Teams folder. There, you can also find a useful checklist that you can use as a reminder during scanning. NOTE: refer to the page with hospital information once all the info from the fMRI_protocol_MR8_October2019 file has been moved</p> </li> </ul>"},{"location":"research/fmri/fmri-get-started.html#managing-scan-data-and-invoicing","title":"Managing scan data and invoicing","text":"<ul> <li> <p>Tracking sessions:   Keep detailed records of all scan sessions, noting which sessions provided useful data. Regular reports should be made to your Principal Investigator (PI).</p> </li> <li> <p>Quarterly reports:   Every three months, your PI will receive an Excel sheet listing all scan sessions conducted during that period.</p> </li> <li> <p>Documenting experiments:   Complete the Excel sheet with the experiment name for each session and note down comments for any session that did not yield useful for various reasons (e.g., participant cancellation, no-shows, artifacts, technical issues).</p> </li> <li> <p>Financial management:   Include the name of your SAP antenne (i.e., An Van Kets) below the total invoice amount. Additionally, adjust the total on the invoice to reflect the actual scan hours and amount due based on successful data collection sessions (\"corrected total\").</p> </li> </ul> <p>Invoicing details</p> <p>Add columns in your invoicing reports to specify the funding source for each session, and mark any sessions that should not be charged due to issues like cancellations or technical problems.</p>"},{"location":"research/fmri/fmri-procedure.html","title":"Practical scanning protocol","text":"<p>This page outlines the procedures followed by our lab at MR8.</p> <p>For a quick overview of all the steps on the day of a scanning section, please consult the MRI checklist</p>"},{"location":"research/fmri/fmri-procedure.html#general-information","title":"General Information","text":"<p>The MR8 suite houses a Philips Ingenia scanner with a 32-channel head coil, located in MR suite E408 (map). Detailed scanner specifications can be found in the manual.</p> <p>Important Notes</p> <ul> <li>There is no cell phone service inside the MR suite. Use the control room phone for external calls (dial <code>0</code> before the number).</li> <li>After 6 pm and on weekends, two certified MR users (MRRUs) are required to run a session. More details are available in the Safety Rules &amp; Procedures.</li> <li>You can find relevant phone numbers to call for urgent questions as well as usernames and passwords of the PCs in the scan console room in this file in the Hoplab Teams folder.</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#mr8-equipment","title":"MR8 Equipment","text":"Area/Equipment Description Lockers Store white lab coats and personal belongings. Scan Console Screen Includes USB slots for data export. Stimulus PC &amp; Screen Main stimulus computer setup. Eyetracker Setup Screen and PC for eye-tracking experiments. Volunteer Monitoring Screen Displays a camera feed focused on the volunteer\u2019s legs to monitor movements. Light Switches Control the lights in the scanner room. Press 0 or 1 to switch off/on, and use the surrounding circle to gradually adjust brightness. Storage Contains earplugs, washcloths, padding for headphones (top right drawer), filters (top left drawer), etc. Projection Screen Always ensure the projection screen is aligned with the black marks in the scanner. Do not touch the screen directly. Filter Use the default filter (3NB). Eyetracker Complete setup for eye-tracking experiments. Projector Controlled from the technical room using a remote. Stimulus Desktop PC The main system for running visual stimuli. Power Supply Power for the eyetracker. Light Switches for Technical Room Located near the equipment area for controlling lighting. Scanner Room Key Used to lock and unlock the scanner room. Headphones - Auditory System Headphones for delivering auditory stimuli."},{"location":"research/fmri/fmri-procedure.html#required-forms","title":"Required Forms","text":"<p>Before going to the hospital, ensure that you have the following forms ready:</p> <ul> <li> <p>Consent Form: Must be signed by both the participant and yourself before the session. Keep it safe post-session.</p> </li> <li> <p>MR Safety Checklist: This form should be filled out by the participant prior to the session. You can send it in advance to avoid delays on the day of the scan. When the radiology desk is open, this form should be handed to the desk personnel, which will stamp it and confirm your scanning session. Link</p> </li> <li> <p>Check-In/Check-Out Form: Fill this form when entering and leaving the MR suite. The timings you indicate on there will be used to record our usage of the scanner and the amount of hours to pay for. Leave this form on the dedicated tray, next to that of the screening questionnaires. Link</p> </li> </ul>"},{"location":"research/fmri/fmri-procedure.html#participant-arrival-and-registration","title":"Participant Arrival and Registration","text":""},{"location":"research/fmri/fmri-procedure.html#participant-registration","title":"Participant Registration","text":"<p>Upon arriving at the hospital, participants must register at the main entrance. The registration procedure varies depending on whether they hold a Belgian ID:</p> <ul> <li>Belgian eID-card: Use the self-service kiosks or the Mynexuzhealth app for fast registration.</li> <li>No Belgian eID-card: Participants must visit the registration desks (open from 7:00 AM to 6:30 PM).</li> <li>Children under 12: Register using a Kids-ID or ISI+ card (for those with Belgian Social Security but without a Belgian ID).</li> </ul> <p>Participants must wait at the main entrance at least 30 minutes before their scheduled scanning session. A researcher will meet them and guide them through the check-in process.</p> Weekdays (before 5:30 PM)After 5:30 PM or Weekends/Holidays <p>The researcher will guide the participant through the process, ensuring that:</p> <ul> <li>The MR Safety Checklist and Consent Form are completed at the hospital entrance. Family members or anyone accompanying the participant into the Inner Controlled Area must also complete the MR Safety Checklist.</li> <li>The MR Safety Checklist is submitted at the \"Wachtzaal Radiologie\" registration desk.</li> <li>The secretary scans the participant's screening questionnaire into their medical file.</li> <li>The researcher brings the stamped questionnaire to the MRI scanner.</li> </ul> <p>Important</p> <p>The MR Safety Checklist must be submitted at the Radiology desk. Failure to do so will prevent the participant from being listed in the Radiology Information System (RIS), which could cause delays.</p> <ul> <li>The MR Safety Checklist and Consent Form are completed at the hospital entrance.</li> <li>The researcher and participant will proceed directly to the MR8 suite together.</li> </ul> <p>Controlled Areas Access</p> <p>Access to the Controlled Areas (MRI suite) is restricted and requires a KU Leuven card. Participants are not permitted to enter these areas until the MR Safety Checklist and Consent Form are signed.</p>"},{"location":"research/fmri/fmri-procedure.html#at-the-scanner-control-room","title":"At the Scanner Control Room","text":"<p>Upon arriving in the scanner control room, follow these steps to ensure smooth preparation and transition to the scanning session:</p> <ol> <li> <p>Task Explanation:</p> <ul> <li>Clearly explain the task and any relevant stimuli to the participant. If applicable, show them examples of the stimuli or allow them to practice a few trials to help them understand the task before scanning begins.</li> </ul> </li> <li> <p>Form Submission:</p> <ul> <li>Confirm that the Consent Form and MR Safety Checklist have been signed. These forms must be signed before entering any Controlled Area.</li> <li>Ensure that the check-in section of the Check-in/out form is completed.</li> <li>Place the signed forms in the designated trays in the scanner control room.</li> </ul> </li> <li> <p>Pre-scan Preparation:</p> <ul> <li>Remind the participant to use the bathroom if needed. The bathroom is located behind the orange door, across from the control room.</li> <li>Check that neither you nor the participant have any metal or magnetic items on your body (e.g., watches, hair clips, bank cards, festival bracelets, belts, phones). If the participant prefers not to remove a festival bracelet, you can cover the metal portion with tape.</li> </ul> </li> <li> <p>Personal Belongings:</p> <ul> <li>Store the participant's personal belongings in the lockers (refer to locker no. 1 on the map of the MR8 suite).</li> </ul> </li> <li> <p>Final Check:</p> <ul> <li>Double-check that all necessary forms have been completed and submitted.</li> <li>Confirm that the participant and all accompanying individuals are prepared to enter the scanning suite with no metal or magnetic items.</li> </ul> </li> <li> <p>Optional Comfort:</p> <ul> <li>If the participant is expected to be in the scanner for an extended period, offer them water or a snack beforehand to ensure they are comfortable.</li> </ul> </li> </ol>"},{"location":"research/fmri/fmri-procedure.html#preparation-of-the-scanner-area","title":"Preparation of the Scanner Area","text":"<p>Warning</p> <p>After leaving the scanner room, always lock the door.  If the door isn\u2019t locked properly, the scan console will display an error when you try to start scanning.</p>"},{"location":"research/fmri/fmri-procedure.html#stimulus-pc","title":"Stimulus PC","text":"<p>The stimulus computer's desktop is located in the control room. It is the second-last computer from the right, between the eye-tracking computer (last) and MRI control computer.</p> <ol> <li> <p>Logging In:</p> <ul> <li>Use the provided username and password. Login details can be found here.</li> </ul> <p>Password Not Accepted?</p> <p>If the password is not accepted, check for a qwerty-azerty keyboard mismatch. Press <code>alt+shift</code> and ensure EN is selected on the login screen.</p> </li> <li> <p>Storing Experiment Files:</p> <ul> <li>Store your experiment folders under: <code>C:\\Research\\Psychology\\</code>  (Create your own folder within this directory.)</li> </ul> </li> <li> <p>Installed Software:</p> <ul> <li>Matlab 2011b, 2015a, and Psychtoolbox 3.0.123 are installed.</li> </ul> <p>Tip</p> <p>If Matlab freezes or shows a JAVA error, restarting Matlab should fix the issue.</p> </li> <li> <p>Screen Resolution:</p> <ul> <li>The resolution is set to 1920 x 1080 (landscape).</li> <li>To flip the screen, adjust the projector settings, not the computer.</li> <li>Screen Width: 28.35 visual degrees</li> </ul> </li> </ol>"},{"location":"research/fmri/fmri-procedure.html#trigger-boxes","title":"Trigger Boxes","text":"<p>The scanner sends a trigger \"5\" to the stimulus computer. Different setups are used for static and dynamic stimuli:</p> Static StimuliDynamic Stimuli (e.g., movies) <p>A single wire connects two button boxes, each with 2 buttons:</p> <ul> <li>Box 1: <ul> <li>Blue button = Trigger 1</li> <li>Yellow button = Trigger 2</li> </ul> </li> <li>Box 2: <ul> <li>Green button = Trigger 3</li> <li>Red button = Trigger 4</li> </ul> </li> </ul> <p>A response box with 4 buttons:</p> <ul> <li>Blue button = Trigger \"b\"</li> <li>Yellow button = Trigger \"y\"</li> <li>Green button = Trigger \"g\"</li> <li>Red button = Trigger \"r\"</li> </ul> <p>Check Trigger Outputs</p> <p>Before starting the experiment, verify that the buttons provide the expected outputs on the stimulus PC screen. If no triggers are working:</p> <ul> <li>Restart Matlab and/or the stimulus computer.</li> <li>Check if any cables have been left disconnected. The response box is on top of the stimulus desktop PC in the control room. Ensure both cables are properly connected.</li> </ul> <p></p>"},{"location":"research/fmri/fmri-procedure.html#common-issues","title":"Common Issues","text":"Button Box Not Responding <ol> <li>Restart Matlab.</li> <li>Reset the button boxes in the technical room by unplugging and reconnecting the power cables.</li> <li>If the problem persists, restart the stimulus computer.</li> </ol> Trigger Not Working <ol> <li>Restart Matlab and check for responses from the button box.</li> <li>Ensure the trigger passes through the static stimuli box (check if the boxes are responsive).</li> <li>Verify that all cables are connected properly. The response box is on the table next to the desktop PC in the technical room.</li> </ol> Restarting the Scanner <p>Do not do this without the approval of Ron or Stefan. If the trigger still doesn\u2019t work, you may need to restart the scanner:</p> <ol> <li>Ensure the volunteer is out of the scanner first.</li> <li>Go to the technical room and locate the box with the red stop and green start buttons.</li> <li>Press the red button to stop the scanner. Wait 10 seconds, then press the green button to restart it.</li> <li>Log back into the scanner computer using MRService credentials.</li> <li>Wait until all components are ready and restart the software.    Confirm any errors, such as helium pressure alerts, by pressing OK.</li> </ol>"},{"location":"research/fmri/fmri-procedure.html#scanner-table-setup","title":"Scanner Table Setup","text":"<ol> <li> <p>Cover Cushions:      Always cover the cushions with paper towels before use.</p> </li> <li> <p>Keep Equipment Off the Floor:      Do not place cushions or equipment on the floor. If any are found on the floor, place them on the shelves.</p> </li> <li> <p>Patient Table Setup:</p> <ul> <li>The 32-channel coil should be placed ~10 cm from the edge of the table.</li> <li>Coil connections:  <ul> <li>Left lower plug and right upper plug.</li> </ul> </li> <li>Headphones:   Plug into the upper left connector at the top of the table.</li> <li>Panic Button:   Plug into the lower left connector at the bottom of the table.</li> </ul> </li> </ol> <p>Running Low on Supplies?</p> <p>If you run out of supplies (e.g., paper towels), you can find new ones in the closet right in front of you when entering MR suite E408. Paper rolls are stored on top.</p>"},{"location":"research/fmri/fmri-procedure.html#projection-screen","title":"Projection Screen","text":"<ul> <li> <p>Correct Position:     Ensure the back of the screen is aligned with the black marks on the scanner table.</p> </li> <li> <p>Handling:     Never touch the projection side of the screen. Use the plastic stand at the bottom if you need to move it.</p> </li> </ul>"},{"location":"research/fmri/fmri-procedure.html#projector-filter","title":"Projector Filter","text":"<p>Ensure that filter 3NB (1.34% light transmission) is placed in front of the projector tunnel for consistency across scan sessions.</p> <p>MR8 offers four filter options, each with different light transmission levels:</p> Filter Light Transmission 3NB 1.34% A+B 4.27% A+C 4.86% Unnamed (grey tape) 69.3% <p>You can combine filters to adjust the luminance.</p> <p>Handle Filters with Care</p> <p>Filters are fragile. Always hold them by the frame to avoid damage. Filters are stored in the top left drawer of the cabinet in the scanner room.</p>"},{"location":"research/fmri/fmri-procedure.html#projector-usage","title":"Projector Usage","text":"<ol> <li> <p>Powering On:    The projector brand is NEC. Use the remote (button on the top right) to turn it on.</p> </li> <li> <p>Adjusting the Lens:    If the lens is out of position, use the buttons next to the lens on the projector to adjust \u2014 do not touch the lens directly.</p> </li> </ol>"},{"location":"research/fmri/fmri-procedure.html#common-issues_1","title":"Common Issues","text":"<p>If the screen is showing a blue window or incorrect display:</p> <ul> <li>Check that the projector cable is properly connected to the stimulus computer.</li> <li>Ensure the source is set to DisplayPort.      Press the DisplayPort button on the remote to reset the projector to standard settings.</li> </ul> <p>Viewing Projector Menu</p> <p>To view the projector menu, you'll need to be inside the scanner room with the remote. Remove the filter, then use the remote inside the scanner to see the menu options on the projection screen.</p>"},{"location":"research/fmri/fmri-procedure.html#getting-the-volunteer-ready-for-the-scanner","title":"Getting the Volunteer Ready for the Scanner","text":""},{"location":"research/fmri/fmri-procedure.html#earplugs-and-headphones","title":"Earplugs and Headphones","text":"<p>Volunteers must wear earplugs and white earphones. New white earpad covers can be found:</p> <ul> <li>On top of the cabinet to the right</li> <li>Inside the cabinet in the hallway (enter, go straight, then turn right)</li> </ul> <p>Mandatory Hearing Protection</p> <p>Volunteers who refuse to wear the provided hearing protection cannot be scanned.</p>"},{"location":"research/fmri/fmri-procedure.html#coil-setup","title":"Coil Setup","text":"<ol> <li> <p>Positioning the Volunteer:</p> <ul> <li>Ask the volunteer to lie down on the patient table with their head fitted inside the coil.</li> <li>Ensure they don\u2019t hit their head when positioning.</li> <li>Place a knee cushion under the volunteer's legs for comfort.</li> </ul> </li> <li> <p>Head Stability:</p> <ul> <li>Secure the volunteer's head using washcloths placed between the sides of the head and the coil.</li> <li>Make sure the volunteer is comfortable, ensuring the washcloths do not apply too much pressure.</li> </ul> </li> <li> <p>Panic Button:</p> <ul> <li>Attach the panic button to the volunteer's clothing (within easy reach).</li> <li>Do not place it in their hand.  </li> <li>Explain its operation and test the alarm before starting the session.</li> </ul> </li> <li> <p>Response Button Box:</p> <ul> <li>Hand the response button box to the volunteer and repeat instructions on which buttons to use.</li> </ul> </li> <li> <p>Positioning the Coil:</p> <ul> <li>Place the top of the coil onto the bottom part, ensuring the volunteer's nose/head is not touching the coil.</li> <li>Align the volunteer\u2019s eyebrows with the calibration line on the coil. This ensures the head is positioned at the center of the magnet.</li> <li>Secure the coil by clipping it with the gray handle.</li> </ul> </li> </ol>"},{"location":"research/fmri/fmri-procedure.html#mirror-and-screen-alignment","title":"Mirror and Screen Alignment","text":"<p>Preferred Mirror</p> <p>Use the single square-shaped mirror (preferred for better resolution over the double mirror).</p> <ol> <li> <p>Attach the Mirror:</p> <ul> <li>Slide the mirror on top of the head coil.</li> <li>There are two ways to align it easily:</li> <li>Click the mirror on and slide it forward to block the calibration light. Then, adjust and insert the volunteer.</li> <li>Align the mirror, click it on, adjust the position, and insert the volunteer.</li> </ul> </li> <li> <p>Volunteer Adjustment:</p> <ul> <li>The volunteer can adjust the mirror themselves if needed by sliding it backward or forward to get a clear view of the screen.</li> </ul> </li> </ol>"},{"location":"research/fmri/fmri-procedure.html#table-calibration","title":"Table calibration","text":"<p>The control panels on the left and right of the scanner have identical functions. Use the same switch to move the table up/down and backward/forward.</p> <ol> <li> <p>Table Height:</p> <ul> <li>If the table is down, raise it by pressing the up button until it stops at the maximum height.</li> </ul> </li> <li> <p>Moving the Table Inside:</p> <ul> <li>Use the up button to move the table inside the scanner.</li> </ul> </li> <li> <p>Eye Protection:</p> <ul> <li>Ask the volunteer to close their eyes and gently cover their eyes with your hand.</li> </ul> </li> <li> <p>Calibration Laser:</p> <ul> <li>Press the button with the light bulb icon to activate the red calibration laser.</li> <li>Line up the laser with the volunteer\u2019s eyebrows.  </li> </ul> <p>Tip</p> <p>If the laser turns off, press the button again to reactivate it.</p> </li> <li> <p>Confirm Coil Position:</p> <ul> <li>Press the button below the light bulb button to confirm the coil's position (a green light will indicate confirmation).</li> <li>The table will move automatically into the scanner when the button is held for a few seconds.</li> </ul> <p>Note</p> <p>Place the mirror on top of the coil before sliding the volunteer into the scanner.</p> </li> </ol>"},{"location":"research/fmri/fmri-procedure.html#common-issues_2","title":"Common Issues","text":"Table Calibration Failed <ul> <li>If the table moves too far inside the scanner, calibration may have failed. Slide the table out of the scanner, recalibrate, and try again.</li> <li>If the scanner light remains on, use the control buttons to switch it off.</li> <li>For fMRI studies, maintain consistent lighting throughout the session by using the outer circle on the control panel to switch the light on or off.</li> </ul> Green Calibration Light Already On <ul> <li>If the green calibration light is already on before positioning the table correctly, move the table out of the scanner to reset the calibration. The light will turn off, allowing you to restart the calibration process.</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#inserting-the-volunteer-into-the-scanner","title":"Inserting the Volunteer into the Scanner","text":"<ol> <li> <p>Move the Table:</p> <ul> <li>Use the backward/forward switch to move the table into the scanner. The table will stop automatically when it reaches the correct position according to the calibration.</li> </ul> </li> <li> <p>Cable Management:</p> <ul> <li>Hold the cables while moving the volunteer to prevent them from stretching.</li> </ul> </li> <li> <p>Comfort Check:</p> <ul> <li>Ensure the volunteer is comfortable in the scanner, without crossed arms or legs (to avoid forming current loops).</li> <li>Make sure no metal or wires are touching the volunteer\u2019s skin or the bore of the scanner.</li> <li>No wires should be looped within the scanner bore.</li> </ul> </li> </ol>"},{"location":"research/fmri/fmri-procedure.html#common-issues_3","title":"Common Issues","text":"Mirror Doesn\u2019t Fit in the Bore <ul> <li>Check if the washcloths are stuck between the edges of the coil, as this could lift the coil's top.</li> <li>Ensure the bottom part of the coil is properly slotted into the grooves on the table.</li> </ul> Table Doesn\u2019t Move <ul> <li>The table might be disconnected. Press the button located at the bottom right, next to the red button (Button 2), to reconnect the table.</li> </ul> Table Moves Too Far Inside Scanner <p>If the table moves too far inside the scanner, it indicates a calibration failure:</p> <ol> <li>Slide the table out of the scanner.</li> <li>Recalibrate the patient\u2019s position using the calibration laser.</li> </ol>"},{"location":"research/fmri/fmri-procedure.html#screen-visibility","title":"Screen Visibility","text":"<p>Before leaving the room, check the following:</p> <ul> <li>Ask the volunteer if the screen is fully visible and centered.</li> <li>Check the screen yourself to ensure it is aligned with the black marks on the scanner table.</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#eyetracker-setup","title":"Eyetracker Setup","text":""},{"location":"research/fmri/fmri-procedure.html#positioning-the-participant","title":"Positioning the Participant","text":"<ol> <li>Use the square mirror with front reflection.</li> <li>Position the participant\u2019s head as high as possible in the coil (to reduce shadows on the face).</li> <li>Support the participant\u2019s neck with washcloths to tilt the head back for better eye visibility.</li> </ol>"},{"location":"research/fmri/fmri-procedure.html#eyetracker-startup","title":"Eyetracker Startup","text":"<ol> <li> <p>Scanner area:</p> <ul> <li>Connect the eyetracker plug to the power supply (marked with a white tag: \u201ceyetracking\u201d).</li> <li>Ensure the screen is aligned with the EYE line.</li> <li>Check if the eyetracker setup is aligned with the floor marks.</li> </ul> </li> <li> <p>Control room - Eyetracker PC:</p> <ul> <li>Boot the Eyelink software (default option in the Windows Boot Manager).</li> <li>If Eyelink doesn\u2019t start, press <code>t</code> followed by Enter to launch it manually.</li> </ul> </li> <li> <p>Control room - Stimulus PC:</p> <ul> <li>Open the track2popup to view the eye on the screen and adjust the sharpness.</li> </ul> </li> </ol>"},{"location":"research/fmri/fmri-procedure.html#eyelink-camera-setup","title":"Eyelink Camera Setup","text":"<ol> <li>Press <code>ENTER</code> to begin Camera Setup.</li> <li>Adjust the camera position by holding a finger in front of it to check where it\u2019s pointing.</li> <li>Ensure both the pupil and corneal reflex (CT) are well-detected.</li> <li>Adjust the pupil threshold using the up/down arrows for the clearest possible image.</li> </ol>"},{"location":"research/fmri/fmri-procedure.html#calibration-validation","title":"Calibration &amp; Validation","text":"<ol> <li> <p>Calibration:</p> <ul> <li>Before starting Smartbrain, ensure the participant is in the optimal head position for calibration.</li> <li>Press <code>C</code> to start calibration, and guide the participant to focus on the dots.</li> <li>When the word \"stable\" appears, press <code>SPACEBAR</code> 9 times for each point.</li> </ul> </li> <li> <p>Validation:</p> <ul> <li>Press <code>V</code> to start validation, guiding the participant to focus on the dots.</li> <li>If successful, press ACCEPT. If validation fails, recalibrate if needed.</li> </ul> </li> <li> <p>Recording:</p> <ul> <li>Open a new file before each functional run and press RECORD at the start of the run.</li> <li>Stop recording by pressing CLOSE FILE at the end of the run.</li> </ul> </li> </ol> <p>Controlling EyeLink</p> <p>It is advisable to control the calibration, validation, recordings and data collection from the script you use for your fMRI task.</p>"},{"location":"research/fmri/fmri-procedure.html#common-issues_4","title":"Common Issues","text":"CalPopUp2 Issues <p>If CalPopUp2 does not start properly (errors or failure to create a new file), restarting the stimulus PC should solve the issue.</p> Tracking Issues <p>If the eye is not being tracked during camera setup: - Ask the participant to adjust the mirror for better light. - Add washcloths under their neck to tilt the head back for a clearer view.</p>"},{"location":"research/fmri/fmri-procedure.html#prepare-and-start-scanning","title":"Prepare and Start Scanning","text":""},{"location":"research/fmri/fmri-procedure.html#communication-with-the-volunteer","title":"Communication with the Volunteer","text":"<ul> <li>Ask if they are OK before starting.</li> <li>Test the response buttons: Ask the volunteer to press each relevant button one by one, and check the responses on the screen.</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#prepare-the-scanner","title":"Prepare the Scanner","text":"<ol> <li> <p>New Examination:</p> <ul> <li>Select \"Patient \u2013 New Examination\".</li> <li>Choose RIS to load the volunteer's details. Their data (name, ID, birthdate, sex, and exam) will be automatically filled in.</li> </ul> </li> <li> <p>Volunteer Information:</p> <ul> <li>Enter the volunteer\u2019s weight (from the MR Safety Checklist).</li> <li>For women: Answer no for pregnancy.</li> <li>For both men and women: Answer no for implants.</li> <li>Anatomical images are sent automatically to PACS with the correct identification.</li> </ul> </li> <li> <p>Proceed:</p> <ul> <li>Click Proceed to start setting up the exam.</li> </ul> </li> </ol> <p>Lighting Change</p> <p>Starting a new exam will automatically switch on the outer light circle of the scanner. You may want to switch it off manually.</p> <p>Lighting for fMRI Studies</p> <p>Keep the same light settings throughout the entire fMRI study. - The center button turns the light on or off. - Swipe around the center button to dim the lights.</p>"},{"location":"research/fmri/fmri-procedure.html#select-your-exam-card","title":"Select Your Exam Card","text":"<ol> <li> <p>Loading the Exam Card:</p> <ul> <li>To set up an exam card, contact Ron Peeters.</li> <li>Exam cards are stored under <code>/hospital/Research/</code> with names in the format: S-number and Researcher\u2019s Name.</li> <li>Press the + next to the exam card name or drag it to the left of the window.</li> <li>To copy sequences, right-click on the sequence and choose copy. Right-click again to paste (or use shortcuts: <code>Ctrl+C</code> and <code>Ctrl+V</code>).</li> </ul> </li> <li> <p>Standard Exam Setup:</p> <ul> <li>Load the following sequences:</li> <li>Smartbrain</li> <li>Check_fMRI</li> <li>Then your own sequences, such as:<ul> <li>fMRI protocol N=4 (use this to check slice position and timing)</li> <li>fMRI protocol N=X (number of dynamic scans in the actual study)</li> </ul> </li> </ul> </li> </ol>"},{"location":"research/fmri/fmri-procedure.html#common-issues_5","title":"Common Issues","text":"Participant Can\u2019t Be Found in CP <ol> <li>Start a new examination by going to Patients &gt; New Examination.</li> <li>Update the patient list by clicking RIS Configuration, then Proceed.</li> <li>Close the New Examination window and reopen it via Patients &gt; New Examination &gt; RIS.</li> </ol> <p>If no one is available to help, manually fill in the participant's details and send an email to Ron with the following information:</p> Field Value Patient Name Participant's name Registration ID Same as patient name Birthday 01-01-(year of birth) Sex Participant's sex Exam Name Same as patient name Weight Weight from MR Safety Checklist"},{"location":"research/fmri/fmri-procedure.html#start-scanning","title":"Start Scanning","text":"<ol> <li> <p>Smartbrain:</p> <ul> <li>Double-click Smartbrain \u2192 Proceed \u2192 Start scan.</li> </ul> </li> <li> <p>Check fMRI:</p> <ul> <li>After Smartbrain finishes, start Check fMRI.</li> <li>The scan frame should contain the whole brain.</li> <li>Accept \u2192 Proceed.</li> </ul> </li> <li> <p>fMRI Protocol:</p> <ul> <li>Double-click your fMRI sequence.</li> <li>Ensure the scan frame covers the area of interest (whole brain or region of interest).</li> <li>Accept the frame and proceed to start the experiment on the Stimulus PC.</li> </ul> </li> </ol> <p>Don\u2019t Forget</p> <ul> <li>Always press Proceed before starting the scan. Any changes made in the tabs won\u2019t take effect unless Proceed is clicked.</li> <li>Ensure consistent TR, slices, and settings within and between participants.</li> <li>Start the experiment on the Stimulus PC before proceeding on the scanner, to avoid missing the trigger.</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#common-issues_6","title":"Common Issues","text":"Door Not Closed Properly <p>Ensure both the door to the technical room and the scanner door are securely closed. Improperly closed doors will trigger error messages and prevent scanning from starting.</p> Patient position on the table is unknown <p>If you encounter the error message \"Patient position on the table is unknown\":</p> <ul> <li>Return to the scanner room and recalibrate the patient\u2019s position using the laser alignment system.</li> <li>Ensure that the calibration laser is correctly aligned and restart the scan.</li> </ul> Scanner Light Still On <p>If the scanner light remains on, adjust it using the control buttons.</p> <p>For fMRI studies, ensure the lighting remains consistent throughout the session. Use the outer circle on the control panel to turn the light off or dim it as needed.    </p> Pixelated Image After Reference Scan <p>If the reference scan shows a pixelated image with only the skull contours visible, the top of the coil may not be properly mounted.</p> <ul> <li>Slide the volunteer out of the scanner.</li> <li>Ensure that the coil is securely closed before attempting to recalibrate.</li> </ul> Ventilation Too Low <p>If the ventilation error appears during Smartbrain, the system requires a minimum ventilation setting of 3.</p> <ul> <li>You can either proceed without adjusting the setting or adjust ventilation via Examination &gt; Adjust Ventilation in the scan console.</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#anatomical-scan","title":"Anatomical Scan","text":"<p>If you need to collect only an anatomical scan, you still must run the standard scans first (refer to the section above).</p> <p>You have two options for scheduling the anatomical scan:</p> <ul> <li>At the end of the session</li> <li>Interleaved with fMRI sequences (to give participants a break)</li> </ul> <p>During the anatomical run, participants can:</p> <ul> <li>Close their eyes</li> <li>Watch a movie (You can present a YouTube video via the stimulus computer).</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#checking-for-movement","title":"Checking for Movement","text":"<p>After an fMRI run finishes:</p> <ol> <li>Drag the sequence name to one of the boxes on the right of the scan console screen.</li> <li>An image of the run will appear.</li> <li>Scroll through the slices and play the time series of images (use the play button at the top of the window).</li> <li>Review the time series to check for any participant movement.</li> </ol>"},{"location":"research/fmri/fmri-procedure.html#exporting-data","title":"Exporting Data","text":"<p>You can export data using either Nifti/PAR-REC or DICOM formats. Choose the method that suits your needs.</p> <p>Faster Export Method</p> <p>For faster and more reliable data transfer, insert your USB key or hard drive into the computer in the technical room, rather than the scan console.</p>"},{"location":"research/fmri/fmri-procedure.html#nifti-or-par-rec-export","title":"Nifti or PAR-REC Export","text":"<ol> <li>Go to Patients &gt; Administration in the scan program.</li> <li>Locate your participant\u2019s name in the patient administration window.</li> <li>Double-click the name and select the runs to export.</li> <li>Click Disk Files.</li> <li>Navigate to the Non-Dicom Export tab.</li> <li>Choose an export file name and format.</li> <li>(Optional) Check the Sort box, but ensure consistency (either always check it or never).</li> <li>Press Proceed to start the export.</li> <li>Verify the exported files in the export folder on the FTP drive. Double-check the file sizes to ensure all volumes were exported correctly.</li> </ol> <p>To monitor export progress, navigate to:</p> <ul> <li>Patients &gt; Administration &gt; Manage Job Queue</li> </ul> <p>Avoid Exporting Incomplete Runs</p> <p>Never export data from a run that is still in progress. The export list will not refresh automatically. Press the Refresh button, or reopen the window after part of the data has been exported</p>"},{"location":"research/fmri/fmri-procedure.html#dicom-export","title":"DICOM Export","text":"<ol> <li>Go to Patients &gt; Administration in the scan program.</li> <li>In the patient administration window, locate the participant\u2019s name.</li> <li>Double-click the name and select the runs to export.</li> <li>Click Disk Files.</li> <li>Select a directory to save the data.</li> <li>Choose between Nifti, Enhanced (4D DICOM) or Classic (2D DICOM) format (each slice saved as a separate file).</li> <li>Press Proceed to start the export.</li> </ol> <p>Anonymization Option</p> <p>For privacy reasons, it is recommended to anonymize the dataset by giving the exported data a code name (possibly the subject number in BIDS format, e.g., <code>sub-01</code>).</p> <p>Handling Export Delays</p> <p>It may take some time before the export starts. If you see a warning about exporting a large number of images, simply press Proceed to confirm.</p> <p>To track export progress, navigate to:</p> <ul> <li>Patients &gt; Administration &gt; Manage Job Queue</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#common-issues_7","title":"Common Issues","text":"Not Enough Free Disk Space <p>If files do not export properly (e.g., incorrect sizes), it may indicate that the export drive has insufficient space.</p> <ol> <li>Check the available disk space by right-clicking the Export drive and selecting Properties.</li> <li>If the drive is full, delete old data such as PAR-REC, Nifti, or DICOM files. These files can be re-exported later, so no data will be permanently lost.</li> </ol> Local Patient Database Near Full Capacity <p>If the local patient database is nearly full (90-100% capacity), scanning may not proceed.</p> <ol> <li>Navigate to Patients &gt; Administration in the scan program.</li> <li>Check the percentage of disk space used (displayed in the top-right corner).</li> </ol> <p>Freeing Space</p> <ul> <li>Delete previous participant data only after confirming that it has been exported and transferred without corruption.</li> <li>Alternatively, ask for help from an MR technician to delete unnecessary data.</li> </ul> Missing Export Window <p>If the export window doesn\u2019t appear, press the Windows key to reveal the taskbar and locate the hidden export window.</p> Export Progress Stalled <p>If DICOM exports seem to have stalled, navigate to Manage Job Queue and check that the dropdown menu is set to Enabled.</p> Safe Ejection of External Drives <p>If you are unable to safely eject your external drive:</p> <ol> <li>Log off the scanner computer to shut down the scanning software.</li> <li>Log back in using MRService credentials.</li> <li>Restart the scanning software and acknowledge any helium pressure alarms.</li> <li>Once done, you can safely eject the external drive.</li> </ol> External Drive Not Detected <p>If the external drive is not detected in the Devices and Drives window:</p> <ol> <li>Log off and log back in using the MRService credentials.</li> <li>Check again in the Devices and Drives window to see if the external drive appears.</li> </ol>"},{"location":"research/fmri/fmri-procedure.html#after-scanning","title":"After Scanning","text":""},{"location":"research/fmri/fmri-procedure.html#scanner-area","title":"Scanner Area","text":"<p>When finishing a session, ensure the scanner area is returned to its original state. Follow these steps:</p> <ol> <li> <p>Move the volunteer out of the scanner:</p> <ul> <li>Use the up/down and backward/forward buttons to lower the table, allowing the volunteer to comfortably get off the table.</li> </ul> </li> <li> <p>Organize the equipment:</p> <ul> <li>Button box: Place the button box back in the cabinet to the right of the scanner.</li> <li>Panic button: Leave it at the end of the patient table.</li> <li>Mirror: Return the square mirror to the shelf and replace it with the curved mirror (do not touch the mirror itself).</li> <li>Top of the coil: Leave it inside the scanner (keep the bottom part plugged in and on the table).</li> <li>Washcloths: Dispose of the used washcloths in the transparent white bag near the door.</li> <li>Headphones: Hang the white headphones back on the hook at the front of the scanner.</li> <li>Earplugs: Dispose of them in the blue bag near the door.</li> <li>Paper towels: Throw away any used paper towels in the blue bag.</li> </ul> </li> <li> <p>Cleaning:</p> <ul> <li>Use the disinfectant provided in the MRI magnet room to wipe down the MRI system table.</li> <li>Cushions and equipment: Ensure no equipment is left on the floor. If you find anything on the floor, place it on a shelf.</li> </ul> </li> <li> <p>Turn off the projector:</p> <ul> <li>Go to the technical room and use the remote control to switch off the projector.</li> </ul> </li> <li> <p>If clinical scans follow your session:</p> <ul> <li>Remove the projection screen from the scanner bore and place it safely inside the scanner room (e.g., against the wall).</li> <li>Change the filter back to the default setting (3NB).</li> </ul> </li> </ol>"},{"location":"research/fmri/fmri-procedure.html#control-room","title":"Control Room","text":""},{"location":"research/fmri/fmri-procedure.html#stimulus-pc_1","title":"Stimulus PC","text":"<ul> <li>Collect your data from the stimulus PC.</li> <li>Turn off the screen (but do not shut down the computer).</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#scan-console","title":"Scan Console","text":"<ol> <li> <p>Verify data export:</p> <ul> <li>Ensure all data has been exported.</li> <li>Check the file sizes to confirm all files were exported correctly (files should have similar sizes; if some are smaller, they may still be exporting).</li> </ul> </li> <li> <p>Clear the screen:</p> <ul> <li>Select Patient &gt; Close \"participant name\" to clear the participant's data from the screen.</li> <li>Turn off the screen (do not shut down the computer).</li> </ul> </li> </ol>"},{"location":"research/fmri/fmri-procedure.html#check-out-procedures","title":"Check-out Procedures","text":"<p>Before leaving the department, complete the check-out part of the check-in/out form:</p> <ol> <li>Fill out the check-out section of the form.</li> <li>Leave the form with the other documents, along with the MRI safety questionnaire.</li> <li>Report any minor technical incidents on the form and email the MRI Safety Officer: Dr. Ronald Peeters.</li> <li>Incidental abnormalities: Do not inform the participant. Contact Prof. Dr. Stefan Sunaert immediately.</li> </ol>"},{"location":"research/fmri/fmri-procedure.html#if-you-are-the-last-person-scanning-experiments-that-day","title":"If You Are the Last Person Scanning Experiments That Day","text":""},{"location":"research/fmri/fmri-procedure.html#scanner-area_1","title":"Scanner Area","text":"<ul> <li>Use alcohol wipes to clean the patient table.</li> <li>Put the projection screen on the side, against the wall.</li> <li>Remove the coil from the table and store it in the cabinet.</li> <li>Lock the scanner area (the key is in the control room).</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#control-room_1","title":"Control Room","text":"<ul> <li>Do not shut down the console or stimulus PC!</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#scanning-of-children","title":"Scanning of Children","text":"<ol> <li> <p>Preparation:</p> <ul> <li>Bring biscuits and drinks for the child.</li> <li>Make sure the time slot is long enough so the session is not rushed.</li> <li>Limit scanning sessions to 50 minutes of active tasks with plenty of breaks.</li> </ul> </li> <li> <p>During the session:</p> <ul> <li>Show the child the control room.</li> <li>Go through the MR screening form with the parents and double-check that the child has no metal on their clothes.</li> <li>Ask the child to use the toilet before scanning.</li> </ul> </li> <li> <p>Parental presence:</p> <ul> <li>Parents must stay in the control room during scanning. Once the scanning has started, they should wait in the waiting area outside the scanner.</li> <li>If the child is too scared, they can be accompanied by a parent into the scanner room (ensure the parent removes all metal and wears earplugs and headphones).</li> <li>Once the child is calm, the parent can leave the scanner room.</li> </ul> </li> <li> <p>Communicating with the child:</p> <ul> <li>Explain that you will talk to them via the intercom.</li> <li>Let them know they can speak when prompted and need to stay quiet otherwise.</li> <li>Use simple, reassuring language:<ul> <li>Call the coil a \u201chelmet.\u201d</li> <li>Explain that the table movement is like being on a ride.</li> <li>Tell them about the lights being off during scanning and that they need to stay very still.</li> </ul> </li> </ul> </li> <li> <p>Head positioning:</p> <ul> <li>Fixate the child\u2019s head with washcloths on the sides, but avoid too much pressure.</li> <li>Optionally, use tape across the child\u2019s forehead to further secure the head.</li> </ul> </li> <li> <p>Calibration:</p> <ul> <li>Explain that the child must keep their eyes closed during calibration.</li> <li>Cover their eyes with your hand for extra comfort.</li> <li>Ensure the laser is positioned between the child\u2019s eyebrows.</li> </ul> </li> <li> <p>Lighting for children:</p> <ul> <li>Leave a bit of light on during scanning to reduce fear. If needed, use the dimmer switch in the control room.</li> </ul> </li> <li> <p>During scanning:</p> <ul> <li>For structural scans (where functional information isn\u2019t needed), you can play a YouTube video or DVD to keep the child entertained.</li> </ul> </li> <li> <p>Breaks:</p> <ul> <li>Take a break after each run and ask the child how they are feeling.</li> <li>If the tasks change between runs, give the child a short reminder of the instructions.</li> </ul> </li> <li> <p>Post-scan:</p> <ul> <li>After scanning, let the child sit up slowly to avoid dizziness.</li> </ul> </li> </ol>"},{"location":"research/fmri/fmri-procedure.html#auditory-stimuli","title":"Auditory Stimuli","text":""},{"location":"research/fmri/fmri-procedure.html#scanner-room-yellow-headphones","title":"Scanner Room - Yellow Headphones","text":"<ul> <li>The yellow headphones are stored on the left side of the storage space (against the wall).</li> <li>The headphones will present sound at full level only when placed inside the scanner bore.</li> <li>Disconnect the white headphones from the head coil and replace them with the yellow headphones.</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#control-room-microphone","title":"Control Room - Microphone","text":"<p>The microphone is always on, but goes into standby mode after a few seconds.</p> Button Function + / - Buttons Increase/decrease the volume. Menu Button Access various options. Hold it and press the + button to navigate the menu. Grey Button Speak to the participant. <p>Activate the fMRI settings by holding the Menu button and pressing + to navigate to the fMRI option.</p>"},{"location":"research/fmri/fmri-procedure.html#control-room-amplifier-and-converter","title":"Control Room - Amplifier and Converter","text":"<ul> <li>Check that the red and white plugs (audio cables to the headphones) are connected to the converter.</li> <li>Ensure the power cable is plugged in next to the red and white plugs.</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#common-issues_8","title":"Common Issues","text":"Participant Can't Hear You <ul> <li>Reboot the amplifier by unplugging the power cable underneath the desk.</li> <li>Reboot the converter by unplugging its power cable.</li> </ul> Volume Imbalance (left/right) <ul> <li>Adjust the balance via the Menu button. Hold it and use \u00b1 to adjust levels separately.</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#in-case-of-emergency","title":"In Case of Emergency","text":""},{"location":"research/fmri/fmri-procedure.html#seeing-an-abnormality-on-brain-images","title":"Seeing an Abnormality on Brain Images","text":"<p>Do not disclose concerns to the volunteer</p> <p>Avoid causing unnecessary distress to the volunteer. False alarms can arise from misinterpretations.</p> <p>If you detect a potential abnormality:</p> <ol> <li>Report the concern immediately to Dr. Stefan Sunaert. If unavailable, contact the radiologist on call.</li> <li>Supply a copy of the image showing the suspected abnormality.</li> <li>Make a note of the finding in the Check-out part of the Check-In/Out form.</li> </ol>"},{"location":"research/fmri/fmri-procedure.html#emergency-procedures","title":"Emergency Procedures","text":"<p>In case of an emergency involving the MRI system or facility:</p>"},{"location":"research/fmri/fmri-procedure.html#equipment-malfunction","title":"Equipment Malfunction","text":"<ul> <li>If the use of facility equipment results in an accident, immediately notify certified MR personnel (MR technicians or radiologist) and the MRI Safety Officer.</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#system-failure","title":"System Failure","text":"<ul> <li> <p>If part of the system fails and poses a danger to the volunteer:</p> </li> <li> <p>Remove the volunteer from the scanner.</p> </li> <li>Seek help from certified MR personnel.</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#emergency-magnet-shutdown-quenching","title":"Emergency Magnet Shutdown (Quenching)","text":"Magnet Quenching <p>Emergency shutdown of the magnet (quenching) must only be performed by authorized personnel in the following life-threatening situations:</p> <ul> <li>If the magnetic field poses an immediate danger to a person.</li> <li>If emergency services need access to the Inner Controlled Area with ferromagnetic equipment.</li> </ul>"},{"location":"research/fmri/fmri-procedure.html#in-case-of-fire","title":"In Case of Fire","text":"<p>Danger</p> <p>Do not bring ferromagnetic fire extinguishers into the Inner Controlled Area (risk of projectile hazard). Use fire extinguishers marked with a YELLOW ribbon, which are non-ferromagnetic (aluminum).</p> <ol> <li>Call emergency number 2580. Clearly indicate the location: \"MRI Suite MR8\".</li> <li>Do not take unnecessary risks. Only perform one extinguishing attempt.</li> <li>Close doors to the endangered area once all persons are evacuated.</li> <li>Evacuate the area, using emergency exits if necessary.</li> <li>Follow instructions from the fire crew without taking further risks.</li> </ol>"},{"location":"research/fmri/fmri-procedure.html#in-case-of-reanimation","title":"In Case of Reanimation","text":"<ol> <li>Seek immediate assistance from the ASU.</li> <li>Call emergency number 1000. Clearly state the location: \"MRI Suite MR8\".</li> </ol>"},{"location":"research/fmri/analysis/index.html","title":"fMRI Analysis Overview","text":"<p>This section of the wiki provides a comprehensive guide for analyzing fMRI data. Follow the steps below to ensure smooth data processing, from environment setup to advanced multi-variate pattern analysis (MVPA).</p>"},{"location":"research/fmri/analysis/index.html#analysis-steps-overview","title":"Analysis Steps Overview","text":"<ul> <li> <p> General Information   Overview of the pipeline, including key terminology and data structure. Start here to get a sense of the entire workflow.</p> </li> <li> <p> Setting Up the Environment   Install essential tools and software like Docker, fMRIPrep, and SPM to prepare your analysis environment.</p> </li> <li> <p> Converting Data to BIDS   Organize your raw data in the BIDS format for compatibility with neuroimaging tools. Includes step-by-step instructions for converting and validating your dataset.</p> </li> <li> <p> Preprocessing &amp; QA   Perform quality control and preprocess your data using tools like fMRIPrep and MRIQC to ensure it's ready for statistical analysis.</p> </li> <li> <p> First-Level Analysis   Model brain activity using the General Linear Model (GLM) in SPM. Set up contrasts and extract statistical values.</p> </li> <li> <p> Regions of Interest (ROIs)   Create and analyze regions of interest for targeted brain analysis. ROIs are crucial for advanced analyses like MVPA.</p> </li> <li> <p> Multi-Variate Pattern Analysis (MVPA)   Decode complex neural patterns using machine learning methods like SVM. Analyze brain activity across different conditions.</p> </li> <li> <p> Complete Workflow Example   An end-to-end guide that ties everything together, providing an example of a full fMRI analysis pipeline.</p> </li> </ul>"},{"location":"research/fmri/analysis/index.html#additional-resources","title":"Additional Resources","text":"<ul> <li> <p>BIDS Starter Kit   Learn more about the BIDS format and how to structure your datasets.</p> </li> <li> <p>SPM Documentation   Dive into SPM resources to get the most out of your GLM analyses.</p> </li> <li> <p>CoSMoMVPA Documentation   Explore multi-variate pattern analysis techniques with CoSMoMVPA.</p> </li> </ul>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html","title":"fMRI workflow example","text":"<p>This page is a work in progress and is based on my (Andrea) fMRI pipeline. This information may change once we agree on shared practices.</p> <p>The code to reproduce these analyses can be found here.</p> <p>For information on how to set up the working environment, install, and configure the packages mentioned in this document, refer to Set-up your fMRI environment and Coding practices</p>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#from-raw-data-to-bids","title":"From Raw Data to BIDS","text":""},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#collecting-raw-data","title":"Collecting Raw Data","text":"<p>Note</p> <p>It is essential to ensure that no personal identifiers are present in any of the files that leave the hospital. Use my script for anonymizing filenames and data.</p> <p>At the hospital:</p> <ul> <li>Take fMRI scans from the hospital computer. Specify which buttons to select in the GUI.</li> <li>Anonymize the filenames using my script to ensure subject privacy.</li> <li>Extract behavioral (bh) and eye-tracking (et) data from the output folders on the experiment PC.</li> <li>Copy all files into a <code>sourcedata/</code> folder organized with subfolders: <code>bh</code>, <code>nifti</code>, and <code>et</code>.</li> </ul>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#converting-fmri-data-to-bids","title":"Converting fMRI Data to BIDS","text":""},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#step-1-preparing-for-the-first-subject","title":"Step 1: Preparing for the First Subject","text":"<p>Info</p> <p>This step should only be performed for the first subject in your dataset. It can be skipped if anatomical and functional JSON templates are already available in <code>code/misc/</code>. See this guide for more info on the template files.</p> <ol> <li> <p>Convert DICOM to BIDS (NIfTI):</p> <ol> <li> <p>Prerequisites:</p> <ul> <li><code>dcm2nii</code></li> <li>Raw data should be organized as: <code>/sourcedata/sub-&lt;xx&gt;/dicom</code></li> <li>MATLAB</li> </ul> </li> <li> <p>Download <code>dicm2nii</code> from dicm2nii, unzip, and add to the MATLAB path.</p> </li> <li> <p>Open MATLAB and type <code>anonymize_dicm</code> in the console. Select the folder where the files are and the output folder: <code>/sourcedata/sub-&lt;xx&gt;/dicom_Anon</code>.</p> </li> <li> <p>Run <code>dicm2nii</code> in MATLAB. Select the DICOM folder and result folder (e.g., <code>dicom_converted</code>). Untick the compress box and ensure to save the JSON file.</p> </li> </ol> <p>The output folder structure should be as follows:</p> <pre><code>dicom_converted\n\u251c\u2500\u2500 sub-01\n\u2502   \u251c\u2500\u2500 anat\n\u2502   \u2502   \u251c\u2500\u2500 sub-01_T1w.json\n\u2502   \u2502   \u2514\u2500\u2500 sub-01_T1w.nii.gz\n\u2502   \u251c\u2500\u2500 func\n\u2502   \u2502   \u251c\u2500\u2500 sub-01_task-exp_run-1_bold.json\n\u2502   \u2502   \u2514\u2500\u2500 sub-01_task-exp_run-1_bold.nii.gz\n\u2502   \u2514\u2500\u2500 dcmHeaders.mat\n\u2514\u2500\u2500 participants.tsv\n</code></pre> <ul> <li>Copy the <code>sub-01</code> folder from <code>dicom_converted</code> into the BIDS folder.</li> </ul> </li> <li> <p>Validate the BIDS Directory:</p> <ul> <li>Use the BIDS Validator to check for any errors.</li> </ul> </li> </ol>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#step-2-processing-subsequent-subjects","title":"Step 2: Processing Subsequent Subjects","text":"<p>If the raw data is organized in a <code>sourcedata/sub-xx</code> folder, and JSON templates are already created:</p> <ul> <li>Anonymize/deface the images.</li> <li>Run <code>script01</code> to move and rename the raw files into the BIDS folder, creating a <code>sub-xx</code> folder for each subject.</li> </ul>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#converting-behavioral-data-to-bids","title":"Converting Behavioral Data to BIDS","text":"<ul> <li>Run <code>script02</code> to convert behavioral <code>.mat</code> data into <code>events.tsv</code> files following the BIDS specification. This will parse the trial data from the <code>.mat</code> file and create new <code>.tsv</code> files for each subject and run.</li> </ul> <p>The fMRI task script should output two files per run:</p> <ol> <li> <p><code>&lt;timestamp&gt;_log_&lt;subID&gt;-&lt;run&gt;-&lt;buttonMapping&gt;_&lt;taskName&gt;.tsv</code> : This is the human-readable log file produced by the task. Here is an extract from the file:</p> EVENT_TYPE EVENT_NAME DATETIME EXP_ONSET ACTUAL_ONSET DELTA EVENT_ID START - 2024-05-03 10:49:43.099 - 0 - - FLIP Instr 2024-05-03 10:50:11.399 - 28.300201 - - RESP KeyPress 2024-05-03 10:50:34.160 - 51.063114 - 51 FLIP TgrWait 2024-05-03 10:50:34.216 - 51.117046 - - PULSE Trigger 2024-05-03 10:50:40.000 - 56.904357 - 53 </li> <li> <p><code>&lt;timestamp&gt;_log_&lt;subID&gt;_&lt;run&gt;_&lt;taskName&gt;.mat</code>: This MATLAB file contains all the parameters to reproduce the experimental run, and stores input parameters and results.</p> </li> </ol> <p>Ensure that each resulting TSV file has at least three columns: <code>onset</code>, <code>duration</code>, and <code>trial_type</code>.</p> <p>If the behavioural data is stored in a sourcedata/sub-xx/bh/ folder consistent to the one described above, you can run the script02_behavioural-to-BIDS.m script, after editing the parameters at the top of the script. This script iterates through subject-specific directories targeting behavioral .mat files, then processes and exports trial-related info into BIDS-compliant TSV event files in the BIDS folder provided as parameters.</p>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#converting-eye-tracking-data-to-bids","title":"Converting Eye-Tracking Data to BIDS","text":"<p>Pre-requisite: Install the EyeLink Developers Kit/API to convert EDF files into ASC files. Refer to the official setup guide:</p> <ul> <li> <p>EyeLink Developers Kit/API</p> </li> <li> <p>Run the eye-tracking (ET) conversion script to convert the data to ASC in BIDS format.</p> <p>Warning</p> <p>BEP020 has not been approved yet. Consider whether event messages should be included in the BIDS structure.</p> </li> </ul>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#pre-processing-fmri-data-in-bids-format","title":"Pre-processing fMRI Data in BIDS Format","text":""},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#quality-control-with-mriqc","title":"Quality Control with MRIQC","text":"<p>Use MRIQC to perform quality control checks on your fMRI data:</p> mriqc_batch.sh<pre><code>#!/bin/bash\nfor i in {0..40}; do\n    if [ $i -eq 0 ] || [ $i -eq 5 ] || [ $i -eq 14 ] || [ $i -eq 31 ]; then\n        continue\n    fi\n    subID=$(printf \"sub-%02d\" $i)\n    echo \"Processing $subID\"\n    docker run -it --rm \\\n        -v /data/BIDS:/data:ro \\\n        -v /data/BIDS/derivatives/mriqc:/out \\\n        -v /temp_mriqc:/scratch \\\n        nipreps/mriqc:latest /data /out participant \\\n        --participant-label ${subID} \\\n        --nprocs 16 --mem-gb 40 --float32 \\\n        --work-dir /scratch \\\n        --verbose-reports --resource-monitor -vv\n    sleep 0.5\ndone\n\necho \"Running group analysis\"\ndocker run -it --rm \\\n    -v /data/BIDS:/data:ro \\\n    -v /data/BIDS/derivatives/mriqc:/out \\\n    -v /temp_mriqc:/scratch \\\n    nipreps/mriqc:latest /data /out group \\\n    --nprocs 16 --mem-gb 40 --float32 \\\n    --work-dir /scratch \\\n    --verbose-reports --resource-monitor -vv\n\nsleep 0.5\n\necho \"Running classifier\"\ndocker run \\\n    -v /temp_mriqc:/scratch \\\n    -v /data/BIDS/derivatives/mriqc:/resdir \\\n    -w /scratch --entrypoint=mriqc_clf poldracklab/mriqc:latest \\\n    --load-classifier -X /resdir/group_T1w.tsv\n</code></pre> <p>Warning</p> <p>JSON files may include <code>NaN</code> values that are incompatible with MRIQC. Use <code>./utils/sanitize_json.py</code> to fix this issue before running MRIQC.</p>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#minimal-preprocessing-with-fmriprep","title":"Minimal Preprocessing with fMRIprep","text":"<p>With your BIDS data organized, the next step is preprocessing using fMRIprep:</p> <ul> <li>Install Docker (and WSL if on Windows) and configure it for use with fMRIprep.</li> <li>Install <code>fmriprep-docker</code> with <code>pip install fmriprep-docker</code>.</li> <li>Ensure Docker has access to the folders you will be using (e.g., BIDS folder, temporary work directory).</li> </ul> <p>To run <code>fmriprep</code> for a single subject, use the following command:</p> <pre><code>fmriprep-docker /data/projects/chess/data/BIDS /data/projects/chess/data/BIDS/derivatives/fmriprep participant \\\n    --work-dir //data/projects/chess/data/temp_fmriprep --mem-mb 10000 --n-cpus 16 \\\n    --output-spaces MNI152NLin2009cAsym:res-2 anat fsnative \\\n    --fs-license-file /data/projects/chess/misc/.license \\\n    --bold2t1w-dof 9 --task exp --dummy-scans 0 \\\n    --fs-subjects-dir /data/projects/chess/data/BIDS/derivatives/fastsurfer \\\n    --notrack --participant-label 41\n</code></pre> Use CIFTI output for surface data <p>If you plan to run analysis on surface data, consider using CIFTI output images from fMRIPrep. While this approach hasn't been directly tested here, CIFTI outputs can provide several advantages:</p> <ul> <li>Surface analysis in SPM (see this conversation on Neurostars).</li> <li>CIFTI images include cortical BOLD time series projected onto the surface using templates like the Glasser2016 parcellation (which is also used for MVPA).</li> <li>This method allows for direct analysis of surface data in formats like <code>.gii</code>, which can be compatible with SPM for further analysis.</li> <li>Using CIFTI outputs could simplify the process of obtaining surface-based parcellations and make the data more directly usable in subject space, potentially eliminating the need for complex and time-consuming transformations.</li> <li>It may also provide a more accurate representation of cortical activity by avoiding interpolation errors that can occur when mapping from volume to surface space.</li> </ul> <p>If you decide to explore this option, make sure to include the cifti falg in <code>--output-spaces</code> when running <code>fmriprep-docker</code>. This setup will produce CIFTI files (<code>.dtseries.nii</code>) along with standard volumetric outputs, giving you flexibility in how you proceed with your analysis.</p> Allocating resources to fMRIprep <p>Running fMRIPrep is resource and time intensive, especially with high-resolution data. Here are some practical tips to optimize the process:</p> <ul> <li>Time Estimate: Processing a single subject can take between 4-8 hours depending on your system's specifications (e.g., CPU, RAM). Plan accordingly if you have many subjects.</li> <li> <p>Optimize Resource Allocation: Adjust the <code>--n-cpus</code> and <code>--mem-mb</code> arguments to make the best use of your available hardware:</p> <ul> <li>n-cpus: Allocate about 70-80% of your CPU cores to avoid system slowdowns (e.g., <code>--n-cpus 12</code> on a 16-core system).</li> <li>mem-mb: Use around 80-90% of your total RAM, leaving some free for the operating system (e.g., <code>--mem-mb 32000</code> on a 40 GB system).</li> </ul> </li> <li> <p>Monitor Resource Usage: While running fMRIPrep, open a system monitor like Task Manager (Windows), Activity Monitor (Mac), or htop (Linux) to observe CPU and memory usage:</p> <ul> <li>Aim for high CPU usage (close to maximum) and RAM usage that is slightly below your system\u2019s capacity.</li> <li>If memory usage exceeds available RAM, the process might crash due to Out of Memory (OOM) errors or cause disk space issues if using a <code>--work-dir</code> that fills up.</li> </ul> </li> <li> <p>Adjust Settings if Necessary: If you encounter OOM errors or the process is slower than expected:</p> <ul> <li>Lower <code>--mem-mb</code>: Decrease memory allocation incrementally (e.g., by 2-4 GB at a time).</li> <li>Reduce <code>--n-cpus</code>: Using fewer cores can help balance the load and prevent crashes.</li> <li>Use a dedicated <code>--work-dir</code>: Specify a work directory on a high-speed SSD or similar to reduce I/O bottlenecks and ensure there's enough disk space for temporary files.</li> </ul> </li> </ul> <p>If the run finishes successfully (check the last line of your terminal output), you should have a new <code>BIDS/derivatives/fmriprep/sub-xx</code> folder. See here for a complete list of outputs generated by fMRIPrep. Make sure that inside your <code>anat</code> and <code>func</code> folders you have all the scans (anatomical and functional for all runs) in the specified spaces. Since we specified <code>fsnative</code> as a space and did not use the <code>--no-recon-all</code> flag, fMRIPrep will also produce surface data in <code>BIDS/derivatives/fastsurfer/sub-xx</code>.</p>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#interpreting-fmriprep-visual-reports","title":"Interpreting fMRIPrep Visual Reports","text":"<p>Check the <code>sub-xx.html</code> report to ensure everything ran smoothly. Pay particular attention to:</p> <ul> <li>Registrations: Verify the alignment between functional and anatomical images.</li> <li>Framewise Displacement (FD) Values: Look for runs with unusually high FD values, as these may indicate motion artifacts or poor data quality.</li> </ul> <p>For more details, refer to the general guidelines outlined here, and to the following links:</p> <ul> <li>fMRIPrep Output Confounds</li> <li>Video on Reviewing fMRIPrep Outputs</li> </ul>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#processing-eye-tracking-data-with-bidsmreye","title":"Processing Eye-Tracking Data with <code>bidsmreye</code>","text":"<p>To process eye-tracking data using <code>bidsmreye</code>, run the following Docker command:</p> <pre><code>docker run -it --rm \\\n    -v /data/projects/chess/data/BIDS/derivatives/fmriprep:/data \\\n    -v /data/projects/chess/temp_bidsmreye:/out \\\n    cpplab/bidsmreye:0.5.0 \\\n    /data /out participant all \\\n    --space T1w \\\n    --reset_database \\\n    --verbose\n</code></pre> <p>Note</p> <p>In my experience, <code>bidsmreye</code> worked only when using the <code>T1w</code> fMRIPrep output space.</p>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#first-level-analysis-general-linear-model-glm","title":"First-Level Analysis \u2013 General Linear Model (GLM)","text":"<p>After preprocessing, proceed to the first-level analysis with the GLM. Running the GLM and setting contrasts is straightforward using <code>script03</code>. Make sure to adjust the following parameters:</p> <ul> <li>Paths:</li> <li><code>fmriprepRoot</code>: Path to the fMRIPrep folder.</li> <li><code>BIDSRoot</code>: Path to your BIDS folder.</li> <li><code>outRoot</code>: Path to save GLM results (ideally in the derivatives folder, in a <code>fmriprep-spm</code> folder).</li> <li> <p><code>tempDir</code>: Directory for temporary files, such as uncompressed or smoothed files.</p> </li> <li> <p>Subject Selection:</p> <p>Leave a new line before listing subjects.</p> </li> <li> <p><code>selectedSubjectsList</code>: A list of integers like <code>[41, 42, 43, 44]</code> or use <code>'*'</code> to analyze all subjects.</p> </li> <li> <p><code>selectedRuns</code>: List of runs to analyze.</p> </li> <li> <p>Contrasts Setup:</p> <pre><code>selectedTasks(1).name = 'exp';  % The name of the task. Must match the task name in your BIDS filenames.\nselectedTasks(1).contrasts = {'Check &gt; No-Check'};  % Name of the contrast.\nselectedTasks(1).weights(1) = struct('C_WILDCARD___WILDCARD_', 1, 'NC_WILDCARD___WILDCARD_', -1);  % Weights for each regressor.\nselectedTasks(1).smoothBool = false;  % Whether to smooth images before GLM. Useful for localizers.\n</code></pre> </li> </ul> <p>If everything is configured correctly, the script will generate new <code>sub-xx</code> folders in your output directory. These folders will contain subdirectories for each analysis task, with <code>beta_000x.nii</code> files for each regressor (including confounds and conditions).</p>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#verifying-the-design-matrix","title":"Verifying the Design Matrix","text":"<p>It is advisable to verify that the design matrix is set up correctly:</p> <ol> <li>Open the SPM GUI by typing <code>spm fmri</code> in the MATLAB Command Window.</li> <li>Click on Results and select the <code>SPM.mat</code> file located in your <code>BIDS/fmriprep-spm/{space}/sub-xx/{task_name}/</code> directory.</li> <li> <p>This will open the SPM Contrast Manager, showing the design matrix and assigned contrasts. Ensure the following:</p> <ul> <li>No overlapping or unusually long conditions.</li> <li>The correct number of runs.</li> <li>Confound regressors are positioned at the end of each run.</li> <li>Contrast weights are assigned correctly.</li> </ul> </li> <li> <p>Select your contrast and click Done.</p> </li> <li>In the next window, set the following options:<ul> <li>Apply masking: None</li> <li>P-value adjustment: None</li> <li>Threshold: <code>0.001</code></li> <li>Extent threshold: <code>0</code></li> </ul> </li> </ol> <p>This will display the results of the contrast (thresholded t-map) on the top right, along with a list of significantly active clusters in the bottom right panel.</p>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#visualizing-activations","title":"Visualizing Activations","text":"<p>To visualize activations on a volume or surface:</p> <ol> <li>Click Display -&gt; overlays... in the SPM GUI.</li> <li>Select sections for volume plotting or render for surface plotting.</li> <li>Choose the subject's anatomical image from <code>BIDS/derivatives/fmriprep/sub-xx/anat</code>.<ul> <li>For volume plots, select the <code>.nii</code> file corresponding to the same space as your GLM (usually MNI).</li> <li>For surface plots, select the pial or inflated brain image.</li> </ul> </li> </ol> <p>Warning</p> <p>SPM cannot read <code>.nii.gz</code> files directly, so you must decompress them into <code>.nii</code> files. This can be done with any decompression tool by right-clicking on the file in your file explorer. Once decompressed, use the SPM GUI to select the <code>.nii</code> file.</p>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#generating-and-organizing-regions-of-interest-rois","title":"Generating and Organizing Regions of Interest (ROIs)","text":""},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#rois-from-functional-localizers","title":"ROIs from Functional Localizers","text":"<p>To run MVPA, you need Regions of Interest (ROIs) to select your voxels. You can obtain ROIs through:</p> <ul> <li>Functional Localizers: Perform a localizer task in the scanner, then run a GLM on the preprocessed and smoothed data. For example, <code>Faces &gt; Objects</code> to identify the FFA.</li> <li>Pre-defined Anatomical Masks: Use anatomical masks in the same space as your subjects (e.g., MNI). Ensure the mask resolution matches the resolution of your data (e.g., resample/reslice if necessary using tools like ANTs, SPM, or Python libraries like nilearn or nibabel).</li> </ul>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#hcp-glasser-parcellation","title":"HCP Glasser Parcellation","text":"<p>In my pipeline, I use the Glasser2016 parcellation projected on <code>fsaverage</code>, which includes 180 ROIs per hemisphere. This process involves converting Glasser parcellation annotation files to labels and mapping them from <code>fsaverage</code> to the subject's T1 and MNI spaces. Use the <code>HPC-to-subject.sh</code> script for automation (see the top of the script file for usage notes).</p>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#multi-variate-pattern-analysis-mvpa","title":"Multi-Variate Pattern Analysis (MVPA)","text":""},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#running-decoding-with-svm","title":"Running Decoding with SVM","text":"<p>After organizing your ROIs, proceed with the MVPA analysis:</p> <ul> <li>Use <code>script04</code> to perform independent cross-validated SVM classification on each subject and ROI.</li> <li>The script outputs decoding accuracy for each ROI of the HCP parcellation.</li> </ul> <p>The results are saved in a <code>BIDS/derivatives/mvpa</code> folder organized according to the BIDS structure. Each subject's folder will contain a <code>.tsv</code> file with the decoding accuracy results.</p>"},{"location":"research/fmri/analysis/fmri-andrea-workflow.html#plotting-and-reporting","title":"Plotting and Reporting","text":"<p>The Glasser parcellation includes parcels at three levels, with each higher level grouping several ROIs into a single ROI. In my pipeline, the analysis is performed at the lowest level (180 parcels per hemisphere), then averaged across ROIs within a larger ROI using <code>script06</code>.</p> <ul> <li>The script computes the significance of each decoding accuracy against chance.</li> <li>It generates plots of significant accuracies on an inflated brain for each grouping level.</li> </ul> <p>For example:</p> <p></p> <p>TODO: Add links to folder structure and/or data. TODO: Add information about defacing/anonymizing raw data (including filenames) using my script. TODO: Improve and add details for the parameters required in the <code>script02_behavioural-to-BIDS.m</code>. TODO: Wrap NIfTI and behavioral data to BIDS conversion into a single script that accepts input arguments. TODO: Provide more details on how behavioral files are saved and on the BIDS structure. TODO: Include references to other commonly used atlases for ROI generation. TODO: Explain how to save and run the <code>mriqc</code> commands. TODO: Refine the phrasing and add more info on the parameters for GLM and contrasts setup. TODO: Possibly include screenshots for better clarity (e.g., code sections).</p>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html","title":"Convert your fMRI data into BIDS format","text":"<p>TODO: [TIM] add figures. It would definitely be nice to show a full tree of an example repostitory, and how it changes at each step of the way.</p>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#bids-standards","title":"BIDS standards","text":"<p>To organize our fMRI dataset, we follow the BIDS Specification.</p> <p>If you are not familiar with the BIDS Specification, the BIDS Starter Kit provides all the information needed to get started, along with example BIDS datasets, Talks and Slides, and most importantly Tutorials.</p> <p>It is crucial that you get familiar with BIDS folders/files naming convention and structure. Most, if not all, the tools we are going to use in the next steps are BIDS Apps, and they rely on data organized following the BIDS Specification. Following this structure will make it easier to use these tools, share your code and data, and communicate with other scientists.</p> <p>The BIDS Specification provides guidelines on how to organize all your data formats, including (f/d)MRI, EEG, eye-tracking, Task events associated with Neuro-Imaging recordings or not, and Derivatives (e.g., pre-processed files, Regions Of Interest mask files, GLM files, etc.).</p> <p>At any moment, you can check your dataset for BIDS compliance. To do so, you can use the BIDS dataset validator.</p>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#bids-conversion-overview","title":"BIDS Conversion Overview","text":"<p>After scanning participants, you'll obtain data from two primary sources:</p> <ol> <li>The scanner: Functional and structural outputs (<code>.nii</code> files), alongside potential <code>dicom</code> files</li> <li>The stimulus presentation computer: Behavioural outputs (mainly <code>log</code> files and <code>.mat</code> files) and potentially eye-tracking data</li> </ol> <p>Your first step is to organize these files in a <code>sourcedata</code> folder. Follow the structure outlined in How to store raw data. Once your data is properly arranged, you can proceed to anonymize it and convert it to BIDS format.</p> <p>Here's a high-level overview of the steps involved in arranging your data in a BIDS-compatible way. While this provides a general understanding, most of these steps should be performed using the code provided in each sub-section to minimize errors.</p> <ol> <li> <p>First and foremost, make sure your DICOM / nifti file names do not contain subject identificative information, such as the subject's name. This is particularly relevant for our pipeline, because that's exactly what our scanner does. You can either manually rename your files, or run the small Python utility (available here) in your terminal. More information on how to use it can be found in the docstring inside the script and in the relevant section below.</p> </li> <li> <p>Create <code>events.tsv</code> files (more info on required and optional columns can be found here):</p> <ul> <li>Make one file per functional run</li> <li>Add them to the <code>./BIDS/sub-xx/func</code> folder</li> <li>Optional: Create an <code>events.json</code> sidecar file to describe extra columns in event files</li> </ul> <p>Example:</p> <pre><code>\u2514\u2500 sub-01/\n\u2514\u2500 func/\n  \u251c\u2500 sub-01_task-exp_events.tsv \n  \u2514\u2500 sub-01_task-exp_events.json \n</code></pre> </li> <li> <p>Rename functional <code>nifti</code> files:</p> <ul> <li>Follow BIDS naming format: <code>sub-&lt;label&gt;_task-&lt;label&gt;_run-&lt;label&gt;_bold.nii</code></li> <li>Add them to the <code>./BIDS/sub-xx/func</code> folder</li> </ul> </li> <li> <p>Rename structural <code>nifti</code> files:</p> <ul> <li>Follow BIDS naming format: <code>sub-&lt;label&gt;_T1W.nii</code></li> <li>Add them to the <code>./BIDS/sub-xx/func</code> folder</li> </ul> </li> <li> <p>Optional: Process <code>dicom</code> files (if you got DICOM files from the scanner):</p> <ul> <li>Anonymize bold <code>dicom</code> files for your first participant using <code>anonymize_dicm</code></li> <li>Convert anonymized <code>dicom</code> files using <code>dicm2nii</code> to get <code>.json</code> sidecar files for your anatomical or function scans.</li> </ul> <p>JSON files</p> <p>Each <code>nii</code> file must have a sidecar JSON file. However, if your fMRI protocol did not change, all the important JSON fields are going to be the same across different scanning sessions, and therefore JSON files can be re-used across subjects. This will save you some time, since getting DICOM files from the scanner can be quite time-consuming.</p> </li> <li> <p>Update <code>.json</code> sidecar files:</p> <ul> <li>Complete the <code>PhaseEncodingDirection</code> and <code>SliceTiming</code> fields (see Missing fields in JSON files for more information)</li> <li>Duplicate and rename sidecar files to accompany each <code>bold.nii</code> file</li> </ul> </li> <li> <p>Create essential modality agnostic BIDS files:</p> <ul> <li><code>dataset_description.json</code></li> <li><code>participants.tsv</code> and <code>participants.json</code></li> <li><code>task-&lt;taskname&gt;_bold.json</code></li> </ul> </li> <li> <p>Set up additional components:</p> <ul> <li>Create a <code>derivatives</code> folder for future outputs</li> <li>Optional: Include a <code>.bidsignore</code> file if needed</li> </ul> </li> <li> <p>Validate your BIDS structure:</p> <ul> <li>Use the BIDS validator</li> </ul> </li> </ol> <p>By following these steps systematically, you'll ensure your data is properly organized in BIDS format, facilitating easier analysis and collaboration.</p>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#step-by-step-instructions","title":"Step-by-step instructions","text":"<p>Here we provide more detailed instructions to perform each of the steps mentioned above.</p> <p>Folder Structure</p> <p>All the steps and scripts below assume a specific folder structure and file naming convention. They will not work otherwise. Ensure you strictly follow the instructions in the How to store raw data page.</p> <p>TODO: [ANDREA] in the how to store raw data page, create a folders tree that includes all the relevant folders and subfolder. The current tree is not complete.</p>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#anonymize-raw-scanner-data","title":"Anonymize raw scanner data","text":""},{"location":"research/fmri/analysis/fmri-bids-conversion.html#expected-project-structure","title":"Expected project structure","text":"<p>This small utility tool renames files within a BIDS-like directory structure, specifically targeting files containing <code>_WIP_</code> in their names.</p> <p>The script operates on the following project structure:</p> <pre><code>Project_Name/\n\u251c\u2500\u2500 sourcedata/\n\u2502   \u2514\u2500\u2500 sub-xx/\n\u2502       \u251c\u2500\u2500 dicom/\n\u2502       \u251c\u2500\u2500 dicom_anon/\n\u2502       \u251c\u2500\u2500 bh/\n\u2502       \u251c\u2500\u2500 et/\n\u2502       \u2514\u2500\u2500 nifti/\n\u2514\u2500\u2500 BIDS/\n    \u251c\u2500\u2500 derivatives/\n    \u2514\u2500\u2500 sub-xx/\n        \u251c\u2500\u2500 anat/\n        \u2514\u2500\u2500 func/\n</code></pre> <p>The script processes files within the 'sourcedata' directory.</p> <p>Execute the script from the 'sourcedata' directory:</p> <ol> <li>Open a terminal or command prompt.</li> <li>Navigate to the project's root:</li> </ol> <pre><code>cd /path/to/Project_Name\n</code></pre> <ol> <li>Change to the 'sourcedata' directory:</li> </ol> <pre><code>cd sourcedata\n</code></pre>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#command-line-arguments","title":"Command-line Arguments","text":"<ul> <li><code>--level {group,participant}</code>: Process all subjects (<code>group</code>) or individual subjects (<code>participant</code>).</li> <li><code>--confirm {True,False}</code>: Ask for confirmation before renaming (default: True).</li> <li><code>--dry_run</code>: Preview changes without renaming.</li> <li><code>--sub [SUB ...]</code>: Specify subject IDs to process.</li> </ul>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#examples","title":"Examples","text":"<ol> <li>Dry run for all subjects:</li> </ol> <pre><code>python /path/to/anon_nii_filename.py --level group --dry_run\n</code></pre> <ol> <li>Rename files for subjects 01 and 02 with confirmation:</li> </ol> <pre><code>python /path/to/anon_nii_filename.py --level participant --sub 01 02 --confirm True\n</code></pre> <ol> <li>Rename files for all subjects without confirmation:</li> </ol> <pre><code>python /path/to/anon_nii_filename.py --level group --confirm False\n</code></pre> <p>Output filename:</p> <pre><code>sub-01/nifti/sub-01_WIP_T1w_20240101141322.nii\n</code></pre> <p>Caution</p> <p>Always backup your data before running renaming operations.</p>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#how-it-works","title":"How It Works","text":"<ol> <li>The script traverses the 'sourcedata' directory structure.</li> <li>It identifies files containing 'WIP' in their names.</li> <li>New names are generated based on the subject ID and the part of the filename after 'WIP'.</li> <li>Depending on the options, it either renames the files or shows the proposed changes.</li> </ol>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#important-notes","title":"Important Notes","text":"<ul> <li>Only files containing 'WIP' are processed. Others are ignored.</li> <li>To process all files, modify the <code>rename_files_in_directory</code> function:</li> </ul> <pre><code>if '_WIP_' in file:\n</code></pre> <p>to:</p> <pre><code>if True:  # Caution: processes all files\n</code></pre> <p>Modifying the Script</p> <p>Processing all files may lead to unintended renaming. Always use <code>--dry_run</code> first and review proposed changes carefully.</p>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#tips","title":"Tips","text":"<ul> <li>Use <code>--dry_run</code> to preview changes before actual renaming.</li> <li>Process subjects in smaller batches for large datasets.</li> <li>Regularly check BIDS specifications for naming convention compliance.</li> </ul>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#troubleshooting","title":"Troubleshooting","text":"<p>If issues occur:</p> <ol> <li>Ensure you're in the 'sourcedata' directory.</li> <li>Check permissions for renaming files in 'sourcedata'.</li> <li>Verify all required Python dependencies are installed.</li> <li>For unprocessed files, check if they contain 'WIP'.</li> </ol>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#creating-event-files","title":"Creating Event Files","text":"<p>Event files are crucial for analyzing fMRI data. They contain information about the timing and nature of stimuli or tasks during the scan. To create your event files manually:</p> <ol> <li>Navigate to your <code>sourcedata/sub-xx/bh/</code> folder.</li> <li>Locate the behavioral output files (<code>.mat</code> or <code>.log</code>) for each run.</li> <li>Create a corresponding <code>events.tsv</code> file for each run in the <code>BIDS/sub-xx/func/</code> folder.</li> </ol> <p>Each <code>events.tsv</code> file should contain at least three columns: <code>onset</code>, <code>duration</code>, and <code>trial_type</code>. Additional columns can be included as needed for your specific analysis.</p> <p>TODO: [ANDREA] Add script for automatically converting behavioral data to BIDS-compliant event files.</p> <p>TODO: [TIM] Include information about event files. Mention how they should ideally be created directly by the behavioural task script. Add a link to the task template to show how that can be done.</p> <p>TODO: [TIM] Add information about making an <code>events.json</code> file and the advantages of it.</p> <p>TODO: [TIM] Add information about using event files to make contrasts in the SPM step. Having a 'condition' + column for instance might be quite useful.</p> <p>TODO: [TIM] Give information about which columns will be useful to include in such files, why, and at what + future step they will become important.</p>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#converting-dicom-files-optional","title":"Converting DICOM files (Optional)","text":"<p>If you have DICOM files from the scanner:</p> <ol> <li>Navigate to your <code>sourcedata/sub-xx/dicom/</code> folder.</li> <li>Use the <code>anonymize_dicm</code> script to anonymize the DICOM files.</li> <li>Use the <code>dicm2nii</code> script to convert the anonymized DICOM files to NIfTI.</li> </ol> <p>TODO: [TIM] Give information on how to use the anonymization and dicom to nifti scripts, and what the results should be like. Give links to the scripts.</p>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#creating-json-sidecar-files","title":"Creating JSON Sidecar Files","text":"<ol> <li>Locate the JSON sidecar files in <code>sourcedata/sub-xx/dicom_converted/</code>.</li> <li>Open each JSON file and update the <code>PhaseEncodingDirection</code> and <code>SliceTiming</code> fields.</li> <li>Copy the updated JSON files to accompany each NIfTI file in the BIDS folder.</li> </ol> <p>Each <code>nii</code> file must have a corresponding JSON sidecar file. If your fMRI protocol didn't change, you can reuse JSON files across subjects.</p> <p>TODO: [TIM] Explain how to get the two missing fields and why it's important. Link to the fmri-general section about it.</p> <p>TODO: [TIM] Explain how to duplicate and rename the sidecar file.</p> <p>TODO: [ANDREA] fill this out with more in depth info about the JSON etc.</p>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#renaming-and-moving-nifti-files","title":"Renaming and Moving NIfTI Files","text":"<ol> <li>Navigate to your <code>sourcedata/sub-xx/dicom_converted/</code> folder.</li> <li>Identify the functional and structural NIfTI files.</li> <li>Rename the files following BIDS conventions:<ul> <li>Functional: <code>sub-&lt;label&gt;_task-&lt;label&gt;_run-&lt;label&gt;_bold.nii</code></li> <li>Structural: <code>sub-&lt;label&gt;_T1w.nii</code></li> </ul> </li> <li>Move the renamed files to their respective folders in <code>BIDS/sub-xx/</code>:<ul> <li>Functional files go to <code>BIDS/sub-xx/func/</code></li> <li>Structural files go to <code>BIDS/sub-xx/anat/</code></li> </ul> </li> </ol> <p>TODO: [ANDREA] is dicom converted and nii the same folder? from which folder should we get the final nifti files to move? this folder needs to be consistent across different workflows (e.g., dicom conversion or just nifti files)</p> <p>TODO: [TIM] Give instructions on how to rename files, both functional and structural, including what happens in case of several scan sessions and the added <code>ses</code> label.</p> Rename and move automatically <p>A MATLAB script that can do this automatically can be found here. Remember to change the input and output folders, run names and subjects numbers at the top of the script according to your needs. The  script expects as input your nifti files, along with the JSON sidecar template files.</p> <p>TODO: [ANDREA] the script should first check whether the JSON files are already availabe in the folder and, if that's the case, it should choose these files over the  templates. Also, we need to add more info about these template files in this page!</p>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#creating-essential-bids-files","title":"Creating Essential BIDS Files","text":"<ol> <li> <p>Create the following modality agnostic BIDS files files in your <code>BIDS/</code> root folder:</p> <ul> <li><code>dataset_description.json</code></li> <li><code>participants.tsv</code></li> <li><code>participants.json</code></li> <li><code>task-&lt;taskname&gt;_bold.json</code></li> </ul> </li> <li> <p>Fill in the required information for each file according to the BIDS specification.</p> </li> </ol> <p>Modality agnostic templates</p> <p>In the modality agnostic BIDS files page, you can find templates and examples.</p>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#setting-up-additional-components","title":"Setting Up Additional Components","text":"<ol> <li>Create a <code>derivatives/</code> folder in your <code>BIDS/</code> directory.</li> <li>If needed, create a <code>.bidsignore</code> file in your <code>BIDS/</code> root folder to exclude any non-BIDS compliant files.</li> </ol> Why should I use a .bidsignore file? <p>A `.bidsignore' file is useful to communicate to the BIDS validator which files should not be indexed, because they are not part of the standard BIDS structure. More information can be found here.</p>"},{"location":"research/fmri/analysis/fmri-bids-conversion.html#validating-your-bids-structure","title":"Validating Your BIDS Structure","text":"<ol> <li>Use the online BIDS Validator to check your BIDS structure.</li> <li>Upload your entire <code>BIDS/</code> folder and review any errors or warnings.</li> <li>Make necessary corrections based on the validator's output.</li> </ol> <p>By following these detailed steps, you'll ensure your data is properly organized in BIDS format, facilitating easier analysis and collaboration.</p> <p>Now that you have your data in BIDS format, we can proceed to data pre-processing and quality assessment. See the next guide for instructions. \u2192 Pre-processing and QA</p>"},{"location":"research/fmri/analysis/fmri-general.html","title":"General Notes","text":"<p>You should land on this page after collecting your fMRI data and converting it to BIDS. Here, you\u2019ll find all the general information and FAQs about fMRI protocols.</p> <p>Data Storage Suggestion</p> <p>Bring a dedicated hard drive to the hospital for storing the output data. This will ensure that you have a reliable medium to transfer and secure the raw data from the scanner.</p>"},{"location":"research/fmri/analysis/fmri-general.html#how-to-store-raw-data","title":"How to Store Raw Data","text":"<p>To avoid errors during BIDS conversion, store the raw data (e.g., data collected from the scanner, behavioral measures, eye-tracking) with the following folder structure:</p> <pre><code>sourcedata\n\u2514\u2500\u2500 sub-41\n    \u251c\u2500\u2500 bh\n    \u2502   \u251c\u2500\u2500 20240503104938_log_41-1-2_exp.tsv\n    \u2502   \u251c\u2500\u2500 20240503105558_41_1_exp.mat\n    \u2502   \u251c\u2500\u2500 20240503105640_log_41-2-1_exp.tsv\n    \u2502   \u251c\u2500\u2500 20240503110226_41_2_exp.mat\n    \u2502   \u251c\u2500\u2500 20240503110241_log_41-3-2_exp.tsv\n    \u2502   \u251c\u2500\u2500 20240503110825_41_3_exp.mat\n    \u2502   \u251c\u2500\u2500 20240503110851_log_41-4-1_exp.tsv\n    \u2502   \u251c\u2500\u2500 20240503111433_41_4_exp.mat\n    \u2502   \u251c\u2500\u2500 20240503111450_log_41-5-2_exp.tsv\n    \u2502   \u2514\u2500\u2500 20240503112032_41_5_exp.mat\n    \u2514\u2500\u2500 nifti\n        \u251c\u2500\u2500 sub-41_WIP_CS_3DTFE_8_1.nii\n        \u251c\u2500\u2500 sub-41_WIP_Functional_run1_3_1.nii\n        \u251c\u2500\u2500 sub-41_WIP_Functional_run2_4_1.nii\n        \u251c\u2500\u2500 sub-41_WIP_Functional_run3_5_1.nii\n        \u251c\u2500\u2500 sub-41_WIP_Functional_run4_6_1.nii\n        \u2514\u2500\u2500 sub-41_WIP_Functional_run5_7_1.nii\n</code></pre> <p>Folder Structure</p> <p>Ensure each subject\u2019s data is organized as shown above to minimize errors during BIDS conversion. Store all behavioral and NIfTI files under <code>sourcedata</code>.</p>"},{"location":"research/fmri/analysis/fmri-general.html#how-to-get-images-from-the-scanner","title":"How to Get Images from the Scanner","text":"<p>For optimal BIDS conversion of fMRI data, it is recommended to initially collect DICOM files (not NIfTI or PAR/REC) at the scanner. Although this adds an extra conversion step, it ensures accurate conversion into BIDS format. Follow these steps:</p> <ol> <li> <p>Initial DICOM Collection:</p> <ul> <li>Collect DICOM files for each modality (e.g., T1 and BOLD) for one subject.</li> <li>Convert these DICOM files to NIfTI format using <code>dcm2nii</code>, which will generate JSON sidecar files. Refer to this section for more details on the conversion process.</li> </ul> </li> <li> <p>Template Creation:</p> <ul> <li>Rename the JSON files for T1 and BOLD images to <code>sub-xx_T1w.json</code> and <code>sub-xx_task-exp_run-x_bold.json</code>.</li> <li>Move the JSON files into the <code>misc/</code> folder.</li> </ul> </li> <li> <p>Subsequent Data Collection:</p> <ul> <li>After creating the template JSON files, collect future data directly in NIfTI format to save time. The <code>script01_nifti-to-BIDS.m</code> script will use the JSON templates to populate the BIDS folders, as long as the fMRI sequence remains unchanged. If the sequence changes, generate new templates from the DICOM files.</li> </ul> </li> </ol>"},{"location":"research/fmri/analysis/fmri-general.html#missing-fields-in-json-files","title":"Missing Fields in JSON Files","text":"<p>Despite these steps, some BIDS fields in the sidecar JSON files may remain empty due to limitations of the Philips scanner. The most relevant fields that may be left empty are <code>SliceTiming</code> and <code>PhaseEncodingDirection</code>.</p> <ul> <li>SliceTiming:</li> <li>This field is required by fMRIPrep during slice timing correction.</li> <li> <p>Populate it using the <code>get_philips_MB_slicetiming.py</code> script, assuming you have access to a DICOM file and know the multiband factor (default is 2, as used in our lab).     !!! warning         The script assumes an interleaved, foot-to-head acquisition and will not work for other acquisition types.</p> </li> <li> <p>PhaseEncodingDirection:</p> </li> <li>This BIDS tag helps tools undistort images.</li> <li>Philips DICOM headers specify the phase encoding axis (e.g., A-P or L-R) but not the polarity (A-&gt;P or P-&gt;A).</li> <li>Check the scanner settings or consult with Ron to determine whether the polarity is AP or PA, and update the <code>?</code> in the JSON file with <code>+</code> or <code>-</code>.</li> </ul> <p>Handling NaNs in JSON Files</p> <p>NaN values in JSON files can cause errors during the MRIQC workflow. To address NaN values, see the discussions in this post, this GitHub issue, and this NeuroStars thread.</p> <p>For more details on Philips DICOM conversion, refer to the following resources:</p> <ul> <li>Philips DICOM Missing Information - dcm2niix</li> <li>PARREC Conversion - dcm2niix</li> </ul>"},{"location":"research/fmri/analysis/fmri-general.html#where-to-find-additional-info-on-the-fmri-sequence","title":"Where to Find Additional Info on the fMRI Sequence","text":"<p>Additional information on the fMRI sequence can be found directly at the scanner. Here\u2019s a step-by-step guide:</p> <ol> <li> <p>Start the Examination:</p> <ul> <li>Go to Patients -&gt; New Examination -&gt; RIS.</li> <li>Select your subject and fill out the required fields:<ul> <li>Weight: Enter the subject's weight.</li> <li>Implants: Specify if the subject has any implants.</li> <li>Pregnant: Indicate if the subject is pregnant.</li> </ul> </li> </ul> </li> <li> <p>Load the Scanning Sequence:</p> <ul> <li>Drag and drop your scanning sequence from the bottom panel to the left panel.</li> </ul> </li> <li> <p>Select a Run:</p> <ul> <li>Click on either a functional or anatomical run from the available list.</li> </ul> </li> <li> <p>Expand the Tabs:</p> <ul> <li>Click on the <code>&gt;&gt;</code> symbol in the bottom panel, below the sagittal, coronal, and horizontal views, to expand additional tabs.</li> </ul> </li> <li> <p>Access Geometry Settings:</p> <ul> <li>Navigate to the Geometry tab to access important scan parameters:<ul> <li>MB factor: Indicates the number of slices recorded simultaneously, used for slice timing correction.</li> <li>Slices: Total number of horizontal slices.</li> <li>Fold-over direction: Required for correcting the phase encoding direction in the BIDS field.</li> <li>Slice scan order: Typically Foot to Head (FH), used for slice timing correction.</li> </ul> </li> </ul> </li> <li> <p>Check Additional Fields:</p> <ul> <li>Visit the Coils tab for details about the head coils used during the scan.</li> <li>In the Contrast tab, note the following fields:<ul> <li>TE (Echo Time): Usually a single echo of 30 ms by default.</li> <li>TR (Repetition Time): Typically set to 2000 ms by default.</li> </ul> </li> </ul> </li> </ol> <p>Next Step \u2192 Set-up your environment</p>"},{"location":"research/fmri/analysis/fmri-glm.html","title":"General Linear Model in SPM","text":"<p>You should land on this page after having collected your fMRI data, converted it to BIDS and preprocessed it. Your goal now is to model the BOLD activity with a Generalised Linear Model (GLM), in order to obtain the beta values on which to apply further analyses.</p> <p>In this section, we will use the Statistical Parametric Mapping (SPM) package to construct the GLM. Here\u2019s an overview of the steps:</p> <ol> <li>Data Preparation: Get your files ready for SPM.</li> <li>Design Matrix Setup: Define the model for your analysis.</li> <li>Model Estimation &amp; Results: Estimate your model and analyze contrasts.</li> </ol>"},{"location":"research/fmri/analysis/fmri-glm.html#step-1-data-preparation","title":"Step 1: Data Preparation","text":"<p>Before running the GLM, we need to make sure the data is compatible with SPM. There are two steps that need to be taken to bring your <code>.nii</code> files from fMRIPrep output to SPM input:</p> <ol> <li>gunzipping (de-compressing <code>.nii.gz</code> files, which SPM can't handle natively)</li> <li>smoothing (mostly for localizer runs).</li> </ol> <p>The sugested way of proceeding is to create a <code>derivatives/pre-SPM</code> folder where to store a <code>gunzipped</code> output folder and a <code>smoothed</code> output folder.</p>"},{"location":"research/fmri/analysis/fmri-glm.html#decompressing-nifti-files","title":"Decompressing NIfTI Files","text":"<p>SPM cannot process <code>.nii.gz</code> files directly, so we first need to decompress them:</p> <ol> <li>Create a directory for pre-processed files:</li> </ol> <pre><code>mkdir derivatives/pre-SPM\n</code></pre> <ol> <li>Decompress the files using <code>gunzip</code> in the terminal:</li> </ol> <pre><code>gunzip path/to/your/files/*.nii.gz\n</code></pre> <ul> <li>Store the decompressed files in a subdirectory called <code>gunzipped</code> inside <code>derivatives/pre-SPM</code>.</li> </ul> <p>Decompress with a right-click!</p> <p>Most Operating Systems will let you decompress the <code>nii.gz</code> files directly from the File Explorer. Right click on the files you want to decompress, and extract them like you would do with a compressed folder.</p>"},{"location":"research/fmri/analysis/fmri-glm.html#smoothing-functional-data","title":"Smoothing Functional Data","text":"<p>Smoothing is required to increase signal-to-noise ratio, especially for localizer runs. Follow these steps:</p> <ol> <li>Launch the SPM GUI with the command:</li> </ol> <pre><code>spm fmri\n</code></pre> <ol> <li>In the GUI, click on <code>Smooth</code>.</li> <li>Select the decompressed <code>.nii</code> files.</li> <li>Set the FWHM (Full Width at Half Maximum) to <code>[4 4 4]</code> or <code>[6 6 6]</code> for moderate smoothing.</li> <li>Save the smoothed output in <code>derivatives/pre-SPM/smoothed</code>.</li> </ol> <p>Automated Preprocessing</p> <p>You can integrate the decompression and smoothing steps into a script to streamline your workflow, avoiding manual steps (see the Analysis Workflow for an example).</p>"},{"location":"research/fmri/analysis/fmri-glm.html#step-2-design-matrix-setup","title":"Step 2: Design Matrix Setup","text":"<p>To run a GLM, you need to create a design matrix that links the timing of experimental conditions to the observed BOLD response. The design matrix is specified in SPM\u2019s <code>Specify 1st level</code> interface. While this can be done manually for simpler designs, for complex designs with many conditions, it\u2019s more efficient to use externally generated onset time and confounds files.</p>"},{"location":"research/fmri/analysis/fmri-glm.html#creating-onset-files","title":"Creating Onset Files","text":"<p>For complex designs, you should create one onset file per run per subject, containing information about event types, onsets, and durations. The <code>eventsBIDS2SPM</code> function can help convert BIDS-formatted event files into the onset files that SPM requires.</p> <ol> <li>Use the <code>eventsBIDS2SPM</code> function to convert event files.</li> <li> <p>Store the onset files in the following structure:</p> <ul> <li><code>BIDS/sub-xx/func/sub-xx_run-x_eventsspm.mat</code>.</li> </ul> <pre><code>BIDS/\n\u251c\u2500\u2500 sub-01/\n\u2502   \u2514\u2500\u2500 func/\n\u2502       \u251c\u2500\u2500 sub-01_run-1_eventsspm.mat\n\u2502       \u2514\u2500\u2500 sub-01_run-2_eventsspm.mat\n</code></pre> </li> </ol> eventsBIDS2SPM <pre><code>function new_df = eventsBIDS2SPM(tsv_file)\n    % eventsBIDS2SPM - Convert BIDS event files to SPM format\n    % This function reads a BIDS event file and converts it to the format required by SPM.\n    % It extracts the unique trial types and their onsets and durations and stores them in a\n    % Matlab structure.\n    %\n    % Author: Andrea Costantino\n    % Date: 23/1/2023\n    %\n    % Usage:\n    %   mat_dict = eventsBIDS2SPM(tsv_file, run_id)\n    %\n    % Inputs:\n    %   tsv_file - string, path to the tsv file containing the events\n    %\n    % Outputs:\n    %   mat_dict - struct, a Matlab structure containing the events in the format\n    %              required by SPM. The structure contains three fields:\n    %                - 'names': cell array of string, the names of the trial types\n    %                - 'onsets': cell array of double, onset times of the trials\n    %                - 'durations': cell array of double, duration of the trials\n    %\n    % This function reads a BIDS event file and converts it to the format required by SPM.\n    % It extracts the unique trial types and their onsets and durations and stores them in a\n    % Matlab structure\n\n    % read the tsv file\n    df = readtable(tsv_file,'FileType','text');\n    % Select unique trial type name\n    unique_names = unique(df.trial_type);\n    % Make new table in a form that SPM can read\n    new_df = table('Size',[length(unique_names),3],'VariableTypes',{'cellstr', 'cellstr', 'cellstr'},'VariableNames',{'names', 'onsets', 'durations'});\n    % For each trial type (i.e., condition)\n    for k = 1:length(unique_names)\n        % Select rows belonging to that condition\n        filtered = df(strcmp(df.trial_type,unique_names{k}),:);\n        % Copy trial name, onset and duration to the new table\n        new_df.names(k) = unique(filtered.trial_type);\n        new_df.onsets(k) = {filtered.onset};\n        new_df.durations(k) = {filtered.duration};\n    end\n    new_df = sortrows(new_df, 'names');\nend\n</code></pre>"},{"location":"research/fmri/analysis/fmri-glm.html#creating-confounds-files","title":"Creating Confounds Files","text":"<p>Head motion and other confound regressors from fMRIPrep need to be formatted to be compatible with SPM. The <code>fMRIprepConfounds2SPM</code> function can convert these files into the format required by SPM.</p> <ol> <li>Use the <code>fMRIprepConfounds2SPM</code> function to convert confounds from fMRIPrep.</li> <li>Store the confounds files in the BIDS structure with SPM-compatible names:<ul> <li><code>BIDS/sub-xx/func/sub-xx_run-x_confoundsspm.mat</code>.</li> </ul> </li> </ol> fMRIprepConfounds2SPM <pre><code>function confounds = fMRIprepConfounds2SPM(json_path, tsv_path, pipeline)\n    % fMRIprepConfounds2SPM - Extracts and formats fMRI confounds for SPM analysis\n    %\n    % This function processes confound data from fMRIprep outputs, suitable for\n    % Statistical Parametric Mapping (SPM) analysis. It reads a JSON file with\n    % confound descriptions and a TSV file with confound values, then selects and\n    % formats the required confounds based on the specified denoising pipeline.\n    %\n    % Usage:\n    %   confounds = fMRIprepConfounds2SPM(json_path, tsv_path, pipeline)\n    %\n    % Inputs:\n    %   json_path (string): Full path to the JSON file. This file contains metadata\n    %                       about the confounds, such as their names and properties.\n    %\n    %   tsv_path (string):  Full path to the TSV file. This file holds the actual\n    %                       confound values in a tabular format for each fMRI run.\n    %\n    %   pipeline (cell array of strings): Specifies the denoising strategies to be\n    %                                     applied. Each element is a string in the\n    %                                     format 'strategy-number'. For example,\n    %                                     'HMP-6' indicates using 6 head motion\n    %                                     parameters. Valid strategies include:\n    %             'HMP': Head Motion Parameters, options: 6, 12, 24\n    %             'GS': Global Signal, options: 1, 2, 4\n    %             'CSF_WM': CSF and White Matter signals, options: 2, 4, 8\n    %             'aCompCor': CompCor, options: 10, 50\n    %             'MotionOutlier': Motion Outliers, options: FD &gt; 0.5, DVARS &gt; 1.5\n    %             'Cosine': Discrete Cosine Transform based regressors for HPF\n    %             'FD': Framewise Displacement, a raw non-binary value\n    %             'Null': Returns an empty table if no confounds are to be applied\n    %\n    % Outputs:\n    %   confounds (table): A table containing the selected confounds, formatted for\n    %                      use in SPM. Each column represents a different confound,\n    %                      and each row corresponds to a time point in the fMRI data.\n    %\n    % Author: Andrea Costantino\n    % Date: 23/1/2023\n    %\n    % Example:\n    %   confounds = fMRIprepConfounds2SPM('path/to/json', 'path/to/tsv', {'HMP-6', 'GS-4'});\n    %\n    % This example would extract and format 6 head motion parameters and the global\n    % signal (with raw, derivative, and squared derivative) for SPM analysis.\n\n    % Read the TSV file containing the confound values\n    tsv_run = readtable(tsv_path, 'FileType', 'text');\n\n    % Open and read the JSON file, then parse it into a MATLAB structure\n    fid = fopen(json_path); \n    raw = fread(fid, inf); \n    str = char(raw'); \n    fclose(fid); \n    json_run = jsondecode(str);\n\n    % Initialize an empty cell array to store the keys of the selected confounds\n    selected_keys = {};\n\n    % If 'Null' is found in the pipeline, return an empty table and exit the function\n    if any(strcmp(pipeline, 'Null'))\n        disp('\"Null\" found in the pipeline. Returning an empty table.')\n        return;\n    else\n        % Process each specified strategy in the pipeline\n\n        % Head Motion Parameters (HMP)\n        if any(contains(pipeline, 'HMP'))\n            % Extract and validate the specified number of head motion parameters\n            idx = find(contains(pipeline, 'HMP'));\n            conf_num_str = pipeline(idx(1)); \n            conf_num_str_split = strsplit(conf_num_str{1}, '-');\n            conf_num = str2double(conf_num_str_split(2));\n            if ~any([6, 12, 24] == conf_num)\n                error('HMP must be 6, 12, or 24.');\n            else\n                % Add the appropriate head motion parameters to selected_keys\n                hmp_id = floor(conf_num / 6);\n                if hmp_id &gt; 0\n                    selected_keys = [selected_keys, {'rot_x', 'rot_y', 'rot_z', 'trans_x', 'trans_y', 'trans_z'}];\n                end\n                if hmp_id &gt; 1\n                    selected_keys = [selected_keys, {'rot_x_derivative1', 'rot_y_derivative1', 'rot_z_derivative1', 'trans_x_derivative1', 'trans_y_derivative1', 'trans_z_derivative1'}];\n                end\n                if hmp_id &gt; 2\n                    selected_keys = [selected_keys, {'rot_x_power2', 'rot_y_power2', 'rot_z_power2', 'trans_x_power2', 'trans_y_power2', 'trans_z_power2', 'rot_x_derivative1_power2', 'rot_y_derivative1_power2', 'rot_z_derivative1_power2', 'trans_x_derivative1_power2', 'trans_y_derivative1_power2', 'trans_z_derivative1_power2'}];\n                end\n            end\n        end\n\n        % Global Signal (GS)\n        if any(contains(pipeline, 'GS'))\n            % Extract and validate the specified level of global signal processing\n            idx = find(contains(pipeline, 'GS'));\n            conf_num_str = pipeline(idx(1)); \n            conf_num_str_split = strsplit(conf_num_str{1}, '-');\n            conf_num = str2double(conf_num_str_split(2));\n            if ~any([1, 2, 4] == conf_num)\n                error('GS must be 1, 2, or 4.');\n            else\n                % Add the global signal parameters to selected_keys based on the specified level\n                gs_id = conf_num;\n                if gs_id &gt; 0\n                    selected_keys = [selected_keys, {'global_signal'}];\n                end\n                if gs_id &gt; 1\n                    selected_keys = [selected_keys, {'global_signal_derivative1'}];\n                end\n                if gs_id &gt; 2\n                    selected_keys = [selected_keys, {'global_signal_derivative1_power2', 'global_signal_power2'}];\n                end\n            end\n        end\n\n        % CSF and WM masks global signal (CSF_WM)\n        if any(contains(pipeline, 'CSF_WM'))\n            % Extract and validate the specified level of CSF/WM signal processing\n            idx = find(contains(pipeline, 'CSF_WM'));\n            conf_num_str = pipeline(idx(1)); \n            conf_num_str_split = strsplit(conf_num_str{1}, '-');\n            conf_num = str2double(conf_num_str_split(2));\n            if ~any([2, 4, 8] == conf_num)\n                error('CSF_WM must be 2, 4, or 8.');\n            else\n                % Add the CSF and WM parameters to selected_keys based on the specified level\n                phys_id = floor(conf_num / 2);\n                if phys_id &gt; 0\n                    selected_keys = [selected_keys, {'white_matter', 'csf'}];\n                end\n                if phys_id &gt; 1\n                    selected_keys = [selected_keys, {'white_matter_derivative1', 'csf_derivative1'}];\n                end\n                if phys_id &gt; 2\n                    selected_keys = [selected_keys, {'white_matter_derivative1_power2', 'csf_derivative1_power2', 'white_matter_power2', 'csf_power2'}];\n                end\n            end\n        end\n\n        % aCompCor\n        if any(contains(pipeline, 'aCompCor'))\n            % Extract and format aCompCor confounds based on the specified number\n            csf_50_dict = json_run(ismember({json_run.Mask}, 'CSF') &amp; ismember({json_run.Method}, 'aCompCor') &amp; ~contains({json_run.key}, 'dropped'));\n            wm_50_dict = json_run(ismember({json_run.Mask}, 'WM') &amp; ismember({json_run.Method}, 'aCompCor') &amp; ~contains({json_run.key}, 'dropped'));\n            idx = find(contains(pipeline, 'aCompCor'));\n            conf_num_str = pipeline{idx(1)}; \n            conf_num_str_split = strsplit(conf_num_str{1}, '-');\n            conf_num = str2double(conf_num_str_split(2));\n            if ~any([10, 50] == conf_num)\n                error('aCompCor must be 10 or 50.');\n            else\n                % Select the appropriate aCompCor components and add them to selected_keys\n                if conf_num == 10\n                    csf = sort(cell2mat(csf_50_dict.keys()));\n                    csf_10 = csf(1:5);\n                    wm = sort(cell2mat(wm_50_dict.keys()));\n                    wm_10 = wm(1:5);\n                    selected_keys = [selected_keys, csf_10, wm_10];\n                elseif conf_num == 50\n                    csf_50 = cell2mat(csf_50_dict.keys());\n                    wm_50 = cell2mat(wm_50_dict.keys());\n                    selected_keys = [selected_keys, csf_50, wm_50];\n                end\n            end\n        end\n\n        % Cosine\n        if any(contains(pipeline, 'Cosine'))\n            % Extract cosine-based regressors for high-pass filtering\n            cosine_keys = tsv_run.Properties.VariableNames(contains(tsv_run.Properties.VariableNames, 'cosine'));\n            selected_keys = [selected_keys, cosine_keys];\n        end\n\n        % MotionOutlier\n        if any(contains(pipeline, 'MotionOutlier'))\n            % Process motion outliers, either using pre-computed values or calculating them\n            motion_outlier_keys = tsv_run.Properties.VariableNames(find(contains(tsv_run.Properties.VariableNames, {'non_steady_state_outlier', 'motion_outlier'})));\n            selected_keys = [selected_keys, motion_outlier_keys];\n        end\n\n        % Framewise Displacement (FD)\n        if any(contains(pipeline, 'FD'))\n            % Add raw framewise displacement values to selected_keys\n            % If the first row is 'n/a', replace it with 0\n            fd_values = tsv_run.framewise_displacement;\n            if isnan(fd_values(1))\n                fd_values(1) = 0;\n            end\n            tsv_run.framewise_displacement = fd_values;\n            selected_keys = [selected_keys, {'framewise_displacement'}];\n        end\n\n        % Retrieve the selected confounds and convert them into a table\n        confounds_table = tsv_run(:, ismember(tsv_run.Properties.VariableNames, selected_keys));\n        confounds = fillmissing(confounds_table, 'constant', 0);\nend\n</code></pre> <p>BIDS-Compliant Naming</p> <p>Ensure the files are saved with names that include:</p> <ul> <li><code>sub-xx</code>: subject identifier.</li> <li><code>run-x</code>: run identifier.</li> <li><code>confoundsspm</code> or <code>eventsspm</code> for confounds and timings, respectively.</li> </ul>"},{"location":"research/fmri/analysis/fmri-glm.html#using-the-functions-in-a-script","title":"Using the Functions in a Script","text":"<p>Both <code>eventsBIDS2SPM</code> and <code>fMRIprepConfounds2SPM</code> are MATLAB functions that can be integrated into scripts for batch processing in SPM. This allows you to automate the import of timing and confounds data or save them into SPM-compatible files for later use.</p> Directly Load Data into SPMSave SPM-Compatible Files <p>You can use these functions within a MATLAB script to load onset times and confounds directly into an SPM batch job. This is useful when you want to process multiple subjects and runs in one go:</p> <pre><code>% Example script to use eventsBIDS2SPM and fMRIprepConfounds2SPM in batch jobs\nsubject_id = 'sub-01';\nrun_id = 'run-01';\n\n% Paths to the BIDS event and confound files\ntsv_file = fullfile('BIDS', subject_id, 'func', [subject_id '_' run_id '_events.tsv']);\njson_file = fullfile('BIDS', subject_id, 'func', [subject_id '_' run_id '_desc-confounds_timeseries.json']);\nconfound_tsv = fullfile('BIDS', subject_id, 'func', [subject_id '_' run_id '_desc-confounds_timeseries.tsv']);\n\n% Convert event files to SPM-compatible format\nonset_data = eventsBIDS2SPM(tsv_file);\n\n% Convert confound files to SPM-compatible format with a chosen pipeline\npipeline = {'HMP-6', 'GS-1'}; % Example: 6 head motion parameters + 1 global signal\nconfound_data = fMRIprepConfounds2SPM(json_file, confound_tsv, pipeline);\n\n% Pass the resulting onset and confound data directly into SPM batch processing\nmatlabbatch{1}.spm.stats.fmri_spec.sess.multi = {onset_data};\nmatlabbatch{1}.spm.stats.fmri_spec.sess.multi_reg = {confound_data};\n\n% Run the SPM batch\nspm_jobman('run', matlabbatch);\n</code></pre> <p>This script converts the timing and confounds information, then immediately feeds them into an SPM batch, making it suitable for automated batch jobs over multiple runs or subject.</p> <p>If you want to save the converted files for later use, you can use the functions to write them into files with BIDS-compliant names. This is helpful if you need to inspect the files or share them with collaborators before running the GLM analysis:</p> <pre><code>% Example script to convert and save files in SPM-compatible format\nsubject_id = 'sub-01';\nrun_id = 'run-01';\n\n% Paths to the BIDS event and confound files\ntsv_file = fullfile('BIDS', subject_id, 'func', [subject_id '_' run_id '_events.tsv']);\njson_file = fullfile('BIDS', subject_id, 'func', [subject_id '_' run_id '_desc-confounds_timeseries.json']);\nconfound_tsv = fullfile('BIDS', subject_id, 'func', [subject_id '_' run_id '_desc-confounds_timeseries.tsv']);\n\n% Specify output paths\nonset_save_path = fullfile('BIDS', subject_id, 'func', [subject_id '_' run_id '_desc-events.mat']);\nconfound_save_path = fullfile('BIDS', subject_id, 'func', [subject_id '_' run_id '_desc-confoundsspm.mat']);\n\n% Convert and save onset data\nonset_data = eventsBIDS2SPM(tsv_file);\nsave(onset_save_path, 'onset_data');\n\n% Convert and save confound data with a chosen pipeline\npipeline = {'HMP-6', 'GS-1'}; % Example: 6 head motion parameters + 1 global signal\nconfound_data = fMRIprepConfounds2SPM(json_file, confound_tsv, pipeline);\nsave(confound_save_path, 'confound_data');\n\n% Now the onset and confound files can be loaded into SPM as needed.\n</code></pre> <p>This script allows you to convert the timing and confound data and save them to files with clear, BIDS-compliant names. These files can later be imported into SPM using the GUI or through further scripting.</p> <p>Automating Batch Processing</p> <p>By integrating these functions into a script, you can automate the entire process of setting up the design matrix for multiple subjects and runs. This approach is particularly useful for large datasets, allowing you to focus on refining the analysis rather than manual data preparation.</p>"},{"location":"research/fmri/analysis/fmri-glm.html#specifying-the-1st-level-model-in-spm","title":"Specifying the 1<sup>st</sup>-Level Model in SPM","text":"<p>Once you have your onset times and confound regressors files ready, you can set up the design matrix:</p> <ol> <li>Open SPM: Launch the SPM GUI with <code>spm fmri</code></li> <li>Specify 1<sup>st</sup>-Level: Go to <code>Specify 1st Level</code> in the SPM menu.</li> <li>Set Parameters:<ul> <li>Units for design: Set to <code>seconds</code>.</li> <li>Interscan interval (TR): Use your fMRI acquisition\u2019s TR value.</li> <li>Microtime resolution: This should be the number of slices acquired per TR (e.g., <code>64</code> for a 64-slice scan).</li> </ul> </li> <li>Input Onset Files:<ul> <li>Use the multiple conditions option to input onset time files (e.g., <code>sub-01_run-01_eventsspm.mat</code>).</li> </ul> </li> <li>Include Confound Regressors:<ul> <li>Select the confound regressors from the confound files (e.g., <code>sub-01_run-01_confoundsspm.mat</code>).</li> </ul> </li> </ol>"},{"location":"research/fmri/analysis/fmri-glm.html#reviewing-the-design-matrix","title":"Reviewing the Design Matrix","text":"<p>After specifying the design matrix:</p> <ol> <li>Click <code>Review</code>: This will open a visualization of the design matrix.</li> <li>Check for the following:<ul> <li>Clear separation between conditions.</li> <li>Proper alignment of conditions with the expected timing.</li> <li>Inclusion of nuisance regressors (e.g., head motion).</li> </ul> </li> </ol> <p>What to Look For</p> <ul> <li>Boxcar Patterns: Ensure that the regressors follow the expected patterns based on your design.</li> <li>Orthogonality: Verify that the conditions are not overly correlated, as this can impact the model\u2019s stability.</li> </ul> <p>Saving the Design Matrix</p> <p>To save the design matrix visualization for documentation: - Right-click on the matrix plot and select <code>Save as Image</code>. - Store the image in your documentation folder.</p>"},{"location":"research/fmri/analysis/fmri-glm.html#step-3-model-estimation-results","title":"Step 3: Model Estimation &amp; Results","text":"<p>With your design matrix ready, you can estimate the model and define contrasts to test your hypotheses. This step will produce the beta values and residuals necessary for further analysis.</p>"},{"location":"research/fmri/analysis/fmri-glm.html#estimating-the-model","title":"Estimating the Model","text":"<ol> <li>Review the Design Matrix: Before estimation, ensure the design matrix looks correct by clicking <code>Review</code>.</li> <li> <p>Estimate the Model: Select <code>Estimate</code> in the GUI and choose the <code>SPM.mat</code> file.</p> <ul> <li>Set <code>write residuals</code> to <code>yes</code> to save residual images.</li> <li> <p>Click <code>Run</code> to initiate the model estimation.</p> </li> <li> <p>This process will generate beta images (one per regressor) and residual variance estimates.</p> </li> </ul> </li> </ol> <p>Why Save Residuals?</p> <p>Saving residuals can help diagnose issues with model fit by checking for any systematic patterns in the residual images.</p>"},{"location":"research/fmri/analysis/fmri-glm.html#defining-and-evaluating-contrasts","title":"Defining and Evaluating Contrasts","text":"<p>Contrasts allow you to test specific hypotheses about the brain's response to different conditions, such as comparing activations between different task conditions or testing against a baseline.</p> <ol> <li> <p>Define New Contrasts:</p> <ul> <li>Go to <code>Results</code> &gt; <code>Define New Contrast</code>.</li> <li>Enter a name for the contrast (e.g., <code>Condition1 &gt; Condition2</code>).</li> <li>Specify the weights for each condition based on the order of the regressors (e.g., <code>[1 -1]</code>).</li> </ul> </li> <li> <p>Evaluate the Contrasts:</p> <ul> <li>After defining contrasts, set the desired threshold (e.g., <code>p &lt; 0.001</code>) and click <code>Run</code> to see the results.</li> <li>Review the statistical maps for significant clusters or activations.</li> </ul> </li> </ol> <p>Example Contrast</p> <p>For a comparison between two conditions (e.g., <code>Faces</code> vs. <code>Objects</code>), use: <pre><code>[1 -1]\n</code></pre> This weights <code>Faces</code> positively and <code>Objects</code> negatively, highlighting brain regions more active during the <code>Faces</code> condition.</p>"},{"location":"research/fmri/analysis/fmri-glm.html#verifying-the-order-of-regressors","title":"Verifying the Order of Regressors","text":"<p>It\u2019s crucial to confirm the order of regressors in the design matrix before specifying contrasts to ensure that your weights align correctly with the conditions. Here\u2019s how to verify this using both the SPM GUI and by inspecting the <code>SPM.mat</code> file directly.</p> Option 1: Checking Regressor Order Using the SPM GUIOption 2: Inspecting the <code>SPM.mat</code> File Directly <ol> <li> <p>Review the Design Matrix:</p> <ul> <li>Open SPM and select <code>Review</code> &gt; <code>SPM.mat</code>.</li> <li>This opens the design matrix in a new window.</li> <li>In the design matrix window, each column represents a different regressor (condition or nuisance variable).</li> </ul> </li> <li> <p>Interpret the Design Matrix:</p> <ul> <li>Hover over each column to see the name and description of the regressor.</li> <li>Typically, the first set of columns corresponds to your experimental conditions (e.g., <code>Faces</code>, <code>Objects</code>), followed by any nuisance regressors (e.g., motion parameters).</li> <li>Make a note of the order so that you can set your contrast weights accurately.</li> </ul> </li> </ol> <p>Use the Design Matrix Visualization</p> <p>The design matrix visualization provides a graphical representation of each regressor. Patterns in the design matrix (e.g., boxcar shapes for task conditions) can help you verify the expected structure.</p> <ol> <li> <p>Load the <code>SPM.mat</code> File in MATLAB:</p> <p>In the MATLAB command window, navigate to the folder containing your <code>SPM.mat</code> file:  <pre><code>cd('/path/to/your/SPM_results_folder');\nload('SPM.mat');\n</code></pre> This loads the <code>SPM</code> structure into your workspace.</p> </li> <li> <p>Explore the Regressors:</p> <p>To see the names of the regressors, type:  <pre><code>SPM.xX.name\n</code></pre> This command will display a list of the regressor names in the order they appear in the design matrix.</p> </li> <li> <p>Interpret the Output:</p> <p>The output will look something like this:  <pre><code>'Sn(1) condition1*bf(1)'\n'Sn(1) condition2*bf(1)'\n'Sn(1) condition3*bf(1)'\n'Sn(1) motion_x'\n'Sn(1) motion_y'\n</code></pre> Each string corresponds to a regressor:</p> <ul> <li><code>Sn(1)</code>: Refers to session 1 (the run number).</li> <li><code>condition1*bf(1)</code>: Represents a condition convolved with the basis function (e.g., <code>Faces</code>).</li> <li><code>motion_x</code>, <code>motion_y</code>, etc.: These are motion parameters as nuisance regressors.</li> </ul> </li> <li> <p>Align the Contrast Weights:</p> <p>Based on this order, you can now set your contrast weights correctly. For instance, if <code>condition1</code> is the first regressor and <code>condition2</code> is the second, a contrast comparing them would be:  <pre><code>[1 -1 0 0 0 ...]\n</code></pre></p> </li> </ol> <p>Checking Regressors in a Script</p> <p>If you are scripting the process, you can automate this check by including: <pre><code>% Load the design matrix and display regressor names\nload('SPM.mat');\ndisp(SPM.xX.name);\n</code></pre> This will print the regressor names directly in the MATLAB command window, helping you confirm the correct order before specifying your contrasts.</p> <p>Why Checking Regressor Order Matters?</p> <ul> <li>Ensures Correct Contrast Specification: Mismatched contrasts can lead to incorrect interpretations of your data, as they might test unintended comparisons.</li> <li>Simplifies Troubleshooting: If the results look unexpected, double-checking the regressor order is one of the first steps to identify potential issues in the GLM setup.</li> <li>Consistency Across Sessions: If you\u2019re analyzing multiple runs or sessions, verifying regressor order ensures consistency across sessions, which is crucial for second-level analyses.</li> </ul>"},{"location":"research/fmri/analysis/fmri-glm.html#visualizing-and-saving-results","title":"Visualizing and Saving Results","text":"<ol> <li>Viewing Results: Use the SPM results viewer to explore significant clusters.</li> <li>Save the Statistical Maps:<ul> <li>Save thresholded activation maps as <code>.nii</code> files using the <code>Save</code> button in the results window.</li> </ul> </li> <li>Generate Figures:<ul> <li>Use the <code>Render</code> or <code>Surface</code> options to create visual summaries of your findings.</li> <li>Save these figures for inclusion in reports or presentations.</li> </ul> </li> </ol> <p>Exporting Images</p> <p>To include figures in publications or reports: - Use <code>Export</code> in SPM to save figures as high-resolution images. - For 3D brain renderings, adjust the orientation and threshold for a clear presentation.</p> <p>Continue to the next guide for instructions on setting up Regions of Interest (ROIs) to extract and analyze data from specific brain regions: \u2192 Regions of Interest</p> <ul> <li>[TODO]: Add example directories showing how files are organized before and after preprocessing.</li> <li>[TODO]: Include screenshots or illustrations for key steps (e.g., setting up the design matrix in SPM).</li> <li>[PLACEHOLDER]: Add a screenshot of the SPM results interface to illustrate how to set thresholds.</li> <li>[TODO]: Include instructions on visualizing and saving the design matrix in SPM for documentation.</li> </ul>"},{"location":"research/fmri/analysis/fmri-mvpa.html","title":"Multi-variate analysis (MVPA/RSA)","text":"<ul> <li>TODO:  populate this</li> </ul>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html","title":"fMRI Preprocessing and Quality Assessment","text":"<p>You should land on this page after having collected your (f)MRI data and converted it to BIDS.</p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#preprocessing-quality-assessment-overview","title":"Preprocessing &amp; Quality Assessment Overview","text":"<p>In this page, you will learn how to preprocess fMRI data using fMRIPrep and perform quality assessment with MRIQC. We will cover:</p> <ul> <li> <p> Running fMRIPrep   Step-by-step guide to run fMRIPrep, including the required command structure, key options, and output directory organization.</p> </li> <li> <p> Performing Quality Control with MRIQC   Use MRIQC to assess the quality of your MRI data. Identify potential artifacts and ensure data suitability for further analysis.</p> </li> <li> <p> Interpreting fMRIPrep Outputs   Understand the content of the fMRIPrep HTML report, including motion parameters, anatomical alignment, and other key quality checks.</p> </li> <li> <p> Reviewing MRIQC Reports   Learn how to interpret MRIQC's visual reports and quality metrics, such as SNR and temporal SNR, to evaluate the data's integrity.</p> </li> <li> <p> Troubleshooting Common Issues   Find solutions to common challenges with fMRIPrep and MRIQC, including memory management and output interpretation.</p> </li> <li> <p> Next Steps: GLM Analysis   Once your data is preprocessed and quality-checked, move on to first-level analysis with the General Linear Model.</p> </li> </ul> <ul> <li> <p>fMRIPrep Documentation   Get detailed insights into the preprocessing steps, output formats, and recommended practices.</p> </li> <li> <p>MRIQC Documentation   Explore MRIQC's metrics and recommendations for improving MRI data quality.</p> </li> <li> <p>NeuroStars Community   A valuable resource for troubleshooting and community discussions related to fMRIPrep and MRIQC.</p> </li> <li> <p>YouTube: Reviewing fMRIPrep Outputs</p> </li> </ul> <p>Tip</p> <p>Before proceeding, ensure that your fMRI data is converted into BIDS format. Refer to the BIDS Conversion Guide for more details.</p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#preprocessing-with-fmriprep","title":"Preprocessing with fMRIPrep","text":""},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#1-setting-up-fmriprep","title":"1. Setting Up fMRIPrep","text":"<p>To use fMRIPrep, ensure that you have:</p> <ul> <li>Docker (or Singularity for HPC environments).</li> <li>Installed the <code>fmriprep-docker</code> wrapper for easier command-line usage:</li> </ul> <pre><code>pip install fmriprep-docker\n</code></pre> <ul> <li>A valid FreeSurfer license (<code>license.txt</code>) saved in a path accessible by fMRIPrep. This is needed for surface-based preprocessing.</li> </ul> <p>System Requirements</p> <p>fMRIPrep is resource-intensive. For optimal performance, allocate:</p> <ul> <li>At least 16 GB RAM and 4 CPUs.</li> <li>A high-speed SSD for the working directory to improve I/O performance.</li> </ul> <p>For detailed instructions, visit the fMRIPrep Installation Guide.</p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#2-running-fmriprep","title":"2. Running fMRIPrep","text":"<p>Once your environment is ready, you can run fMRIPrep using the following command:</p> <pre><code>fmriprep-docker /path/to/BIDS /path/to/derivatives/fmriprep participant \\\n    --work-dir /path/to/temp_fmriprep \\\n    --fs-license-file /path/to/.license \\\n    --output-spaces MNI152NLin2009cAsym:res-2 anat fsnative \\\n    --participant-label &lt;SUBJECT_ID&gt; \\\n    --n-cpus 8 --mem-mb 16000 --notrack\n</code></pre> <p>Replace:</p> <ul> <li><code>/path/to/BIDS</code> with the path to your BIDS directory.</li> <li><code>/path/to/derivatives/fmriprep</code> with where you want to store fMRIPrep outputs.</li> <li><code>&lt;SUBJECT_ID&gt;</code> with the ID of the subject being processed.</li> </ul> Why specify output spaces? <p><code>--output-spaces</code> defines the spaces in which your data will be resampled. Common options include:</p> <ul> <li>MNI152NLin2009cAsym: Standard volumetric template.</li> <li>anat: Subject\u2019s native T1w space.</li> <li>fsnative: FreeSurfer's subject-specific surface space.</li> </ul>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#3-output-structure-and-files","title":"3. Output Structure and Files","text":"<p>After running fMRIPrep, the output will be in the <code>derivatives/fmriprep</code> folder. This includes:</p> <ul> <li>Preprocessed anatomical images (<code>T1w</code>, <code>T2w</code>).</li> <li>Preprocessed functional images (BOLD series).</li> <li>Confounds: <code>.tsv</code> files containing motion parameters and other potential noise regressors.</li> <li>Reports: <code>sub-xx.html</code> files with a summary of the preprocessing.</li> </ul> <p>Refer to the fMRIPrep Output Documentation for more information.</p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#quality-assessment-with-mriqc","title":"Quality Assessment with MRIQC","text":""},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#1-running-mriqc","title":"1. Running MRIQC","text":"<p>MRIQC helps identify potential issues in your data by generating quality metrics. Run MRIQC using Docker with the following command:</p> <pre><code>docker run -it --rm \\\n    -v /path/to/BIDS:/data:ro \\\n    -v /path/to/derivatives/mriqc:/out \\\n    nipreps/mriqc:latest /data /out participant \\\n    --participant-label &lt;SUBJECT_ID&gt; --nprocs 8 --mem-gb 16 --verbose-reports\n</code></pre> <p>This command will analyze individual subjects and save the results in the specified output directory. Replace the paths as appropriate.</p> <p>Running Group-Level Analysis</p> <p>After processing individual subjects, you can run a group-level analysis to compare metrics across subjects:</p> <pre><code>docker run -it --rm \\\n    -v /path/to/BIDS:/data:ro \\\n    -v /path/to/derivatives/mriqc:/out \\\n    nipreps/mriqc:latest /data /out group \\\n    --nprocs 8 --mem-gb 16 --verbose-reports\n</code></pre>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#2-understanding-mriqc-outputs","title":"2. Understanding MRIQC Outputs","text":"<p>MRIQC generates:</p> <ul> <li>Visual reports (<code>sub-xx.html</code>) for each subject.</li> <li>CSV files with quality metrics.</li> <li>Group-level metrics for overall dataset quality.</li> </ul> <p>Refer to the MRIQC Documentation for a detailed explanation of each metric.</p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#interpreting-fmriprep-and-mriqc-reports","title":"Interpreting fMRIPrep and MRIQC Reports","text":""},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#fmriprep-html-report","title":"fMRIPrep HTML Report","text":"<p>After running fMRIPrep, the outputs will be stored in the <code>derivatives/fmriprep</code> directory, with each subject's data organized into subfolders like <code>sub-01</code>. These folders contain both the preprocessed functional and anatomical data, alongside JSON files with metadata.</p> <p>Each subject\u2019s report (<code>sub-xx.html</code>) includes:</p> <ul> <li>Registration Plots: Check the alignment of functional and anatomical images.</li> <li>Field Map Corrections: Review the effect of susceptibility distortion corrections.</li> <li>Motion Correction: Look for high motion frames using Framewise Displacement (FD) plots.</li> </ul> What is Framewise Displacement (FD)? <p>FD is a measure of head movement between frames. High FD values indicate potential motion artifacts.</p> <p>Let\u2019s walk through the key components of the output and how to interpret the HTML summary reports.</p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#1-output-directory-structure","title":"1. Output Directory Structure","text":"<p>Within each subject's directory (<code>sub-01</code>):</p> <ul> <li><code>anat/</code> folder: Contains anatomical images, including normalized versions (e.g., <code>MNI152</code> template) and images in native space.</li> <li><code>func/</code> folder: Contains functional data for each run, including:</li> <li>Confound Regressors (<code>.tsv</code>): Time series of noise estimates like white matter and cerebrospinal fluid (CSF).</li> <li>Preprocessed Functional Images: Aligned to templates like <code>MNI152</code>.</li> <li>Brain Masks: Estimated masks for the brain, used in further analyses.</li> </ul> <p>These files will be referenced in the HTML summary report, which provides an overview of the preprocessing steps and quality metrics.</p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#2-opening-the-html-summary-report","title":"2. Opening the HTML Summary Report","text":"<p>To view the HTML report, navigate to <code>derivatives/fmriprep/sub-01/</code> and open <code>sub-01.html</code> by double-clicking it or using the terminal:</p> <p>The report contains the following sections: Summary, Anatomical, Functional, About, Methods, and Errors. Use the tabs at the top of the report to navigate these sections.</p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#3-understanding-the-summary-section","title":"3. Understanding the Summary Section","text":"<p>The Summary tab includes:</p> <ul> <li>Number of Structural and Functional Images: Lists the number of anatomical and functional images processed.</li> <li>Normalization Template: Shows the template used for alignment (e.g., <code>MNI152NLin2009cAsym</code>).</li> <li>FreeSurfer: Indicates whether surface-based preprocessing was performed.</li> </ul> <p>Make sure these details match the parameters specified in your fMRIPrep command.</p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#4-anatomical-quality-checks","title":"4. Anatomical Quality Checks","text":"<p>The Anatomical section provides:</p> <ul> <li>Brain Mask Overlay: Displays the brain mask (red outline), gray matter (magenta), and white matter boundaries (blue) overlaid on the anatomical image in sagittal, axial, and coronal views.</li> </ul> <p></p> <ul> <li> <p>Normalization Check: A GIF compares the subject\u2019s anatomical image with the MNI template. Ensure that:</p> </li> <li> <p>The outlines of the brain and internal structures (e.g., ventricles) align well.</p> </li> <li>Any misalignment could indicate poor normalization, which may need further inspection.</li> </ul> <p></p> <p>Tip</p> <p>Hover over the GIF to see the back-and-forth comparison between the subject's brain and the template. Look closely at the alignment of internal brain structures.</p> <ul> <li>Surface Reconstruction if you ran the <code>recon-all</code> routine in fMRIprep</li> </ul> <p></p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#5-functional-quality-checks","title":"5. Functional Quality Checks","text":"<p>In the Functional section, you\u2019ll find:</p> <ul> <li>Functional-to-Anatomical Alignment: A GIF shows how well the preprocessed functional images align with the anatomical image.</li> </ul> <p>Check for alignment</p> <p>Check for alignment between internal structures like ventricles in the functional and anatomical images. Open the image in a new tab (Right Click on the image -&gt; Open in a new tab) and hover to see the dynamic image.</p> <p></p> <ul> <li>CompCor Masks: Displays masks used for Anatomical Component Correction (aCompCor):</li> <li>White Matter and CSF (Magenta): Masks used to extract noise components.</li> <li>High-Variance Voxels (Blue): Used for Functional Component Correction (fCompCor).</li> </ul> <p>Assessing Alignment</p> <p>Good alignment between functional and anatomical images is crucial for accurate analysis. Pay special attention to lighter fluid-filled regions in the functional image, which should correspond with dark CSF areas in the anatomical image.</p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#6-bold-summary-and-carpet-plot","title":"6. BOLD Summary and Carpet plot","text":"<p>The report includes time series plots for various confounds:</p> <ul> <li>Global Signal (GS): Measures signal fluctuations across the entire brain.</li> <li>CSF Signal (GSCSF) and White Matter Signal: Represent fluctuations in specific tissue types.</li> <li>Motion Metrics (DVARS, Framewise Displacement):</li> <li>DVARS: Shows changes in BOLD signal intensity from one time point to the next.</li> <li>Framewise Displacement (FD): Tracks the amount of head movement between frames.</li> <li>Use DVARS and FD to identify frames with high motion that could affect data quality.</li> </ul> <p>Tip</p> <p>High motion values often correlate with changes in global signal. Consider including these regressors in your GLM to account for motion-related noise.</p> <p>The carpet plot displays time series of BOLD signals across different brain regions:</p> <ul> <li>Cortex (blue), Subcortex (orange), Gray Matter (green), and White Matter/CSF (red).</li> <li>Look for sudden changes across a column, which may indicate motion artifacts affecting the entire brain at a particular time point.</li> </ul> <p></p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#7-correlation-matrix-of-confound-regressors","title":"7. Correlation Matrix of Confound Regressors","text":"<p>The report also includes a correlation matrix showing relationships between confound regressors:</p> <ul> <li>High correlations between CSF and motion regressors may indicate that motion affects CSF signals.</li> <li>Use this matrix to decide which regressors to include in your GLM for better noise correction.</li> </ul> <p>High Correlations</p> <p>High correlation values may suggest redundancy among some regressors. Consider removing or combining them to avoid overfitting when building your GLM.</p> <p></p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#8-making-decisions-for-further-analysis","title":"8. Making Decisions for Further Analysis","text":"<p>After reviewing the report:</p> <ul> <li>Identify Good Quality Runs: Look for well-aligned images and minimal motion artifacts.</li> <li>Decide on Regressors: Choose confounds like DVARS, FD, and CompCor components to include in your GLM.</li> </ul> <p>What confound regressors should I use in my GLM?</p> <p>A common choice is to include at least the 6 Head Motion parameters, and optionally FD and Global Signal ad nuisance regressors in your GLM.  </p> <p>See this awesome NeuroStars conversation with advice on choosing regressors and relevant resources.</p> <p>For more details on interpreting fMRIPrep reports, see the fMRIPrep Outputs Documentation and discussions on NeuroStars.</p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#mriqc-html-report","title":"MRIQC HTML Report","text":"<p>The MRIQC report highlights:</p> <ul> <li>Summary Image: A visual overview of key metrics, including signal-to-noise ratio (SNR) and temporal SNR (tSNR).</li> <li>Detailed Metrics: Click through different tabs to examine metrics like Mean Framewise Displacement, EPI-to-T1w registration quality, and artifact presence.</li> </ul> <p>Interpreting tSNR</p> <p>Higher temporal SNR (tSNR) values indicate better data quality. Typical values range from 30-60 for fMRI. Low tSNR may suggest issues like excessive noise or scanner artifacts. Review the group-level metrics to identify subjects with unusually high motion or low tSNR.</p> <p>For more information on understanding these metrics, check out the MRIQC interpretation guide on NeuroStars.</p>"},{"location":"research/fmri/analysis/fmri-prepocessing-qa.html#common-issues-with-fmriprep-and-mriqc","title":"Common Issues with fMRIPrep and MRIQC","text":"Memory Errors: Out of Memory (OOM) or Crash <ul> <li>Problem: fMRIPrep crashes or terminates unexpectedly due to insufficient memory.</li> <li>Solution: Reduce the <code>--mem-mb</code> parameter to allocate less memory or increase the swap space available on your system. This can help prevent OOM errors.</li> <li>Tip: Monitor your memory usage during processing using tools like <code>htop</code> (Linux) or Activity Monitor (Mac). Aim to use around 80-90% of your available RAM without exceeding it.</li> </ul> Docker File Permissions Error <ul> <li>Problem: fMRIPrep cannot access input or output directories due to file permissions.</li> <li>Solution: Ensure that Docker has read and write permissions to the directories being mounted. Adjust permissions using:   <pre><code>chmod -R 755 /path/to/BIDS /path/to/derivatives\n</code></pre></li> <li>Tip: On Windows, ensure that Shared Drives are enabled in Docker Desktop settings.</li> </ul> Missing Fields in JSON Files <ul> <li>Problem: fMRIPrep fails due to missing <code>SliceTiming</code> or <code>PhaseEncodingDirection</code> fields in the JSON sidecar files.</li> <li>Solution: Verify that all required metadata fields are present using the BIDS Validator. For guidance on JSON sidecar fields, see the BIDS Specification.</li> <li>Tip: If using custom acquisition parameters, manually edit JSON files to include the missing fields.</li> </ul> RuntimeError: Fieldmap Issues <ul> <li>Problem: fMRIPrep throws a <code>RuntimeError</code> related to fieldmaps, such as missing or improperly specified fieldmaps.</li> <li>Solution: Ensure that fieldmaps are correctly specified in your BIDS dataset according to the BIDS Fieldmap documentation.</li> <li>Tip: If your study does not require fieldmap correction, you can skip this step by specifying <code>--ignore fieldmaps</code> in your fMRIPrep command.</li> </ul> MRIQC: NaN Values in JSON Files <ul> <li>Problem: MRIQC fails when encountering <code>NaN</code> values in JSON metadata files.</li> <li>Solution: Use a script like <code>sanitize_json.py</code> to replace <code>NaN</code> values with valid placeholders before running MRIQC.</li> <li>Tip: Validate your JSON files before running MRIQC to avoid processing interruptions.</li> </ul> Docker: Cannot Allocate Memory <ul> <li>Problem: fMRIPrep crashes with the error <code>cannot allocate memory</code> when using Docker.</li> <li>Solution: Restart the Docker service or allocate more memory and CPUs through the Docker Desktop settings under Resources.</li> <li>Tip: Increase memory allocation gradually (e.g., 2-4 GB increments) until fMRIPrep runs smoothly.</li> </ul> Slow Processing: fMRIPrep Takes Too Long <ul> <li>Problem: fMRIPrep runs slowly, taking an excessively long time for each subject.</li> <li>Solution: Use a faster SSD for the <code>--work-dir</code> to improve read/write speeds and reduce processing time. Also, ensure <code>--n-cpus</code> is set to the majority of available cores, but not all, to avoid system slowdowns.</li> <li>Tip: Consider running fMRIPrep on a high-performance computing (HPC) cluster if available.</li> </ul> Missing or Corrupted Output Files <ul> <li>Problem: After running fMRIPrep or MRIQC, certain output files (e.g., <code>sub-xx.html</code> reports) are missing or corrupted.</li> <li>Solution: Check for errors in the log files generated during the run. Often, disk space issues or interruptions during processing can cause missing files. Re-run the affected subjects with sufficient disk space.</li> <li>Tip: Use a dedicated work directory and ensure it has at least 100 GB of free space to accommodate intermediate files.</li> </ul> MRIQC: No Group Report Generated <ul> <li>Problem: Group-level analysis in MRIQC does not produce a report.</li> <li>Solution: Ensure that MRIQC was run in group mode using the correct <code>group</code> argument. Check if all individual reports are present in the output directory before running the group-level command.</li> <li>Tip: Verify that the <code>derivatives/mriqc</code> directory has read and write access for Docker.</li> </ul> <p>With these quality checks complete, you\u2019re ready to proceed to the General Linear Model (GLM) analysis. See the next guide for instructions on setting up your GLM. \u2192 Go to GLM</p>"},{"location":"research/fmri/analysis/fmri-rois.html","title":"Regions Of Interest","text":"<ul> <li>TODO:  populate this. mention the roi stuff Filippo did, and perhaps ask him to write something about it?</li> </ul> <p>https://neuroimaging-core-docs.readthedocs.io/en/latest/pages/atlases.html#id4 https://neurosynth.org/ https://openneuro.org/</p> <p>Now that you have your beta images (from the GLM) and your ROIs, you have everything you need to run your multi-variate analysis. \u2192 MVPA</p>"},{"location":"research/fmri/analysis/fmri-setup-env.html","title":"Setting Up Your fMRI Analysis Environment","text":"<p>Welcome to the fMRI analysis environment setup guide. This walkthrough will help you install and configure all necessary tools for our fMRI analysis workflow across Windows, macOS, and Linux platforms.</p> <p>Suggested System Specifications</p> <ul> <li>Operating System: Windows 10/11, macOS 10.14+, or Linux (Ubuntu 18.04+)</li> <li>RAM: 16GB (32GB+ recommended)</li> <li>Storage: 200GB+ free space (SSD preferred)</li> <li>CPU: Multi-core processor (4+ cores)</li> <li>GPU: NVIDIA GPU with CUDA support (optional, but beneficial)</li> </ul>"},{"location":"research/fmri/analysis/fmri-setup-env.html#folder-structure","title":"Folder Structure","text":"<p>Our lab uses a specific folder structure for fMRI projects. Here's an overview:</p> <pre><code>Project_Name/\n\u251c\u2500\u2500 sourcedata/\n\u2502   \u2514\u2500\u2500 sub-xx/\n\u2502       \u251c\u2500\u2500 dicom/\n\u2502       \u251c\u2500\u2500 dicom_anon/\n\u2502       \u251c\u2500\u2500 bh/\n\u2502       \u251c\u2500\u2500 et/\n\u2502       \u2514\u2500\u2500 nifti/\n\u251c\u2500\u2500 BIDS/\n\u2502   \u251c\u2500\u2500 derivatives/\n\u2502   \u2502   \u251c\u2500\u2500 deepmreye/\n\u2502   \u2502   \u251c\u2500\u2500 fastsurfer/\n\u2502   \u2502   \u251c\u2500\u2500 fmriprep/\n\u2502   \u2502   \u251c\u2500\u2500 fmriprep-mriqc/\n\u2502   \u2502   \u251c\u2500\u2500 fmriprep-spm/\n\u2502   \u2502   \u251c\u2500\u2500 fmriprep-spm-cosmomvpa/\n\u2502   \u2502   \u2514\u2500\u2500 rois/\n\u2502   \u2514\u2500\u2500 sub-xx/\n\u2502       \u251c\u2500\u2500 anat/\n\u2502       \u2514\u2500\u2500 func/\n\u251c\u2500\u2500 code/\n\u2502   \u251c\u2500\u2500 misc/\n\u2502   \u2514\u2500\u2500 utils/\n\u2514\u2500\u2500 temp/\n    \u251c\u2500\u2500 temp_fmriprep/\n    \u251c\u2500\u2500 temp_spm/\n    \u251c\u2500\u2500 temp_deepmreye/\n    \u2514\u2500\u2500 temp_mriqc/\n</code></pre> <ul> <li><code>sourcedata/</code>: Contains raw data for each subject</li> <li><code>BIDS/</code>: Organized according to BIDS specification</li> <li><code>derivatives/</code>: Stores processed data</li> <li><code>code/</code>: Contains analysis scripts and utilities</li> <li><code>temp/</code>: Temporary directories for various processing steps</li> </ul> <p>Create the folder structure</p> <p>To create this folder structure, you can use the following bash script:</p> create_fmri_structure.sh<pre><code># Create main project directory\nmkdir -p Project_Name\n\n# Navigate to the project directory\ncd Project_Name\n\n# Create sourcedata structure\nmkdir -p sourcedata/sub-xx/{dicom,dicom_anon,nifti,bh,et}\n\n# Create BIDS structure\nmkdir -p BIDS/sub-xx/{anat,func}\nmkdir -p BIDS/derivatives/{deepmreye,fastsurfer,fmriprep,fmriprep-spm,fmriprep-spm-cosmomvpa,fmriprep-mriqc,rois}\n\n# Create code structure\nmkdir -p code/{misc,utils}\n\n# Create temp structure\nmkdir -p temp/{temp_fmriprep,temp_spm,temp_deepmreye,temp_mriqc}\n\necho \"Folder structure created successfully!\"\n</code></pre> <p>Save this script as <code>create_fmri_structure.sh</code> and run it using:</p> <pre><code>bash create_fmri_structure.sh\n</code></pre>"},{"location":"research/fmri/analysis/fmri-setup-env.html#installing-core-tools","title":"Installing Core Tools","text":""},{"location":"research/fmri/analysis/fmri-setup-env.html#docker-desktop","title":"Docker Desktop","text":"<p>Docker is crucial for running containerized applications like fMRIPrep. Althoug Docker can be installed as a command-line tool, we strongly advise installing the GUI version (Docker Desktop).</p> <p>For up-to-date installation info, please consult the Docker Desktop installation pages for Mac, Windows or Linux.</p> <p>After installation, configure Docker resources:</p> <ol> <li>Open Docker Desktop settings</li> <li>Go to \"Resources\" section</li> <li>Allocate resources:<ul> <li>CPUs: Set to total CPUs - 2 (e.g., if you have 8 cores, set to 6)</li> <li>Memory: Set to 80% of total RAM (e.g., if you have 32GB, set to 25GB)</li> <li>Disk image size: Set to a reasonable amount (e.g., 100GB)</li> </ul> </li> <li>In the \"File sharing\" or \"Resources &gt; File sharing\" section, add your project folder (e.g., <code>~/fMRI_Projects</code>)</li> </ol>"},{"location":"research/fmri/analysis/fmri-setup-env.html#installing-docker-tools","title":"Installing Docker Tools","text":"<p>We use several tools via Docker for our fMRI analysis pipeline. Docker installations are strongly encouraged over \"bare metal\" setups for several reasons:</p> <ol> <li>Docker containers come bundled with all necessary dependencies, ensuring compatibility across different systems.</li> <li>They provide a consistent environment, reducing \"it works on my machine\" issues.</li> <li>Docker simplifies the installation process and manages complex software interactions.</li> </ol> <p>Many of these tools are BIDS-apps, which are container images designed to work with BIDS-formatted datasets. BIDS (Brain Imaging Data Structure) is a standard for organizing and describing neuroimaging datasets. BIDS Apps have consistent command-line arguments, making them easy to run and integrate into automated platforms.</p> <p>Important</p> <p>Before running any BIDS-app, ensure your input folder is correctly structured according to BIDS standards. Validate your BIDS dataset using the BIDS Validator to avoid potential issues.</p> <p>For detailed installation and usage instructions, please refer to each tool's respective documentation. For examples of how to run these tools using Docker, refer to the usage notes in their respective documentation or check our fMRI workflow example in this same folder.</p> <p>Below are the basic Docker pull commands for the main tools we use:</p> <ul> <li> <p>fMRIprep:</p> <p>fMRIPrep is a tool for minimal pre-processing of structural and anatomical MRI images.</p> <p>To get the Docker image:</p> <pre><code>python -m pip install fmriprep-docker\n</code></pre> </li> <li> <p>MRIQC:</p> <p>MRIQC is a tool to perform Quality Check on your raw and pre-processed MRI images.</p> <p>To get the Docker image:</p> <pre><code>docker pull nipreps/mriqc:latest\n</code></pre> </li> <li> <p>FastSurfer:</p> <p>FastSurfer is a self-contained, faster (it uses the NVIDIA GPU processing) alternative to FreeSurfer. It can save quite some time when performing surface processing pipelines (e.g., <code>recon-all</code>).</p> <p>To get the Docker image:</p> <pre><code>docker pull deepmi/fastsurfer:latest\n</code></pre> <p>Note</p> <p>FastSurfer can save you time if you have a CUDA-compatible GPU. In short, this means that your machine should have a dedicated NVIDIA GPU with CUDA installed. You can check whether CUDA is correctly installed on you machine by typing <code>nvidia-smi</code> on your terminal. If this command does not return a list of active GPUs, you either need to install and configure CUDA, or you can avoid installing this tool and rely on the <code>recon-all</code> pipeline performed with the anatomical workflow of fMRIPrep.</p> </li> <li> <p>DeepMReye:</p> <p>DeepMReye is a tool to perform eye-tracking data analysis when you have no eye-tracking data. It estimates eye-movements from the eyes position in your functional images. This will of course results in a (very) much lower temporal resolution than real eye-tracking data, but we found results to be good enough for some experimental paradigms.</p> <p>To get the Docker image:</p> <pre><code>docker pull deepmreye/deepmreye\n</code></pre> </li> </ul>"},{"location":"research/fmri/analysis/fmri-setup-env.html#dcm2niix","title":"dcm2niix","text":"<p>dcm2niix is a powerful tool used for DICOM to NIfTI conversion. It can be used as a command-line tool or through a Graphical User Interface (GUI) when shipped with MRIcroGL (see this for more information).</p> <p>There are several ways to install dcm2niix, depending on your operating system and preferences:</p> WindowsmacOSLinux <ol> <li> <p>Download pre-compiled executable: <pre><code>curl -fLO https://github.com/rordenlab/dcm2niix/releases/latest/download/dcm2niix_win.zip\n</code></pre>    Unzip the file and add the executable to your system PATH:    <pre><code>$env:Path += \";C:\\path\\to\\dcm2niix\"\n</code></pre>    Replace <code>C:\\path\\to\\dcm2niix</code> with the actual path where you unzipped dcm2niix.</p> </li> <li> <p>Install with Conda: <pre><code>conda install -c conda-forge dcm2niix\n</code></pre></p> </li> <li> <p>Install with pip: <pre><code>python -m pip install dcm2niix\n</code></pre></p> </li> <li> <p>Download MRIcroGL: Download MRIcroGL which includes dcm2niix with a GUI.</p> </li> </ol> <ol> <li> <p>Download pre-compiled package: <pre><code>curl -fLO https://github.com/rordenlab/dcm2niix/releases/latest/download/macos_dcm2niix.pkg\n</code></pre>    Open the downloaded package to install.</p> </li> <li> <p>Install with Homebrew: <pre><code>brew install dcm2niix\n</code></pre></p> </li> <li> <p>Install with MacPorts: <pre><code>sudo port install dcm2niix\n</code></pre></p> </li> <li> <p>Install with Conda: <pre><code>conda install -c conda-forge dcm2niix\n</code></pre></p> </li> <li> <p>Install with pip: <pre><code>python -m pip install dcm2niix\n</code></pre></p> </li> </ol> <ol> <li> <p>Download pre-compiled executable: <pre><code>curl -fLO https://github.com/rordenlab/dcm2niix/releases/latest/download/dcm2niix_lnx.zip\n</code></pre>    Unzip the file and add the executable to your system PATH:    <pre><code>echo 'export PATH=$PATH:/path/to/dcm2niix' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>    Replace <code>/path/to/dcm2niix</code> with the actual path where you unzipped dcm2niix.</p> </li> <li> <p>Install on Debian-based systems: <pre><code>sudo apt-get install dcm2niix\n</code></pre></p> </li> <li> <p>Install with Conda: <pre><code>conda install -c conda-forge dcm2niix\n</code></pre></p> </li> <li> <p>Install with pip: <pre><code>python -m pip install dcm2niix\n</code></pre></p> </li> </ol> Older Linux versions compatibility <p>The pre-compiled Linux executable requires a recent version of Linux (e.g., Ubuntu 14.04 or later) with Glibc 2.19 (from 2014) or later. Users of older systems can compile their own copy of dcm2niix or download the compiled version included with MRIcroGL, which is compatible with Glibc 2.12 (from 2011).</p>"},{"location":"research/fmri/analysis/fmri-setup-env.html#python-and-conda","title":"Python and Conda","text":"<p>We use Conda to manage our Python environment.</p> <ol> <li>Install Miniconda</li> <li> <p>Create and activate the environment:</p> <pre><code>conda create -n fmri_env python=3.9 spyder numpy scipy matplotlib nibabel nilearn scikit-learn\n</code></pre> </li> <li> <p>Activate the environment:</p> <pre><code>conda activate fmri_env\n</code></pre> </li> </ol> <p>Warning</p> <p>It's crucial to create a new conda environment for each new project you start. Installing new packages into the base conda environment it's a very bad practice that will eventually lead to a bloated, brittle environent with broken packages and compatibility issues. Uninstalling or re-installing Python on some machine can be a very painful (sometimes impossible) process!</p>"},{"location":"research/fmri/analysis/fmri-setup-env.html#setting-up-spyder-ide","title":"Setting up Spyder IDE","text":"<ol> <li> <p>Launch Spyder:</p> <pre><code>conda activate fmri_env\nspyder\n</code></pre> </li> <li> <p>Create a new project:</p> <ul> <li>Go to \"Projects\" &gt; \"New Project\"</li> <li>Choose \"Existing directory\"</li> <li>Select your project folder (e.g., <code>~/fMRI_Projects/Project_Name</code>)</li> <li>Name your project and click \"Create\"</li> </ul> </li> </ol>"},{"location":"research/fmri/analysis/fmri-setup-env.html#matlab","title":"MATLAB","text":"<p>For MATLAB installation and licensing, please refer to the Installing MATLAB section in our computer setup guide.</p> <p>Install the following MATLAB toolboxes:</p> <ul> <li> <p>SPM:</p> <p>SPM (Statistical Parametric Mapping) is used for GLM analysis.</p> <ol> <li>Download SPM12</li> <li>Unzip to a location of your choice</li> <li>Add SPM to MATLAB path:</li> </ol> <pre><code>addpath('path/to/spm12')\nsavepath\n</code></pre> <p>Mac installtion</p> <p>For mac users, potential installation issues can be tackled with the instructions for mac on the SPM wiki. Make sure Xcode is installed on your computer before installing SPM.</p> </li> <li> <p>CoSMoMVPA</p> <p>CoSMoMVPA is used for multivariate pattern analysis.</p> <ol> <li>Download from the official website</li> <li>Add to MATLAB path:</li> </ol> <pre><code>addpath(genpath('path/to/CoSMoMVPA'))\nsavepath\n</code></pre> </li> <li> <p>MarsBaR:</p> <p>MarsBaR is a region of interest toolbox for SPM.</p> <ol> <li>Download MarsBaR</li> <li>Unzip to a location of your choice, such as <code>/home/myhome/marsbar-0.42/</code></li> <li> <p>Copy the MarsBaR distribution into the SPM directory with:</p> <pre><code>mkdir /path-to-spm/toolbox/marsbar\ncp -r /home/myhome/marsbar-0.42/* /path-to-spm/toolbox/marsbar\n</code></pre> </li> </ol> <p>Change <code>/path-to-spm/</code> with your SPM path (e.g., <code>/usr/local/spm/spm12/</code>).</p> <p>The next time you start spm you should be able to start the toolbox by selecting \u2018marsbar\u2019 from the toolbox button on the SPM interface.  </p> </li> </ul>"},{"location":"research/fmri/analysis/fmri-setup-env.html#installing-additional-tools","title":"Installing Additional Tools","text":"<p>These tools are not mandatory -- they can be installed if needed.</p>"},{"location":"research/fmri/analysis/fmri-setup-env.html#freesurfer","title":"FreeSurfer","text":"<p>FreeSurfer is used for cortical surface reconstruction. The main surface reconstruction pipeline of FreeSurfer (<code>recon-all</code>) is bundled in the fmriprep docker image, and it is performed during the fmriprep anatomical workflow. This means that this tool is not strictly necessary, unless you plan on running additional surface processing steps (e.g., additional surface projections, such as the Glasser volumetric projection from fsaverage that is performed in the fMRI workflow example.</p> <p>To install:</p> <ol> <li>Download from the official website</li> <li>Set up environment variables:</li> </ol> <pre><code>export FREESURFER_HOME=/path/to/freesurfer\nsource $FREESURFER_HOME/SetUpFreeSurfer.sh\n</code></pre> FreeSurfer on Windows <p>FreeSurfer is not natively compatible with Windows. To use FreeSurfer on a Windows system, you have a few options:</p> <ol> <li> <p>Use Windows Subsystem for Linux (WSL):</p> <ul> <li>Install WSL 2 on your Windows machine</li> <li>Install a Linux distribution like Ubuntu through WSL</li> <li>Install FreeSurfer within the Linux environment</li> </ul> </li> <li> <p>Use a virtual machine:</p> <ul> <li>Install virtualization software like VirtualBox or VMware</li> <li>Set up a Linux virtual machine </li> <li>Install FreeSurfer in the Linux VM</li> </ul> </li> <li> <p>Use a Docker container:</p> <ul> <li>Install Docker Desktop for Windows</li> <li>Pull and run a FreeSurfer Docker image</li> </ul> </li> <li> <p>Remote access:</p> <ul> <li>Use a remote Linux server or cluster with FreeSurfer installed</li> <li>Connect via SSH or remote desktop</li> </ul> </li> </ol> <p>The WSL or Docker options are generally recommended as they have less overhead than a full VM. Whichever method you choose, ensure you have adequate disk space and RAM allocated for FreeSurfer to run efficiently.</p>"},{"location":"research/fmri/analysis/fmri-setup-env.html#ants","title":"ANTs","text":"<p>ANTs is used for image registration and normalization. As for FreeSurfer, this tool is not strictly necessary, unless you want to generate the Glasser volumetric projection from fsaverage described here</p> <ol> <li>Download from GitHub</li> <li>Add to system PATH:</li> </ol> <pre><code>export ANTSPATH=/path/to/ANTs/bin\nexport PATH=$ANTSPATH:$PATH\n</code></pre>"},{"location":"research/fmri/analysis/fmri-setup-env.html#common-issues","title":"Common Issues","text":"Docker: WSL2 Configuration Errors on Windows <p>Problem: Docker fails to start or displays errors related to WSL2.</p> <p>Solution: Ensure WSL2 is properly installed and configured. Open Docker Desktop settings and verify that WSL2 is selected as the backend. Restart Docker Desktop after making changes. If issues persist, run the following command in PowerShell: <pre><code>wsl --update\n</code></pre></p> Docker: Service Issues on Linux <p>Problem: Docker service fails to start or stops unexpectedly on Linux systems.</p> <p>Solution: Restart the Docker service and check the logs for more details: <pre><code>sudo systemctl restart docker\nsudo journalctl -u docker.service\n</code></pre> Ensure Docker is set to start on boot using: <pre><code>sudo systemctl enable docker\n</code></pre></p> MATLAB: Not Recognized in PATH <p>Problem: MATLAB is not found in the system PATH, leading to command not found errors.</p> <p>Solution: Add the MATLAB installation directory to your system PATH. For a temporary fix, run: <pre><code>export PATH=$PATH:/path/to/matlab/bin\n</code></pre> To make this change permanent, add the above line to your <code>~/.bashrc</code> or <code>~/.zshrc</code> file and restart the terminal.</p> SPM: Missing Toolboxes <p>Problem: Errors occur due to missing SPM toolboxes in MATLAB.</p> <p>Solution: Ensure the required toolboxes (e.g., SPM, CoSMoMVPA, MarsBaR) are installed and added to the MATLAB path. Use the following in MATLAB: <pre><code>addpath('path/to/spm12')\nsavepath\n</code></pre></p> FreeSurfer: License Not Found <p>Problem: FreeSurfer cannot locate the <code>license.txt</code> file, leading to startup errors.</p> <p>Solution: Place the <code>license.txt</code> file in the FreeSurfer home directory and set the path correctly: <pre><code>export FS_LICENSE=/path/to/license.txt\n</code></pre> Add this line to your <code>~/.bashrc</code> or <code>~/.zshrc</code> file to ensure the license path is set on each terminal start.</p> Python: Package Conflicts <p>Problem: Conflicting package versions cause Python environments to break.</p> <p>Solution: Create a new conda environment for each project to avoid conflicts. Use: <pre><code>conda create -n new_env python=3.9\nconda activate new_env\n</code></pre> For existing environments, try resolving conflicts by specifying package versions during installation: <pre><code>conda install package_name=version\n</code></pre></p> FreeSurfer: Incompatible with Native Windows <p>Problem: FreeSurfer is not compatible with Windows and cannot be installed directly.</p> <p>Solution: Use one of these methods: - WSL2: Install WSL2 and a Linux distribution like Ubuntu, then install FreeSurfer in this environment. - Virtual Machine: Use VirtualBox or VMware to set up a Linux virtual machine, then install FreeSurfer. - Docker: Install Docker Desktop for Windows and run a FreeSurfer Docker image for compatibility.</p> <p>For more specific issues, consult tool documentation or seek help on NeuroStars.</p> <p>Remember, setting up an fMRI analysis environment can be complex. Take your time, and don't hesitate to ask for help when needed. Good luck with your research!</p> <p>Now you\u2019re ready to proceed convert your data into BIDS format. See the next guide for instructions on setting up your BIDS folder. \u2192 BIDS conversion</p>"}]}